---
title: "Assignments Mixed models"
author: "Wouter van Amsterdam"
date: 2018-04-16
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->


## Setup R environment


```{r}
library(dplyr)
library(data.table)
library(magrittr)
library(purrr)
library(here) # for tracking working directory
library(ggplot2)
library(epistats)
library(broom)
```

# Day 1

## 1. schools

```{r}
london <- read.table(here("data", "school.dat"), header = T)
str(london)
```


First clean up the data a bit so that factor variables are coded as such

```{r}
factor_vars <- c("gender", "schgend", "schav")
london %<>% mutate_at(vars(factor_vars), funs(as.factor))
```


All data

```{r}
london %>%
  ggplot(aes(y = normexam, x = standlrt)) + 
  geom_point()
```


Linear model

```{r}
london %>%
  lm(normexam ~ standlrt, data = .) %>%
  summary()
```


Get individual scatterplots

```{r, cache = T}
london %>%
  ggplot(aes(y = normexam, x = standlrt)) + 
  geom_point() +
  facet_wrap(~school)

```


Perform lm in each school

We can use split from base R and combine this with map to apply 
lm to each element of the list

```{r}
coefs <- london %>%
  split(f = .[["school"]]) %>%
  map(function(data) lm(normexam~standlrt, data = data)) %>%
  map_df(tidy)
coefs %>%
  group_by(term) %>%
  summarize(mean(estimate), sd(estimate))
```

Here is a nice way of doing this with purrr, tidyr and dplyr (completely 
tidyverse)

```{r}
require(tidyr)
london_nested <- london %>% group_by(school) %>% nest()

get_coef <- function(coefs, coef = "(Intercept)") {
  stopifnot(is.data.frame(coefs))
  coefs[coefs$term == coef, "estimate"]
}

london_nested %>%
  mutate(fit = map(data, ~lm(normexam~standlrt, data = .x)),
         coefs = map(fit, tidy),
         intercept = as.numeric(map(coefs, ~get_coef(.x))),
         slope     = as.numeric(map(coefs, ~get_coef(.x, "standlrt")))) %>%
  summarize_at(vars(intercept, slope), funs(mean, sd))

```


Using data.table

.. and broom::tidy in 1 throw

```{r}
setDT(london)
coefs <- london[, {
  fit = lm(normexam ~ standlrt, data = .SD)
  tidy(fit)
  }, by = "school"]
coefs[, list(mean = mean(estimate), sd = sd(estimate)), by = "term"]
```


.. with step of list of fits

```{r}
setDT(london)
fits <- london[, list(fit = list(lm(normexam ~ standlrt, data = .SD))), 
               by = "school"]
fits[[2]] %>% 
  map_df(tidy) %>%
  group_by(term) %>%
  summarize(mean(estimate), sd(estimate))

```

### 2.

> Continue with reproducing the analysis of the schools dataset (school.dat or school.sav) so far.

#### a.	

> Fit a linear mixed model with random intercept to predict exam scores using the LRT scores.

```{r}
require(lme4)
lmer(normexam ~ standlrt + (1 | school), data = london, REML = F)
```


#### b.

> Add a random slope to the model in (a). Interpret this model.

```{r}
lmer(normexam ~ standlrt + (standlrt | school), data = london, REML = F)
```

On average, children with average baseline score, score avarage on the normalized 
exams. There is a positive correlation with baseline score and normalized exam.
Schools differ in overall normalized exam scores, and the correlation between 
baseline score and normalized exam score differs between schools


## 3.

> Finish the analysis of the schools dataset (school.dat or school.sav).

### a.	

> Add child- and school-level explanatory variables. Interpret the model.

```{r}
lmer(normexam ~ standlrt + gender + schgend + schav + (standlrt | school), data = london,
     REML = F) %>% 
  summary()
```

### b.	

> For the model in (a), we will write a brief description of the statistical model used. Fill in the blanks:

"A linear mixed effects model was estimated, using fixed effects for baseline score,
gender, school gender and school average; A random intercept and a random effect of baseline score per school were added to correct for clustering on school level."

## 4.

> Part c of this question will be used in the quiz this afternoon. Please save or print the output and have it on hand (together with this exercise) when you complete the quiz.

> A multi-center, randomized, double-blind clinical trial was done to compare two treatments for hypertension. One treatment was a new drug (1 = Carvedilol) and the other was a standard drug for controlling hypertension (2 = Nifedipine). Twenty-nine centers participated in the trial and patients were randomized in order of entry. One pre-randomization and four post-treatment visits were made. Here, we will concentrate on the last recorded measurement of diastolic blood pressure (primary endpoint: dbp). The data can be found in the SPSS data file dbplast.sav. Read the data into R or SPSS. The research question is which of the two medicines (treat) is more effective in reducing DBP. Since baseline (pre-randomization) DBP (dbp) will likely be associated with post-treatment DBP and will reduce the variation in the outcome (thereby increasing our power to detect a treatment effect), we wish to include it here as a covariate.

Read in the data

```{r}
bp <- haven::read_spss(here("data", "dbplast.sav"))
str(bp)
```

Curate

```{r}
factor_vars <- c("center", "patient", "treat")
bp %<>% mutate_at(vars(factor_vars), funs(as.factor))
```

### a.	

> Make some plots to describe the patterns of the data.

```{r}
summary(bp)
```


First scatter plot an pre-and post bp;

Let's assume that dbp1 = pre

```{r}
bp %>%
  ggplot(aes(x = dbp1, y = dbp)) + 
  geom_point()
```

Now per treatment


```{r}
bp %>%
  ggplot(aes(x = dbp1, y = dbp)) + 
  geom_point() + 
  facet_wrap(~treat)

```

Look at marginal distributions per treatment

```{r}
bp %>% 
  as.data.table() %>%
  data.table::melt(id.vars = c("patient", "treat"), measure.vars = c("dbp", "dbp1")) %>%
  ggplot(aes(x = 1, y = value, fill = treat)) + 
  geom_boxplot(alpha = .5) + 
  facet_wrap(~variable)
```


### b.	

> Fit a model to answer the research question, using maximum likelihood estimation, taking into account that patients within centers may have correlated data. Interpret the coefficients of the model.

```{r}
lmer(dbp ~ dbp1 + treat + (1 | center), data = bp, REML = F) %>%
  summary()
```


### c.

> Make a new baseline dbp variable, centered around its mean. Re-fit the model in (b) using the centered baseline blood pressure variable, using maximum likelihood estimation, and interpret the parameters of this new model.

```{r}
fit <- bp %>%
  mutate(dbp_center = dbp1 - mean(dbp1)) %>%
  lmer(dbp ~ dbp_center + treat + (1 | center), data = ., REML = F)

fit %>%
  summary()
```


## 5.

> In a small crossover study two drugs, A and B, are compared for their effect on the diastolic blood pressure (DBP). Each patient in the study receives the two treatments in a random order and separated in time (“wash-out” period) so that one treatment does not influence the blood pressure measurement obtained after administering the other treatment (i.e. to rule out carry-over effect) . The data are given in the data file crossover.sav and crossover.dat.

> Note that subject 4 has only the measurement for drug A and that subject 16 has only the measurement for drug B.

Read in data and curate

```{r}
bpco <- read.table(here("data", "crossover.dat"), header = T)

bpco %<>% 
  set_colnames(tolower(colnames(bpco)))

factor_vars <- c("period", "drug")

bpco %<>% mutate_at(vars(factor_vars), funs(as.factor))

str(bpco)
```


### a.

> Use descriptive statistics to get a feel for the data. Which drug seems to be better at reducing DBP?

```{r}
setDT(bpco)
bpco[, list(mean_bp = mean(y)), by = "drug,period"]
```

Drug 1 seems to reduce blood pressure, while drug 2 seems to increase.

In a spaghetti plot


```{r}
bpco %>%
  ggplot(aes(x = drug, y = y, group = patient)) + 
  geom_line(alpha = .8) + theme_minimal()


```


### b.

> Fit a model to the data, looking at drug and period effect and correcting for the fact that (most) patients have more than one DBP measurement. Which variable(s) do you choose as random?

```{r}
fit <- lmer(y ~ drug + period + (1 | patient), data = bpco, REML = F)
fit %>% summary()
```

### c.

> Interpret the results of the model. Is there a significant difference between the two drugs?	Is there a significant period effect?

Drug 2 seems to increase blood pressure (be less effective)

Perdiod effect is negative, which could indicate regression to the mean
(participants are included when having a (sometimes random) high blood pressure)

For significance:

```{r}
confint(fit)
```

Yes from profile likelihood intervals, therapy difference is significant, 
but not period

### d. 

> What other hypothesis might we want to test here?

maybe interaction between drug and period?

## 6.

> A secondary question regarding the school exam data (exercises 1 & 2) was proposed in the lecture. Use SPSS or R (or both) to address the question: is the difference between boys and girls the same for single-sex and mixed-gender schools?  (Note: you’ll need to make a new variable for single-gender (schgend = 2 or 3) vs mixed-gender (schgend = 1) schools before proceeding with the analysis.)


```{r}
london %>%
  mutate(mixed_school = schgend == 1) %>%
  lmer(normexam ~ standlrt + gender * mixed_school + schav + (standlrt | school), data = .,
     REML = F) %>% 
  summary()
```

In the mixed school, there seems to be no difference between genders

## 7. (Challenge)

> Tomorrow we will spend the morning session examining different ways of analyzing the Reisby dataset. This is a longitudinal dataset on 66 patients with endogenous or exogenous depression. Patients are measured every week starting at baseline; from week 1 on, they were all treated with imipramine. The outcome is the score on the Hamilton Depression Rating Scale (HDRS), a score based on a questionnaire administered by a health care professional. The score ranges - theoretically - from 0 (no depressive symptoms) to 52, where scores higher than 20 indicate moderate to very severe depression. The questions of interest are how the HDRS score changes over time for the patients, and whether the patterns of HDRS over time differ for patients with endogenous and exogenous depression. The data is available in both a “wide” and a “long” format: reisby_wide.sav and reisby_long.sav .

Read in data and curate

```{r}
reisby_wide <- haven::read_spss(here("data", "reisby_wide.sav"))
reisby_long <- haven::read_spss(here("data", "reisby_long.sav"))

factor_vars <- c("id")
logical_vars <- c("endo")

reisby_wide %<>% mutate_at(vars(factor_vars), funs(as.factor))
reisby_long %<>% mutate_at(vars(factor_vars), funs(as.factor))
reisby_wide %<>% mutate_at(vars(logical_vars), funs(as.logical))
reisby_long %<>% mutate_at(vars(logical_vars), funs(as.logical))

str(reisby_wide)
str(reisby_long)

```

### a.

> We heard this morning that longitudinal data is also multi-level data. How many levels do we have here? What does each level represent?

Level 1: patient + timepoint
Level 2: patient

### b.

> Use descriptive statistics (means, SDs, graphs) to get a feel for the data, concentrating on the patterns (individual and/or group) of HDRS over time (note that there are two versions of the dataset given, one “wide” and one “long”. For some graphs and descriptive statistics, one version may be easier to use than the other.

Let's look at spaghetti plots

```{r}
reisby_long %>% 
  ggplot(aes(x = week, y = hdrs, group = id)) + 
  geom_line() + facet_wrap(~endo, labeller = label_both)
```

All seem to go down.

Slope seems pretty similar for both treatments, but not intercept

### c. What do you notice about the mean HDRS score over time? And the variation?

Mean goes down, sd seems to go up

```{r}
setDT(reisby_long)
reisby_long[, list(n_patients = uniqueN(id),
                   mean_hdrs = mean(hdrs, na.rm = T), 
                   sd_hdrs = sd(hdrs, na.rm = T)), 
            by = "week"]
```

### d. 

> Time was measured at 6 discrete moments. How would you want to incorporate time in the fixed part of the model: as discrete or continuous? Explain your answer.

Probably as continous, all moments are equally spaced. This requires less 
degrees of freedom

### e.

> If you were to include a random intercept in the model, for which level would you include an intercept?

Patient

### f. 

> Do you think it is necessary to include time in the random part of the model? Why or why not?
 
Does not make a lot of sense. 

It's not like the time-points are a random draw of all possible time-points to measure at

# Day 2

## 1.

> Repeat the linear mixed models analyses of the Reisby dataset, using time as a continuous variable. There are two versions of the dataset: “wide format” (reisby_wide.sav), meaning that all observations are in separate rows, and “long format” (reisby_long.sav), with observations from different time points on a separate line (so 6 lines per patient). Some of the descriptive analyses are easier to do when the data is in “wide format”, and others when the data is in “long format”. The mixed models need to be run on the data in “long” format.
R users can use the foreign library to read in reisby_wide.sav, and either also read in the reisby_long.sav dataset or use the reshape() function to go from wide to long (see R script for help).


> a.	Do some initial data analysis: get descriptive statistics and make plots of the data (note that most of the descriptive statistics – means, SDs, correlations – are easier to get in the wide version of the data, while the spaghetti plots and individual plots are easier to get from the wide version.

See above

### b. 

> Can you think of a few possible hypotheses about the effect of endo?

Different intercept, different slope

### c.

> Repeat the mixed model analyses of the Reisby dataset: model depression score (HDRS) as a function of time (linear), endo/exo and the interaction of the two. Use a model with only a random intercept per patient, and a model with a random intercept plus a random slope for time.

```{r}
require(lme4)
lmer(hdrs ~ week * endo + (1|id), data = reisby_long) %>% summary()
lmer(hdrs ~ week * endo + (week|id), data = reisby_long) %>% summary()

```

### d.

> Which model from (d) do you think fits the data better, and why?

More terms always fits better according to likelihood.

The residual standard deviation of the model with random intercept and slope 
is lower, so seems to fit better

### e.

> Interpret the second model from (c).
f.	Save your script/syntax for the next exercises!

## 2.

> Model the variance-covariance matrix for the Reisby dataset.

### a.

> Try different covariance pattern models (CPM) and mixed models to capture the correlation present in the dataset.

First get the observed var-covar matrix

```{r}
obs_vcov <- reisby_long %>%
  data.table::dcast(id ~ week, value.var = "hdrs") %>% 
  as.data.frame() %>% .[, -1] %>%
  var(., use = "pairwise.complete.obs")
obs_vcov

vcovs <- list(observed = obs_vcov)

obs_vcov %>% 
  data.table::melt() %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + scale_y_continuous(trans = "reverse")
```



Create mean imputed dataframe which can be used with ANOVA (not done here)

```{r}
mean_impute_vector <- function(x) {
  if (nna(x) == 0) return(x)
  x[is.na(x)] <- mean(x, na.rm = T)
  return(x)
}

mean_impute <- function(data) {
  n_missings <- nna(data)
  vars_with_missings <- names(n_missings)[n_missings > 0]
  if (length(vars_with_missings) == 0) return(data)
  data %>% mutate_at(vars(vars_with_missings), funs(mean_impute_vector))
}

reisby_imp <- mean_impute(reisby_long)
```

First model without dependence

```{r}
fit0 <- lm(hdrs ~ week * endo, data = reisby_imp)
```


```{r}
reisby_long %>%
  mutate(resid = residuals(fit0))
```

```{r}
require(nlme)
lme(fixed = hdrs ~ week * endo, random = ~ 1 | id, data = reisby_long,
    na.action = "na.omit", method = "ML") %>% summary()
```

With independent compound symmetry structure

```{r}
melt_vcov <- function(vcov) {
  if (is.list(vcov)) vcov = vcov[[1]]
  vcov %>%
    as.numeric() %>%
    matrix(., nrow = dim(vcov)[1]) %>%
    data.table::melt() %>%
    set_colnames(c("axis1", "axis2", "value"))
}
melt_vcov(obs_vcov)
```


```{r}
fit_cs <- gls(hdrs ~ week*endo, correlation=corCompSymm(form = ~ 1 | id), data=reisby_long, na.action="na.omit", method="ML")
vcov_cs <- getVarCov(fit_cs, type = "marginal")
vcov_cs

fits <- list(compound_symmerty = fit_cs)
vcovs[["compound_symmerty"]] <- vcov_cs

```

With random intercept only

```{r}
fit_ri <- lme(fixed = hdrs ~ week*endo, random = ~1|id, data = reisby_long,
              method = "ML", na.action = "na.omit")

vcov_ri <- getVarCov(fit_ri, type = "marginal")
vcov_ri

vcovs[["random_intercept"]] <- vcov_ri
fits[["random_intercept"]] <- fit_ri

```

With autoregressive residual correlation structure

```{r}
fit_ar <- gls(hdrs ~ week*endo, correlation = corAR1(form = ~1 | id),
              data = reisby_long, na.action = "na.omit", method = "ML")
vcov_ar <- getVarCov(fit_ar, type = "marginal")
vcov_ar

vcovs[["auto_regressive"]] <- vcov_ar
fits[["auto_regressive"]] <- fit_ar
```


With autoregressive residual correlation structure and heterogeneous variances

It's a bit more complicated to get the variance-covariance matrix

```{r}
fit_har <- gls(hdrs ~ week*endo, correlation = corAR1(form = ~1 | id),
                 weights = varIdent(form = ~1|week),
              data = reisby_long, na.action = "na.omit", method = "ML")
summary(fit_har)

cormat_har <- corMatrix(fit_har$modelStruct$corStruct)[[1]]
var_struct_har <- 1+c(0, as.numeric(fit_har$modelStruct$varStruct))
sigma_har <- fit_har$sigma

vcov_har <- matrix(numeric(0), nrow = 6, ncol = 6)

for (i in 1:nrow(cormat_har)) {
  for (j in 1:ncol(cormat_har)) {
    vcov_har[i, j] = sigma_har^2 * cormat_har[i, j] * var_struct_har[i] * var_struct_har[j]
  }
}
vcov_har

vcovs[["heterogeneous_AR"]] <- vcov_har
fits[["heterogeneous_AR"]] <- fit_har

```


With unstructured correlation (has the most free parameters)

```{r}
fit_unr <- gls(hdrs ~ week*endo, correlation = corSymm(form = ~1|id),
               weights = varIdent(form = ~1|week),
               data = reisby_long, na.action = "na.omit", method = "ML")

cormat_unr <- corMatrix(fit_unr$modelStruct$corStruct)[[1]]
var_struct_unr <- 1+c(0, as.numeric(fit_unr$modelStruct$varStruct))
sigma_unr <- fit_unr$sigma

vcov_unr <- matrix(numeric(0), nrow = 6, ncol = 6)

for (i in 1:nrow(cormat_unr)) {
  for (j in 1:ncol(cormat_unr)) {
    vcov_unr[i, j] = sigma_unr^2 * cormat_unr[i, j] * var_struct_unr[i] * var_struct_unr[j]
  }
}
vcov_unr

## matrix implementation, multiply scalar with (matrix, element-wise with (1d vector matrix product 1d vector (which is like tensor product)))

vcov_unr2 = sigma_unr^2 * cormat_unr * (var_struct_unr %*% t(var_struct_unr))
vcov_unr - vcov_unr2

vcovs[["unstructured_correlation"]] <- vcov_unr
fits[["unstructured_correlation"]] <- fit_unr

```




Using continous AR

```{r}
fit_car <- lme(fixed = hdrs ~ week*endo, random = ~week|id,
               correlation = corCAR1(form = ~ week | id),
               data = reisby_long, na.action = "na.omit", method = "ML")
vcovs[["continous_autoregressive"]] <- getVarCov(fit_car, type = "margin")
fits[["continous_autoregressive"]] <- fit_car

fits_reisby <- fits
```



Plot them to compare

```{r}
vcovs %>%
  map_df(melt_vcov, .id = "model") %>% 
  mutate(model = relevel(factor(model), "observed")) %>%
  ggplot(aes(x = axis1, y = axis2, fill = value)) + 
  geom_tile() + scale_y_continuous(trans = "reverse") + 
  facet_wrap(~model)
```

### b.

> Using the corMatrix() and getVarCov() functions in R (or the option Statistics – Covariance of residuals in the menu,  /PRINT=R in the syntax), we can take a look the estimated correlation or variance-covariance structures for most of the models in (a). Which structures seem more realistic for this data? Which structures seem less realistic?

### c.

> Save your script/syntax for the next exercises!

> Some tips for SPSS users:
(See the extra slides on Moodle.) 
Since we want to explicitly choose the correlation structure, we will not include a random intercept, but instead model impose a structure on the repeated observations within each patient:
Using the long version of the dataset, go to Analyze, Mixed Models, Linear. In the first screen of the Linear Mixed Models menu, put ID in Subjects and WEEK in Repeated. As Repeated Covariance Type, choose either Compound symmetry (with and without Correlation Metric), Unstructured (with Correlation Metric for interpretability), or AR(1) (with and without heterogeneous variances)
Use a fixed model with ENDO, WEEK and their interaction, and no random effects. Choose Method=ML under Estimation.


## 3.

> In this exercise we repeat the rest of the analyses of the Reisby dataset.

### a.

> Take a look at the modelled (assumed) covariance matrices for the LMEs from Exercise 1. Compare these to the observed covariance matrix of the outcomes above, and to some of the CPMs above. Which model(s) do you think best fit the observed data?

offcourse unstructured correlation but it has too many free parameters

heterogeneous autoregressive and continous autoregressive fit best from the rest

### b. 

> Re-analyze the Reisby data, using the baseline HDRS as an adjustment variable (note: you must first remove the HDRS at week = 0 from your dataset before running the mixed model!). Compare the estimates of the fixed and random effects. What changed, and what did not?


```{r}
reisby_base <- reisby_long %>%
  group_by(id) %>%
  mutate(hdrs_baseline = hdrs[week == 0]) %>%
  ungroup() %>%
  filter(week > 0)
```

```{r}
fit_har_base <- gls(hdrs ~ week*endo + hdrs_baseline,
                    correlation = corAR1(form = ~1 | id),
                    weights = varIdent(form = ~1 | week),
                    data = reisby_base, 
                    method = "ML", na.action = "na.omit")
summary(fit_har)

summary(fit_har_base)
```


## 4. (Optional)

> If you wish, go back to reisby_wide.sav and use this dataset to perform a repeated measures ANOVA. Recall the objections to this analysis from the lecture. How many subjects are used in the analysis? And what assumptions does this analysis make? How realistic are those assumptions for this study?

Skipped for now

> Tips for SPSS users:
Go to Analyze, General Linear Model, Repeated measures, type WEEK as Within Subject Factor Name , with 6 levels, and click Define. Choose hdrs.0 – hdrs.5 as Within-Subject Variables, and ENDO as Between-Subjects Factor. OK.
(Note: the results might differ slightly from those from R in the lecture notes.)


## 5.

> On page 25 of Mixed-Effects Models in R (Appendix to An R Companion to Applied Regression, Second Edition) by John Fox and Sanford Weisberg (see link on Moodle) you will find section 2.4, “An Illustrative Application to Longitudinal Data”.
In this exercise you will try to reproduce the results presented there. (Note that you can copy all commands from the article and paste them into R or RStudio.)
Concentrate only on the models and the interpretation. The anova() commands, comparing the models, may be skipped over, as may be the table on page 32 (starting at line 6). Do try out the compareCoefs() function around the middle of page 32!
Whether you choose to skip the anova() commands for now or not, please add method=”ML” to the first lme() command (since the rest of the models are “updated” from the first model, they will all be fit using ML estimation).

Get the data

```{r}
require(car)
head(Blackmore, 10)
```

### a.

> Examine the time variable (age). What is different about this time variable, compared to, say, time in the Reisby data?

```{r}
table(Blackmore$age)

nobs <- Blackmore %>%
  group_by(subject) %>%
  summarize(nobs = uniqueN(age))
table(nobs$nobs)
```

Here are the number of observations per subject.

Age is different from time in Reisby in that it is no just a relative time-indicator
to some general starting point, but the absolute value carries meaning also.

It seems to be sampled at 2 year differences, and then an in between value 
for each subject

### b.

> Why is age-8 used in the models?

To standardize

### c.

> Interpret the coefficients of the 5th model (bm.lme.5).

Reproduce:

```{r}
Blackmore %<>% mutate(log.exercise = log2(exercise + 5/60))
bm_lme_5 <- lme(fixed = exercise ~ age*group, random = ~1 | subject,
                correlation = corCAR1(form = ~age | subject),
                data = Blackmore, method = "ML")
summary(bm_lme_5)
```

Exercise seems lower in patients, and the correlation between age and 
exercise is higher in controls

Within subject variation seems higher than between subject.

correlations over time are correlated with phi = 0.73 (which is not too low I guess)

slope and intercept are negatively correlated, as is more often the case

## d.	

> Write a “statistical methods” second in which you describe, in a few sentences, how the results for the 5th model (bm.lme.5) were obtained. (For today: do not worry about explaining how you chose model 5.) Be as concise - yet complete - as possible.

Skipped for now

> Notes for SPSS users:
-	The data have been saved under blackmoor.csv. Be careful to read the subject number as a string variable, and not as numeric!
-	The log2 function does not exist in SPSS, but you can get from a loge to a log2 using the following trick: compute log2x = ln(x)/ln(2).
-	In SPSS you can save both fixed and individual predicted values. For the fixed, click on “Save” and choose under “Fixed Predicted values” the option “Predicted values”. 
-	For models 4-6: the cAR(1) correlation structure for residuals is not available in SPSS. Use the AR(1) structure (not that you will then get slightly different results). 


## 6.

> The data contained in the file stroke.csv are from an experiment to promote the recovery of stroke patients. There were three experimental groups:
A was a new occupational therapy intervention;
B was the existing stroke rehabilitation program conducted in the same hospital where A was conducted;
C was the usual care regime for stroke patients provided in a different hospital.
There were 8 patients in each experimental group. The response variable was a measure of functional ability, the Bartel index: higher scores correspond to better outcomes and the maximum score is 100. Each program lasted for 8 weeks. All subjects were evaluated at the start of the program and at weekly intervals until the end of the program. The hypothesis was that the patients in group A would do better than those in group B or C.

### a.

> Thinking about the design of the study (and without yet looking at the data), what approach(es) would you use to model this data? Think about both the fixed part of the model (to answer the research question) and the random part of the model (to account for correlated measurements).

Fixed parts: treatment and time, including interaction, and if available: baseline Bartel, age, sex
Random parts: intercept and slope (with time) by patient; we have regular time intervals, we could use them as a linear trend 

or: treat time as categorical if there is no linear relationship, then use
Correlation part: correlation on time-axis by patient
a good bet may be heterogeneous autocorrelation

### b.

> How would you treat the first Bartel index evaluation?

as a covariate

### c.

> Get descriptive statistics of the measurements and examine correlations of measurements over time.

Load data and curate

```{r}
stroke <- read.csv(here("data", "stroke_mim.csv"), sep = ",")
stroke %<>% mutate(Subject = factor(Subject))
str(stroke)
```

Let's go to long

```{r}
stroke_long <- data.table::melt(stroke, id.vars = c("Subject", "Group"),
                                variable.name = "week", value.name = "bartel")
stroke_long %<>%
  mutate(week_int = as.integer(stringr::str_extract(week, "[0-9]")))
```


```{r}
setDT(stroke_long)
stroke_long[, list(mean = mean(bartel), sd = sd(bartel)), by = "week,Group"]
```


Get the var-covariance matrix over times

```{r}
vcov_obs <- var(stroke[, 3:10])
vcov_obs 
vcov_obs %>%
  melt_vcov() %>%
  ggplot(aes(x = axis1, y = axis2, fill = value)) + 
  geom_tile() + scale_y_continuous(trans = "reverse")
```

Variance increases with time

### d. 

> Make a spaghetti plot of the data (don’t forget to restructure the data!).

```{r}
stroke_long %>%
  ggplot(aes(x = week_int, y = bartel, col = Subject, group = Subject)) + 
  geom_line() + facet_wrap(~Group)
```

Most seem to increase. 
Group A starts a little lower but shows relatively steep increase

Pretty different slopes, pretty different intercepts.

Effect is pretty much linear

### e.

> Fit the model you think would best describe the patterns in the data.

We will go for random slope and intercept, taking the first bartel as baseline

```{r}
stroke_base <- stroke_long %>%
  group_by(Subject) %>%
  mutate(bartel_baseline = bartel[week_int == 8]) %>%
  ungroup() %>%
  filter(week_int > 1)
```


Random part with both slope and intercept did not converge, so now only intercept


```{r}
fit <- lme(fixed = bartel ~ Group*week_int + bartel_baseline,
           random = ~ 1 | Subject,
           data = stroke_base,
           method = "ML")
summary(fit)
```

### f.

> Summarize and interpret the results in part (e).

Group B and C start out better than A, but Group A increases faster

Inter and intra subject variation with regards to intercept are approximately 
equal

# Day 3

> During this computer lab we will
1,2,5)	Revisit examples from earlier in the week, and do some proper model building and checking.
3)	(Optional) Try to reproduce the results from this morning’s lecture, using SPSS and/or R.
4)	Expand on the Reisby analyses using polynomial functions for time.
6)	Analyze data from a multi-center, longitudinal trial.
7)	Time permitting, examine effects of centering explanatory variables.
8)	Time permitting, take a look at a (two-level) dataset with complicated residuals.

> Note:	Exercise 1 is a re-analysis of the example from this morning’s lecture, intended to help you familiarize yourself with mixed models in SPSS and R. If you are already comfortable with the software, feel free to skip it.

## 1.

> We will re-analyze the schools data (school.sav or school.dat ) in R or SPSS according to the strategy described in the lecture: starting with the full fixed model we first test the random effects, then the fixed effects.
### a.

> Making use of the full fixed model from Day 1, test (with the likelihood ratio test) whether a random slope is necessary, or whether a random intercept model would be sufficient. Which model do you prefer?

```{r}
full_model <- lmer(normexam ~ standlrt + gender + schgend + schav + (standlrt | school), data = london,
     REML = F)
fit2 <- lmer(normexam ~ standlrt + gender + schgend + schav + (1 | school), data = london,
     REML = F)
anova(full_model, fit2)
```

Model with random slope is a lot better

### b.

> Using maximum likelihood estimation and the “random part” chosen in part (a), try to reduce the fixed part of the model by removing non-significant explanatory variables.

```{r}
fit <- full_model
drop1(fit, test = "Chisq")
```

Remove schav

```{r}
drop1(update(fit, normexam ~ standlrt + gender + schgend + (standlrt | school)), test = "Chisq")
```

Now we can't reduce the model further

```{r}
fit_final <- update(fit, normexam ~ standlrt + gender + schgend + (standlrt | school))
```


### c.

> Once you have a final model, run it one last time using REML estimation for correct parameter estimates. Interpret the results of this model.

```{r}
fit_final_reml <- update(fit_final, REML = T)
fit_final_reml %>% summary()
```

More inter school variation than between school variation.
Higher standlrt is associated with higher normexam

Gender is associated with normexam (1 = better)
School gender is associated with normexam, 2 and 3 being better

> Note: save your R script (or SPSS syntax) to re-run later! After the next part of the lecture, you will continue analyzing this dataset/model.

## 2.

> Continuing with the schools data (school.sav or school.dat ) in R and/or SPSS:

### a.	

> Check the model assumptions for the final model: are the residuals, random intercept (and random slope if you used it) (approximately) normally distributed? (Note that some of the graphs for checking model assumptions are not easily produced in SPSS; see the extra slides on Moodle for help.)

```{r}
plot(fit_final_reml)
```

Boxplot of residuals per subject / group


```{r}
london %>%
  mutate(residual = resid(fit_final_reml)) %>%
  ggplot(aes(x = school, y = residual, group = school)) + 
  geom_boxplot()
```


No structure, no heteroscedasticity

```{r}
qqnorm(resid(fit_final_reml))
```

Normal distributed residuals

Look at intercepts and slopes

```{r}
coefs <- coef(fit_final_reml)
head(coefs$school)
intercepts <- coefs$school[,1]
slopes <- coefs$school[,2]

boxplot(intercepts)
boxplot(slopes)
```

There is a single observation a deviating slope. It is the highest slope, 
so we can get the rownumber:

```{r}
which.max(slopes)
```

Look at the 53'th school

```{r}
london %>%
  filter(as.numeric(school) == 53)
```

We should look at the residuals of this school when corrected for the fixed part

We create predictions based on the beta's of the fixed part, but it's a little 
messy because we would need to properly handle the factor variables that 
should be recoded to dummy variables.

We can also take the predictions, and then add the intercept and slope

First polish up the slopes and intercepts

```{r}
betas <- fit_final_reml@beta

school_df <- coefs$school
school_df %<>%
  transmute(
    random_intercept = `(Intercept)`,
    random_slope = standlrt,
    school = 1:n())
  

london <- merge(london, school_df, by = "school", all.x = T)
london %<>% 
  mutate(predicted = predict(fit_final_reml, type = "response"),
         predicted_fixed = predicted - random_intercept - random_slope * standlrt,
         resid_fixed = normexam - predicted_fixed,
         residual = resid(fit_final_reml))
```



```{r}

london %>%
  mutate(special_school = as.numeric(school) == 53) %>% 
  data.table::melt(measure.vars = c("resid_fixed", "normexam"),
                   variable.name = "y_type") %>% 
  ggplot(aes(x = standlrt, y = value, 
             alpha = special_school, shape = special_school)) + 
  geom_point() + theme_minimal() + 
  facet_grid(~y_type)

```

We can see that this school does seem to have a steeper slope than the rest 
of the schools.

On original scale:


```{r}

london %>%
  mutate(special_school = as.numeric(school) == 53,
         residual = resid(fit_final_reml)) %>%
  ggplot(aes(x = standlrt, y = normexam, 
             alpha = special_school, shape = special_school)) + 
  geom_point() + theme_minimal()

```




## 3. (Optional) 

> Repeat this morning’s analysis of the Reisby data in R or SPSS (or both). Choose the best model, check model assumptions, and interpret the results of the best model. SPSS users will find slight discrepancies between R and SPSS (for unstructured, AR(1) and heterogeneous AR(1) models), but overall conclusions remain the same.

> Note: save your R script (or SPSS syntax) for use in the next exercise!.

Luckily, we saved the fits in a list

```{r}
names(fits_reisby)
```

All these models share the same fixed part, so we can go ahead and compare the 
random parts. All were fitted with ML

```{r}
fits <- map_df(fits_reisby, function(fit) data.frame(fit = I(list(fit)), 
                                             aic = AIC(fit)), .id = "model")
fits
```

AIC of continous autoregressive is crearly best.

Let's reduce the fixed part of this fit

```{r}
fit1 <- fits %>% filter(model == "continous_autoregressive") %>% pull(fit) %>% .[[1]]
fit2 <- update(fit1, fixed = hdrs~week + endo)
fit3 <- update(fit2, fixed = hdrs~week)
anova(fit1, fit2, fit3)
```

We can leave out the interaction and the overall term endo

## 4.

> In this exercise we will consider a possible quadratic effect of time in the Reisby example. You may choose whether you use R or SPSS.

### a.

> Based on the spaghetti plots of the data (see the spaghetti plots on Day 2) one might suspect it is too simplistic to assume that the change across time is linear. Perhaps the trend in time is curvilinear? Test (with the likelihood ratio test) whether adding a fixed quadratic time parameter would improve the model. (Note: when using a quadratic term for time along with the linear term, it is better to first center time.)

```{r}
reisby_long %<>%
  mutate(week_center = week - diff(range(week)) / 2)

fit_lin <- lme(fixed = hdrs ~ week_center,
                 random = ~ week_center | id,
                 # correlation = corCAR1(form = ~ week_center | id),
                 data = reisby_long, na.action = "na.omit",
                 method = "ML")

fit_quadr <- lme(fixed = hdrs ~ week_center + I(week_center^2) ,
                 random = ~ week_center | id,
                 # correlation = corCAR1(form = ~ week_center | id),
                 data = reisby_long, na.action = "na.omit",
                 method = "ML")

drop1(fit_quadr, test = "Chisq")
```

Quadratic can be left out without hurting model fit

### b.

> Would the model be improved if we also postulate that the quadratic time parameter individually deviates from average (i.e. is also random)?

```{r}
reisby_long %<>% mutate(week_center_sqr = week_center^2)

fit_quadr2 <- lme(fixed = hdrs ~ week_center + week_center_sqr,
                 random = ~ week_center + week_center_sqr | id,
                 # correlation = corCAR1(form = ~ week_center | id),
                 data = reisby_long, na.action = "na.omit",
                 method = "ML")

# fit_quadr2_car <- lme(fixed = hdrs ~ week_center + week_center_sqr,
#                  random = ~ week_center + week_center_sqr | id,
#                  correlation = corCAR1(form = ~ week_center + week_center_sqr | id),
#                  data = reisby_long, na.action = "na.omit",
#                  method = "ML")

drop1(fit_quadr2, test = "Chisq")

anova(fit_lin, fit_quadr, fit_quadr2)

summary(fit_quadr2)
```

Quadratic with quadratic term in random part fits th edata better than 
with only linear term

### c.

> The results of this last model suggest that although the trend across time is essentially linear at the population level, it is curvilinear at the individual level. Can you explain this phenomenon?

Some patients may 'wiggle-up' while others will 'wiggle-down', which may 
smooth out the overall 'wiggling' to a linear trend

## 5.

> Part b of this question will be used in the quiz this afternoon. Please save the output and have it on hand (together with this exercise) when you complete the quiz.

> Take another look at the crossover study (crossover.sav and crossover.dat) from Day 1.

Read in data and curate

```{r}
bpco <- read.table(here("data", "crossover.dat"), header = T)
bpco %<>% 
  set_colnames(tolower(colnames(bpco)))

factor_vars <- c("period", "drug")
bpco %<>% mutate_at(vars(factor_vars), funs(as.factor))

str(bpco)
```


### a.

> Check the assumptions for the model from exercise 5b on Day 1.

b. was: 

> Fit a model to the data, looking at drug and period effect and correcting for the fact that (most) patients have more than one DBP measurement. Which variable(s) do you choose as random?


```{r}
fit <- lmer(y ~ drug + period + (1 | patient), data = bpco, REML = F)
fit %>% summary()
```

Normal distribution of residuals:

```{r}
qqnorm(resid(fit))
```

Pretty o.k.

Check outliers of random terms

```{r}
intercepts <- coef(fit)$patient[,1]
boxplot(intercepts)
```

Seems ok

Check distribution of residuals within patients

```{r}
bpco %>%
  mutate(residual = resid(fit)) %>%
  ggplot(aes(y = residual, x = patient, group = patient)) + 
  geom_boxplot()
```

Patient 11 seems to have quite extreme residuals

There is no linear effect of time assumed in the model, so it does not make sense to 
check for this assumption.

### b.

> Use this dataset to answer the questions: is there a significant difference between the two drugs, and is there a significant period effect? Begin with the full model from part (a), and reduce the model (if possible) by removing the least significant explanatory variable(s). Use the likelihood ratio test (and maximum likelihood estimation) to test. 

```{r}
drop1(fit, test = "Chisq")
```

Period can be left out

```{r}
fit <- update(fit, y ~ drug + (1 | patient))
drop1(fit, test = "Chisq")
```

We cannot remove 'drug' from the model without hurting model fit, it needs to stay 
in. 

There is a significant effect of the drug on the outcome, according to the LRT

## 6.

> On day 1 and in the morning session we looked at a multi-center, randomized, double-blind clinical trial to compare three treatments for hypertension (on Monday we only looked at 2). One treatment was a new drug (A = Carvedilol) and the other two were standard drugs for controlling hypertension (B = Nifedipine, C = Atenolol). Twenty-nine centers participated in the trial and patients were randomized in order of entry. One pre-randomization and four post-treatment visits (at weeks 3, 5, 7 and 9) were made. We would like to see if there is a difference among the three treatments. The data can be found in the file bp.csv. Read the data into R or SPSS. The research question is which of the medicines (treat) is more effective in reducing DBP. Since baseline (pre-randomization) DBP (dbp) will likely be associated with post-treatment DBP, we wish to include it here as a covariate. 

Read in data and curate

```{r}
bp <- read.csv(here("data", "bp.csv"))
factor_vars <- c("patient", "center", "treat")

bp %<>% mutate_at(vars(factor_vars), funs(as.factor))
str(bp)
nna(bp)
```

We seem to have 288 unique patients (not 29), but we have the 3 treatments 
and the dbp outcomes, so probably this is the dataset we need

No missing values, which is nice

### a.

> First fit a two-level model, examining the effects of treatment, time and their interaction, while adjusting only for multiple measurements per person by including a random intercept and random slope per patient. Use ML estimation.

Since visit is measured in weeks, we can model is as continous

```{r}
fit1 <- lme(fixed = dbp ~ treat*visit,
            random = ~ visit | patient,
            data = bp, method = "ML")
summary(fit1)
```

### b.

> Now fit a three-level model, examining the effects of treatment, time and their interaction, including a random intercept and random slope per patient and a random intercept per center. Use ML estimation.
Note: R users will perhaps find it easier to switch the the lmer function in the lme4 package, allowing one to add random effects per level using + (effect|level) to the equation.
SPSS users will need to use the syntax for this. Paste the syntax from part (a) and add an extra RANDOM statement:
/RANDOM=INTERCEPT | SUBJECT(center) COVTYPE(ID)
Both: if you get stuck, see the code on Moodle.

```{r}
fit2 <- lmer(dbp ~ treat * visit + (visit | patient) + (1 | center),
             data = bp, REML = F)
summary(fit2)
```

### c.

> Compare the two models using the likelihood ratio test. Is the random intercept per center significant? Should you base your decision to include the intercept on this outcome?

Switch fit1 to lmer too to make the anova function work

```{r}
fit1 <- lmer(dbp ~ treat*visit + (visit | patient),
             data = bp, REML = F)
anova(fit1, fit2)
```

Dropping the intercept per center would decrease the model fit significantly.

This is an argument to keep it in. However you can also argue to just keep it 
in based on the design of the study

### d. 

> Try to reduce the fixed part of the model: is the interaction significant? Is there a treatment effect? Is there a time effect?

Let's continue with fit2

```{r}
drop1(fit2, test = "Chisq")
```

We can drop the interaction

```{r}
fit2 <- update(fit2, dbp ~ treat + visit + (visit | patient) + (1 | center))
drop1(fit2, test = "Chisq")
```

We should keep in treat.

So there is a difference in treatments, and a time-effect

### e.

> Run the final model once more using REML estimation. See if you can get some post-hoc tests of treatments (hint: EMMEANS statement in SPSS. In R, the package lmerTest contains the useful functions lsmeans() and difflsmeans(). If you get stuck, you can look at the R script provided on Moodle).

```{r}
fit2_reml <- update(fit2, REML = T)
summary(fit2_reml)
```

```{r}
require(lmerTest)
difflsmeans(fit2_reml)
```

### f. 

> Interpret the results.

Using the post-hoc test, there is a significant difference between treatments 
A and C, but not between the other treatments

##7.

> Centering the explanatory variables is a major topic in mixed models. (See for example the evaluation review of Omar Paccagnella “Centering or Not Centering in Multilevel Models? The Role of the Group Mean and the Assessment of Group Effects”.) In this exercise we will demonstrate the consequences of centering. Consider again the longitudinal data example of the paper by John Fox (see exercise 3 of Day 2), stored in blackmoor.csv or available as Blackmore in the car package. 

```{r}
data("Blackmore")
str(Blackmore)
bm <- Blackmore
nna(bm)
```

This one is nicely curated. Factor variables are coded as such, and the data 
is nice and long. No missings

### a.

> Fit a model with random intercept, random age effect, fixed group and a fixed interaction between age and group. Don’t forget the transformation of the outcome! Make a table of the most important parameter estimates.

```{r}
bm %<>% mutate(log_exercise = log2(exercise + 5/60))
fit1 <- lme(fixed = log_exercise ~ group*age,
            random = ~ age | subject,
            data = bm, method = "ML", na.action = "na.omit")
fit1 %>% summary()
```

We can print the random effects, but to get them as a numeric vector is pretty 
hard (they are 'well' hidden in the fit-object).

Inspecting the code of nlme:::print.lme should brings us to the answer but takes 
too long for now

We try to get them ourselves but it doesn't help

```{r}
(var(coef(fit1)[, c(1,3)]))
```

This is actually a little troubling

We can get the fixed coefficients and the sigma easily

```{r}
fit1$coefficients$fixed
fit1$sigma
```


### b.

> Repeat the analysis but first transform the age to age-8. Extend the table of (a) with the new estimates. 

```{r}
bm_shift <- mutate(bm, age = age - 8)
fit2 <- update(fit1, data = bm_shift)
```

There is a handy function for the fixed part:

```{r}
compareCoefs(fit1, fit2)
```

Intercept changes, which makes sense, not the linear effect of age, 
nor the interaction. Grouppatient also changes

### c.

> Repeat the analysis again but now transform the age to the deviation from the mean age (i.e. centering to the mean). Extend again the table with the new estimates (R users should recall the compareCoefs() function from yesterday).

```{r}
bm_center <- mutate(bm, age = age - mean(age))
fit3 <- update(fit1, data = bm_center)
compareCoefs(fit1, fit2, fit3)
```

Again the intercept and group effects change, but not the slopes

### d.

> Compare the results of these three models and explain the differences and similarities (Hint. Use something like figure 9 of the Fox & Weisberg paper).

Left for now

### e.

> Which model would you prefer? Explain your choice.

Skipped for now

## 8. (CHALLENGE EXERCISE)

> Kroesbergen et al. (Eur Respir J 1999) investigated the flow-dependency of exhaled nitric oxide (NO) in healthy children (n=20) and children with asthma (n=19). The concentration of NO in exhaled are was measured four times, at four different target values of the flow of exhalation (2, 5, 10, and 20% of their vital capacity per second). The actual flows differed from the target flows. 
The following questions are addressed: is there is an association between NO (pbb) and FLOW (L/sec) for healthy and asthmatic children? Is this association different for the two groups? The variables NO and FLOW have been been log-transformed.

> The dataset no.dat. contains the following variables:

> NUM	child’s identification number
DIAGNOSE	0 = “healthy” and 1 = “asthma”
FLOW	10log(flow)-10log(2)  
NO	10log(NO concentration)

### a. 

> Describe what you see in the graphs. What would be your first impression with respect to the research questions?

Seems like a clear association betheen NO and flow in both groups.

More variace in NO in asthma group, and steeper slope (more negative)

### b.

> In R, fit a model with random intercept random slope regression for the healthy group. What is the mean slope and intercept? What are the estimated variances of the random components? Is a random slope model necessary, or would a random intercept be sufficient? 

```{r}
no <- read.table(here("data", "no.dat"), header = T)

factor_vars <- c("num", "diagnose")
no %<>% mutate_at(vars(factor_vars), funs(as.factor))

str(no)
```

Reproducing the plot from the word-file

```{r}
no %>%
  ggplot(aes(x = flow, y = no, group = num)) + 
  geom_line() + geom_point() + 
  facet_grid(~diagnose) + theme_minimal()
```



```{r}
fit1 <- lme(fixed = no ~ flow,
            random = ~ flow | num,
            data = filter(no, diagnose == "0"),
            method = "ML")
summary(fit1)
```

See random effects for the SD's of the effects

```{r}
fit2 <- update(fit1, random = ~ 1 | num)
anova(fit1, fit2)
```

The AIC is negative here which is a little unusual, but the lower AIC 
(more negative) from fit1 indicates fit1 is better

### c.

> Answer the same questions for the group of children with asthma.

```{r}
fit1_a <- update(fit1, data = filter(no, diagnose == "1"))
fit2_a <- update(fit1_a, random = ~ 1 | num)
anova(fit1_a, fit2_a)
```

Again the model with random slope is better

### d.

> Compare the results of the two groups. What would you conclude on the basis of these results?

```{r}
summary(fit1)
summary(fit1_a)
```

With regards to the random part: 
there is greater variation in slopes and intercepts for the asthmatic group,
which is in accordance with the plot

```{r}
compareCoefs(fit1, fit1_a)
```

For the fixed parts, the intercept is a little higher in the asthmatic group,
and their slopes are more negative

### e. 

> Fit a model for the two groups combined, using an interaction for diagnosis*flow and allowing a different covariance structure for the two groups (note: as far as we know, this cannot be done in SPSS; in R, use the following command:)
no.lme.3 <- lme(no~flow + factor(diagnose)+ flow:factor(diagnose), random=~flow + diagnose + flow*diagnose| num,  weights=varIdent(form=~1|diagnose), method="ML", data=nodat)

```{r}
fit3 <- lme(fixed = no ~ flow * diagnose,
            random = ~ flow * diagnose | num,
            weights = varIdent(form = ~1|diagnose),
            method = "ML", data = no)
summary(fit3)
```

> The random command contains a term for group, flow and the group*flow interaction and thus allows for a separate variance for the random intercept and slope for the two diagnosis groups. The weights statement further allows differing residual variances for the two groups. Check that the log-likelihood of this model is the sum of the log-likelihoods of the models in b and c.

```{r}
logLik(fit1) + logLik(fit1_a)
logLik(fit3)
```

It's the same, awesome

### f.

> Can the variance structure be simplified by assuming equal residual variances? (Hint: try removing the weights statement.)


```{r}
anova(fit3, update(fit3, weights = NULL))
```

Yes, the difference is not statistically significant

### g. 

> Can the covariance structure be further reduced? Try to simplify the random command by removing the diagnose*flow interaction, and then by removing diagnose.

```{r}
fit <- update(fit3, weights = NULL)
anova(fit, update(fit, random = ~diagnose + flow | num))
```

No significant decrease, so throw out interaction

```{r}
fit <- update(fit, random = ~ diagnose + flow | num)
anova(fit, update(fit, random = ~ flow | num))
```

We cannot drop the diagnosis random slope, so let's keep this one in

### h.

> Is the fixed diagnose*flow interaction necessary? In other words: do the asthmatic children indeed have a significantly more negative slope than the healthy children?

```{r}
drop1(fit, test = "Chisq")
```

Yes, there is a significantly different slope on a group level.

### i.

> Answer the following questions for the model you end up with. What is the slope for the healthy group, what for the asthma group? What is the standard deviation of the random intercept the healthy children, and is the variance for asthmatic children larger or smaller? What is the residual standard deviation for the two groups?

```{r}
summary(fit)
```

slope healthy = -0.345
slope asthma = -0.345 - 0.239 = (`r -.345 - .239`)

sd of random intercept healthy: 0.165

From the summary of the separate fit for asthmatic children, 
we see that the variance in intercept is higher. 

I don't know how to properly combine the numbers from the random effects here.
I'm inclined to add the sd of 'diagnose1' to the intercept, but the numbers 
don't add up.

Residual sd = 0.058

## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
