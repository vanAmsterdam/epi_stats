---
title: "Categorical Data"
author: "Wouter van Amsterdam"
date: 2017-11-02
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->
## Introduction
Tutor: Rebecca Stellato

Tests

* Binomial test vfor 1 proportion
* McNemar test for paired data
* Pearson's chi-square for difference in 2 proportions or for contingency tables in general
* Fisher's exact test for 2x2 (or other contingency) table

Confidence intervals

* Normal approximation ("Wald")
* Agresti-Coull improvement to Wald

## Binomial distribution
Assuming:

* independent observations

$$X \sim Bin(n, \pi)$$

$$P(X = x) = {{n}\choose{x}}p^{x}(1-p)^{n-x}$$

With

$${{n}\choose{x}} = \frac{n!}{x!(n-x)!}$$


Binomial distrubution is approximated by normal distribution with
$$\mu = np$$
$$\sigma_2 = np*(p-1)$$

### Binomial test
$$H_0 = p = p_0$$
For a given value, e.g. $0.5%

* one-sided p-value = $P(X \geq x | p_0)$
* two-sided p-value $leq 2*min{P(X \leq x | p_0), P(X \geq x | p_0)}$

Note that the the distribution is only symmetric for $p_0 = 0.5$.

P-value is directly calculated from the distribution.


### Confidence interval
#### Wald confidence interval
$$\hat{p} \pm Z_{\alpha(2)}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$
Has bad coverage

#### Agresti-Coull confidence interval (adjused wald)
Add 2 successess and 2 failures (for 95%-confidence interval)

$r' = r + \frac{Z_{\alpha(2)}^2}{2}$;  $n' = n + Z_{\alpha(2)}^2$;  $\hat{p}' = r'/n'$

This moves the estimate a little closer to 0.5. Most usefull for extreme p-values.

Has better coverage. Report $p$ and the confidence interval based on $r'$ and $n'$.

**consider some simulation examples**

### McNemar test: paired proportions

. | test B + | test B - 
---| ---- | ---
test A + | 20 | 12
test A - | 2 | 16

Test only the discordant paires. They should be equal.

$H_0$: discordant pairs are equal


$p = A_+ / B_-$ or $p = A_- / B_+$
Sample size is sum of discordant pairs
Use binomial distribution with 2-sided p-value

Concordant pairs do not matter, all are discarded.

Confidence interval has little meaning. Check McNemar Odds-ratio, it has a 
confidence interval.


### Chi-squared test: unpaired proportions

Drug | Case | Control
---|---|---
used|71|208
no use|84|173

Difference in proportions: $71/(208+71)$, $84/(173+84)$

#### Wald
$$\hat{p_1-p_2} \pm Z_{\alpha(2)}\sqrt{\frac{\hat{p_1}(1-\hat{p_1})}{n_1} + \frac{\hat{p_2}(1-\hat{p_2})}{n_2}}$$

#### Agresti-Coull
Add 1 success and failure in each group.
$r_i' = r_i + \frac{Z_\alpha(2)^2}{4}$;  $n_i' = n_i + \frac{Z_{\alpha(2)}^2}{2}$

#### Newcombe/Wilson method
Is best way. 
Single proportion: `binom::binom.confint(..., method = "wilson")`
Difference between proportions: `Epi::ci.pd(..., method = "Nc")`


## Chi-square test
Test association / difference in a contingency table (2x2 or IxJ)

Drug | Case | Control
---|---|---
never use|71|208
past use|22|53
current oral use|32|27
current transdermal use|30|93

Null hypothesis is statistical independence:

$$P(A = a_i \& B = b_i) = P(A=a_i)*P(B=b_i)$$

$$E_{ij} = \sum_{j}{O_{ij}} * \sum_{i}{O_{ij}} / n$$

$$T = \sum_{i=1}^I\sum_{j=1}^J\frac{(O_{ij}-E_{ij})^2}{E_ij}$$
Difference between expected and observed in a cell, divided ('normalized') 
by the total numer 
of expected

T is asymptotically chi-square distributed with $(I-1)*(J-1)$.
E.g. in a 2x2 table, given marginal probabilities, filling in 1 cell will fix 
all other cells.
E.g. in a 3x2 table, filling in 2 cells will fix all other cells
E.g. in a 3x3 table, filling in 4 cells will fix all other cells

It is a two-sided test, although you are always on one side of the distribution.

```{r}
my_chisq_function <- function(df) {
  f = function(x) pchisq(q = x, df = df, lower.tail = T)
  return(f)
}
my_chisq <- my_chisq_function(df = 3)

curve(my_chisq, xlim = c(1,30))
```

Rejecting the null hypothesis does not tell you which ratio is actually different.

You can make a series of 2x2 tables as a 'post-hoc' analysis. 
Usually it does not happen. There is no standard way to do this.

#### Assumptions

Theory: all expected values $E_{ij} \geq 5$
Practice: 75% of the $E_{ij}$ should be larger than 5
Otherwise use Fisher exact test

#### Other uses

* Cross-sectional: presence of A and B in all patients
* Case-control: proportion of trait in cases / controls
* Randomized controlled trial

```{r}
set.seed(2)
n = 15
p_flip = 0.2
myData <- data.frame(
  id = 1:n,
  a  = sample(c(T,F), replace = T, size = n)
)
myData$b <- myData$a
flippers <- sample(1:n, size = p_flip*n, replace = F)
myData$b[flippers] <- !myData$b[flippers]

myData
xtabs(~a+b, data = myData)
chisq.test(xtabs(~a+b, data = myData))
fisher.test(xtabs(~a+b, data = myData))
```

## Fisher exact test
For contingency tables with low counts

* Calculate the probability ($p_0$), using the hypergeometric distribution
* Calculate the probabilities for every possible value of t (where row and column totals remain the same)
* Take sum of all probabilities which are smaller or equal to the probability $p_0$ 

## Measures of association in a 2x2 table
Chi-square test will give statistical significance of rate differences

Odds ratios and relative risks will provide estimates of the effect size.

## Sample size for proportion
### Two un-paired proportions
$$n \geq \frac{(Z_{\alpha}\sqrt{2\bar{p}(1-\bar{p})} + Z_{\beta}\sqrt{p_1(1-p_1)+p_2(1-p_2)})^2}{\delta^2}$$

With $\bar{p} = \frac{p_1+p_2}{2}$; $\delta = p_2 - p_1$;

Note: $n$ is an underestimation of the number needed.

### Two paired proportions
There is a way to do this for paired data (McNemar).

$$n = f_{11} + f_{12} + f_{21} + f_{22}$$
$$p = min(\frac{f_{12}}{n}, \frac{f_{21}}{n})$$
$$\Psi = max(\frac{f_{12}}{f_{21}}, \frac{f_{21}}{f_{12}})$$


$$n \geq \frac{(Z_{\alpha}\sqrt{\Psi + 1} + Z_{\beta(1)}\sqrt{(\Psi+1)-p(\Psi-1)})^2}{p(\Psi-1)^2}$$







## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
