---
title: "Assignments Week 1"
author: "Wouter van Amsterdam"
date: 2017-10-23
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->

## Day 1
### 1. Left-handedness, binomial distribution
> In a population 10% of the individuals is left-handed. We draw a random sample of 20 people from this population and indicate with X the number of “left-handers”. We will calculate the following binomial probabilities with SPSS and R:
$P(X = 0), P(X = 1), P(X < 3), P(X >3)$.

This question regards the binomial distribution, which for a sample of size $n$, with probability $p$, is given by

$P(X=x) = {n \choose x}*p^{x}*(1-p)^{n-x}$

$P(X = 0)$ and $P(X = 1)$ are probabilities for a single value, so density is what we need:
```{r}
dbinom(x = c(0, 1, 2), size = 20, p = .1)
```

$P(X < 3)$ and $P(X > 3)$ concern quantiles:
```{r}
pbinom(q = 2, size = 20, p = 0.1)
pbinom(q = 4, size = 20, p = 0.1, lower.tail = F)
1-pbinom(q = 4, size = 20, p = 0.1)
```

Note that
```{r}
pbinom(q = 2, size = 20, p = 0.1)
sum(dbinom(x = c(0,1,2), size = 20, p = 0.1))
```


Plot all probabilities
```{r}
x_seq = 0:20
densities <- dbinom(x = x_seq, size = 20, p = 0.1)
plot(x_seq, densities, ylim = c(0,1))
```

### 2. Elevator weight limit
> A notice in an elevator states that it can carry up to 16 people, with a total weight of 1240 kg. A random sample of 16 people from a distribution with a mean of 72 kg and a standard deviation of 12 kg gets into the elevator. What is the probability that these people weigh more than 1240 kg?

First calculate the standard deviation of the sum of the weights of 16 people

$\sigma_{total} = \sqrt{n}*\sigma_{population}$

```{r}
n = 16
mu = 72
sigma = 12
sigma_total = sigma * sqrt(n)
sigma_total
```

Then calculate the probability of exceeding 1240 kg with 16 people.

```{r}
pnorm(q = 1240, mean = n * mu, sd = sigma_total, lower.tail = F)
```

See if this matches the results of a simulation
```{r}
nsim = 10000
set.seed(2)
x <- matrix(rnorm(n = n * nsim, mean = mu, sd = sigma), ncol = nsim)
totals <- colSums(x)
hist(totals)
abline(v = 1240, lty = 2)
1 - ecdf(totals)(1240)
```

### 3. Excercises in SPSS
Skipped

### 4. Excercises in R
> In this exercise we will assess whether sample data appear to be normally distributed. Load the library ISwR and open its built-in dataset `rmr`: 

```{r, message = F, warning=F}
library(ISwR)
data(rmr)
# help(rmr)

```

> a.	Get some information about the dataset, using `summary(rmr)`
```{r}
summary(rmr)
```

> b.	Make a boxplot of the metabolic rate: `boxplot(rmr$metabolic.rate)`
> Does it look symmetric? Are there any (extreme) outliers?

```{r}
boxplot(rmr$metabolic.rate)
```

It looks pretty symmetric, with a single large outlier

> Make a histogram of the variable `metabolic.rate`:

```{r}
hist(rmr$metabolic.rate, freq=FALSE)
```


> The option `freq=FALSE` is used here to indicate that, rather than setting out the frequencies on the vertical axis, the densities (“relative frequencies”) are plotted, which results in a histogram with total area equal to 1. This puts it on the same scale as the curve of the normal distribution that we want to add next.
> c.	A best-fitting normal curve can be added as follows. First store the mean and the standard deviation of height in two variables, for example in `m` and `s`, then pass `curve(dnorm(x,m,s),add=TRUE)`

```{r}
hist(rmr$metabolic.rate, freq=FALSE)
m <- mean(rmr$metabolic.rate)
s <- sd(rmr$metabolic.rate)
curve(dnorm(x,m,s),add=TRUE)
```


> d.	Does the variable metabolic.rate appear to be normally distributed?

looks pretty normal

> e.	Create a new variable, `lrate`, that is the natural logarithm of `metabolic.rate`  and repeat parts b) and c) for this new variable.

```{r}
rmr$lrate = log(rmr$metabolic.rate)
```

> f.	With which variable would you prefer to work, the original or the transformed one?

The original variable is already pretty normaliy distributed, so transformation is not necessary here, and creates superfluous additional steps for interpretation.

### 6. Q-Q plot
> In this exercise we will build a normal Q-Q plot of the variable `metabolic.rate` from the `rmr` dataset. It assumes that you have already done the previous exercise and that its resulting objects are still available in the R workspace.
> a.	To get a normal Q-Q plot in R, simply type `qqnorm(rmr$metabolic.rate)`. To help you judge whether the points are on a straight line you could add the best fitting line to the plot with the command `abline(m,s)`. (Make sure that m and s are the mean and SD of the original data.) What does this command do, and why does it make sense here?

```{r}
qqnorm(rmr$metabolic.rate)
abline(m, s, col = "red")
```

#### Explanation
This command with `abline(..` creates an intercept line which follows $y = a + b*x$. In the case of the Q-Q plot, on the $y$-axis the measured quantity is shown, on the $x$-axis the number of standard deviations away from the mean. When the variable is normally distributed, it will follow $y = \mu + quantile*\sigma$. This corresponds with the plotted 'abline' when $a =\mu$ and $b = \sigma$. In the Q-Q plot, the actually measured quantities are ordered from low to high. It is expected that most of the measured values will be somewhere around the mean, while only few will be on the extreme ends of the distribution. To be exact, `pnorm(x)` of the observations are expected to have a value of $<x$. Conversely, the $n$ lowest observations are expected at `qnorm(p = n / nTotal, mean = mu, sd = sigma)`, which is equivalent to a $Z$-value of `qnorm(n / nTotal)`. Where

$Z = \frac{x - \mu}{\sigma}$

So the number of standard deviations away from the mean.

For an illustration of this explanation, read the following code.

> b.	To better understand its meaning, we will build it up ourselves:

```{r}
s.meta <- sort(rmr$metabolic.rate)
n <- length(rmr$metabolic.rate)
index <- ((1:n)-0.5)/n
q.index <- qnorm(index)
```

> We will now plot our own Q-Q plot next to the one from R.

```{r}
par(mfrow=c(1,2)) #plots two graphs in 1 row and 2 columns, so next to each other
qqnorm(rmr$metabolic.rate)
plot(s.meta~q.index)
par(mfrow=c(1,1)) #back to one graph (so in 1 row and 1 column)
```


> Try and explain what each line does, and why this results in the desired Q-Q plot.

> c.	Logarithmically transform the metabolic rate data, and redo part b.

```{r}
qqnorm(log(rmr$metabolic.rate))
m_log = mean(log(rmr$metabolic.rate))
s_log = sd(log(rmr$metabolic.rate))
abline(m_log, s_log, col = "red")
```

Not much difference

Adding a few cases on the lower end of the distribution will change the Q-Q plot drastically.

```{r}
par(mfrow = c(1,2))
qqnorm(rmr$metabolic.rate)
qqline(rmr$metabolic.rate, col = "red")

qqnorm(c(rep(500, 20), rmr$metabolic.rate))
qqline(c(rep(500, 20), rmr$metabolic.rate), col = "red")

par(mfrow = c(1,1))
```

## Day 2. Estimating with uncertainty
### Excercises without SPSS or R
>1.	The following sample represents systolic blood pressure measurements for six patients: 121, 130, 127, 142, 139, 115
a.	Using your pocket calculator and suitable tables, compute a 95% confidence interval for the mean blood pressure in the population.
b.	Test at a confidence level of 95% the hypothesis that in the population the mean is 120.

$$n = 6$$
$$mean = (130+127+142+139+115+121)/6 = 129$$
$$sd^2 = (1+2^2+13^2+10^2+14^2+8^2)/(6-1) = 106.8$$
$$sd = 10.33$$
$$SE = \frac{10.33}{\sqrt{6}} = 4.219$$

Grab critical value from T-table with 5 degrees of freedom, at 0.025: 2.571 (which equals the R-command `qt(p = .025, df = 5)`). 

Then the 95% confidence interval is 
$$mean \pm SE*2.571 = {118.2, 139.8}$$

Which equals:
```{r}
t.test(c(130,127,142,139,115,121))$conf.int
```

> 2.	Researchers often compute intervals as estimates of population means. Since these are calculated based on sample data you cannot be sure that such an interval will really cover the population mean. But you can tell the probability with which this will be the case. A common value for this probability is 0.95. Suppose that a scientist carries out 20 independent studies where he computes a single 95% confidence interval every time.
a.	What is the probability that all intervals will cover the true population mean?
b.	What is the probability that one CI will not cover the true mean? And for two CI’s?
(Source: R.G.D. Steel & J.H. Torrie, Principles and procedures of statistics, a biometrical approach, McGraw-Hill, International student edition).

For each study, the chance of coverage is 95% ($p=0.95$), and each study is assumed to be independent of each other, and based on the same population (so independent and identically distributed, i.i.d.)

Then
$$P(n_{no\ coverage}=0) = p^{20} = `r round(.95^20, 3)`$$

For 1 confidence interval not covering the true mean:
$$P(n_{no\ coverage}=1) = {20 \choose 1} * p^{19}*(1-p)^1 = `r round(choose(n = 20, k = 1)*.95^19*.05, 3)`$$


For 2 confidence intervals not covering the true mean
$$P(n_{no\ coverage}=2) = {20 \choose 2} * p^{18}*(1-p)^2 = `r round(choose(n = 20, k = 2)*.95^18*.05^2, 3)`$$

> 3.	
a.	Use the data from exercise 1 to construct 90%, 96% and 99% confidence intervals for the mean blood pressure in the population. Use the T distribution from  http://homepage.stat.uiowa.edu/~mbognar/ to get the correct critical values for the confidence intervals by filling in the appropriate degrees of freedom and the left- or right-tail probability and pressing Esc.
b.	Use the table of the t-distribution on Moodle (under Introductory matters, Tables) to confirm the critical values for the 90% and 99% confidence intervals. Can you use this table for a 96% confidence interval?

Left for the reader. Same as a. but using different critical values of the t-distribution

### Excercises in SPSS
Not covered here

### Excercises in R

>8.	Open the built-in dataset faithful in R (by typing data(faithful) )
a.	Get some information about the dataset using the command:
help(faithful)

```{r}
data(faithful)
# help(faithful)
```

> b.	The dataset contains the variables eruptions and waiting. Make QQ-plots of both these variables.

```{r}
qqnorm(faithful$eruptions)
qqline(faithful$eruptions, col = "red")
qqnorm(faithful$waiting)
qqline(faithful$waiting, col = "red")
```

Both are not very normally distributed

> c.	Make a histograms of the variables eruptions and waiting together with their normal curves.
For this, create a function that returns a function with the normal distribution for a given $\mu$ and $\sigma$.

```{r}
norm_function <- function(mu, sd) {
  f = function(x) (1/(sd*sqrt(2*pi)))*exp(-(x-mu)^2/(2*sd^2))
  return(f)
}

hist(faithful$eruptions, freq = F)
my_norm <- norm_function(
  mu = mean(faithful$eruptions), 
  sd = sd(faithful$eruptions))
curve(my_norm, min(faithful$eruptions), max(faithful$eruptions), add = T, col = "red")

hist(faithful$waiting, freq = F)
my_norm <- norm_function(
  mu = mean(faithful$waiting), 
  sd = sd(faithful$waiting))
curve(my_norm, min(faithful$waiting), max(faithful$waiting), add = T, col = "red")
```

> d.	Is it reasonable to assume normality for the variables eruptions and waiting?

Based on the plots, no.

> 9.	(This is a repeat of Exercise #7, but now in R.) Check the central limit theorem by carrying out the following steps:
a.	Create six variables a, b, c, d, e and f , each of length 200, like this:

```{r}
a <- runif(200)
b <- runif(200)
c <- runif(200)
d <- runif(200)
e <- runif(200)
f <- runif(200)
```

Note that the `runif` function generates random numbers from a uniform distribution with mimimum 0 and maximum 1.

> b.	Combine the six shorter variables in one long variable x like this:

```{r}
x <- c(a,b,c,d,e,f)
```

> Check the variable x for normality.

```{r}
hist(x)
qqnorm(x)
qqline(x, col = "red")
```


> c.	Create a variable of 200 means of samples of size 6 like this:

```{r}
m <- (a+b+c+d+e+f)/6
```

> (Note that the first elements of variables a-f form one sample, whose mean will be the first element of m, etc.)
Check this sequence of means m on normality.

```{r}
hist(m)
qqnorm(m)
qqline(m, col =  "red")
```


> d.	Compare the results in b) and c) in the light of the central limit theorem.

The variable `x` is not normally distributed. Instead, it is distributed like the distribution it was drawn from, namely the uniform distribution. However, when taking means of 6 draws from this distrubtion, these means themselves are a random variable, which by the central limit theorem is known to be approximately normally distributed.


> 10.	The aim of this exercise is to make you “feel” the central limit theorem.
a.	In your workspace, create an object pop containing the numbers 1, 2, . . . , 8.

```{r}
pop <- 1:8
```

From this population of size 8, samples of size 5 are drawn with replacement. There are 85 = 32768 such samples possible. A complete list of all these samples can be retrieved by loading the dataset samples.RData. (Use File, Load workspace…)

```{r}
load(epistats::fromParentDir("data/samples.RData"))
```


b.	Load the dataset samples.RData. This will create a 32768x5-matrix in your workspace. The rows of this matrix represent all possible samples from pop. View the first 10 samples by giving the command samples[1:10,].

```{r}
samples[1:10,]
```


> c.	Create a sequence M of 32768 sample means by passing the command

```{r}
M <- rowMeans(samples)
```

> Without having a look at the content of M, can you predict how often the value 1 will occur among the 32768 sample means? The same question for the values 8, 1.2 and 7.8.

The samples are drawn with replacement, so the mean 1 is a possible value, however, it is not very likely to occur. Using probability theory

$$P(mean = 1) = p^5 = (1/6)^5 = `r round((1/6)^5, 3)` = P(mean = 8)$$

The answer for the value 8 is exactly the same.

The values 1.2 and 7.8 can only occur when all values are a 1 (or an 8), and 1 is a 2. So now:

$$P(mean = 1.2) = {5 \choose 1}*p(1)^4*p(2)^1 = 5*(1/6)^5 = `r round(5*(1/6)^5, 3)`=P(mean = 7.8)$$

> d.	Make a frequency table of M by running the command below.

```{r}
table(M)
```


> Check your answers from c). What is the frequency of occurrence of the number 2? And that of the number 7?
e.	Make an appropriate graph of the frequency table by giving the command:

```{r}
barplot(table(M))
```

> Is this what you could expect according to the Central Limit Theorem?

Yes, this shows that the means of samples drawn from the uniform distrubution are normally distributed (or better: t-distributed with $n$ degrees of freedom, where $n$ is the sample size).

##### 11.
>	This exercise is intended to give you a better understanding of 95% confidence intervals. The distribution of bladder volume in the population of adult men is approximately normal with mean 550 ml and standard deviation 100 ml. We will draw samples of N=25 from this population and for each sample we will calculate the mean and a 95% confidence interval for the mean. What is the standard error of the mean for samples of N=25 from this population?

This time, whe have the actual population standard deviation, instead of only our estimate of the sample standard deviation.

```{r}
n  = 25
mu = 550
s  = 100 
se = s / sqrt(n)
se
```


> To draw 100 samples from this distribution, we will make a matrix of 2500 draws from this normal population, and put them into a matrix mymat with 25 rows and 100 columns, corresponding to 100 samples (columns) of 25 men per sample (rows). To make calculations with the matrix easier, we will then make a data frame mysamples from the matrix:

NB. using the command `set.seed` ensures that anyone else can replicate this code and achieve the exact same numbers.

```{r}
set.seed(1)
mymat <- matrix(rnorm(2500, mean=550, sd=100), 25, 100)
mysamples <- data.frame(mymat)
head(mysamples)
```


> Now we take the mean of each row of the data, resulting in a column of 100 sample means. We use the apply function to accomplish this (see the R help for information about this function):

```{r}
smeans <- apply(mysamples,2,mean)
```


> Now we want to plot the means, together with their 95% CIs. We will plot them against sample number (1 through 100). Add a horizontal line at the true population mean:

```{r}
x <- 1:100
plot(x, smeans, ylab="sample mean",xlab="sample number")
abline(h=550)

```


> To the above plot we will add 95% CIs. We use the arrow command to add “arrows” (without arrowheads: length=0) that are 1.96*SE long above and below the sample mean (why 1.96?):

We use 1.96 because `qnorm(p = 0.025)` equals 1.96. The point at which the cumulative probability density reaches 2.5% is 1.96 (measured in standard deviations, when using the standard normal distribution with $\mu = 0$ and $\sigma = 1$)

```{r}
plot(x, smeans, ylab="sample mean",xlab="sample number")
abline(h=550)
arrows(x, smeans - 1.96*20, x, smeans + 1.96*20, angle=90, length=0)

```


> How many of your 95% CIs contained the true population mean?

```{r}
not_too_low  = smeans + 1.96*20 > 550
not_too_high = smeans - 1.96*20 < 550
sum(not_too_low & not_too_high)
```

So in this case, `r sum(not_too_low & not_too_high)` of the confidence intervals cover the true mean of 550ml.

> If you put the above commands in an R “script” you can re-run them several times. How does your graph change?

All point estimates and confidence intervals change, but the number of confidence intervals covering the true mean of 550ml stays approximately the same.

## Day 3: Hypothesis testing and power, part 1
### Exercises without SPSS or R
#### 1.	Does alcohol affect your reaction time? 
> Subjects are given a psychological test when they are sober (no alcohol) and after drinking two beers. The dataset below contains reaction times (in ms) for 6 subjects while sober and after drinking alcohol. 

```{r}
sober = c(73, 57, 97, 60, 76, 87)
with_alcohol = c(81, 80, 121, 94, 85, 102)
```

> a.	To answer this question, a researcher uses a paired design, measuring reaction time twice on each subject: once while sober; and once with alcohol. (To minimize the effect of learning, subjects were randomized to either sober first and then with beer, or the other way around. This is called a “cross-over” design. Here we will ignore the possible effect of which condition was given first.) Use a suitable test to check whether the mean reaction times with and without alcohol differ significantly.

The appropriate test here is a matched two-sample t-test, assuming equal variance of the groups. This is equivalent to substracting the reaction times of the different conditions for each patients, and then performing a single sample t-test, where a significant difference will be inferred if the confidence boundries exclude 0. We will first do it 'by hand', and then with the r-command.

```{r}
n = length(sober)
mean_sober = mean(sober)
mean_alcohol = mean(with_alcohol)
mean_sober
mean_alcohol

difference = with_alcohol - sober

mean_difference = mean(difference)
s_difference = sd(difference)
se_difference = s_difference / sqrt(n)
t_value = qt(0.025, df = n-1)

mean_difference + c(-1,1)*t_value*se_difference

# for comparison
t.test(sober, with_alcohol, paired = T, var.equal = T)
t.test(with_alcohol - sober)
```

The confidence interval for the mean does not include 0, so significant difference is noted.

Remark: stricly speaking, reaction times can not be perfectly normally distributed, as they are bounded by 0 on the left side, the Poisson distribution might be better. However, when the mean is sufficiently large and the spread sufficiently low, this distribution appriximates the normal distribution. Moreover, by the Central Limit Theorem, the sample mean is approximately normally distributed.

### Exercises in R
#### 5.	
> This exercise uses the built-in dataset react, from  the library ISwR. The dataset is also on Moodle in the file react.RData. The description of the dataset and research question is given in Exercise #4 (SPSS dataset Mantoux.sav) above.
a.	Get the dataset in your workspace:

```{r, message = F, warning = F}
library(ISwR)
data(react)
```

> b.	Print the content of the dataset to the screen. What do you see?

```{r}
react
str(react)
```

React is an integer vector of length 334

> c.	Make a histogram of the variable react. Also try out the following command:

```{r}
hist(react)
plot(density(react))
```

> The plot(density()) command tells R to plot the estimated probability density for a variable, i.e. a kind of smooth version of a histogram.

> d.	Run a suitable t-test to check whether the mean of the measurements differs significantly from zero: 

```{r}
t.test(react)
```

> 6.	This exercise uses the built-in dataset Loblolly. The dataset contains information on the growth of 14 pine trees over a period of 25 years. Is the growth between age 20 and 25 significant?
a.	Get the dataset into the workspace, attach it to your workspace, and get some information about the dataset.

```{r}
data("Loblolly")
attach(Loblolly)
str(Loblolly)
```


> b.	Select the 14 heights at age 20 from the dataset like this:

```{r}
height20 <- subset(Loblolly,age==20)
height20 <- height20[,1]
```

> Similarly, store the 14 heights at age 25 into a variable height25.

```{r}
height25 <- subset(Loblolly,age==25)
height25 <- height25[,1]
```


> c.	Use an appropriate t-test to determine whether there is significant growth between ages 20 and 25. Graphically check any assumptions you make.

```{r}
hist(height20)
qqnorm(height20)
qqline(height20, col = "red")
hist(height25)
qqnorm(height25)
qqline(height25, col = "red")

t.test(height20, height25, paired = F)
```

> d.	Don’t forget to detach the data before using the next data frame in R!

```{r}
detach(Loblolly)
```

#### 7.	
> To start this exercise, first get the built-in dataset sleep.
a.	Get some information about the dataset. What is the study design? Is this paired or unpaired data?

```{r}
data("sleep")
sleep
# help(sleep)

```

From the help file it is clear that each patient was tested under 2 conditions, so we should treat the data as paired. It is a cross-over design.

> b.	Create two variables extra1 and extra2 by extracting the rows 1-10 (extra1) or 11-20 (extra2) and the first column from the dataset sleep. Also make a new variable diff, which is the difference between the two:

```{r}
extra1 <- sleep[1:10,1]
extra2 <- sleep[11:20,1]
diff <- extra1 - extra2
```


> Test whether the mean extra hours of sleep differ for the two treatments.
c.	Part c) can be done quickly without “splitting” the dataset:

```{r}
t.test(extra~group, data = sleep, paired = T)
```

> d.	Check whether the assumption of normally distributed differences is tenable.

```{r}
qqnorm(diff)
qqline(diff, col = "red")
```

Looks pretty ok

### Power (and sample size) estimation in R
#### The function power.t.test( )
> The power of a t-test to detect a difference of δ in a normally distributed outcome variable can be estimated by using the function power.t.test(). The general call to this function is of the form
`power.t.test(n=…,delta=…,sd=…,sig.level=…,power=…,type=…,alternative=…)`
> (Use the call `?power.t.test` to get information about all the options of this function). This function can be used in case of a one sample design or two (independent or paired) samples design.

```{r}
args(power.t.test)
```

> 8.	An established hypothesis states that in the Netherlands the mean height of the adult male population is 175 cm. We want to determine the power of the one sample t-test for certain specific values of mu under the alternative hypothesis, for a sample size of 50 and a sample standard deviation of 10.
a.	Determine the power of the test against an alternative µ = 176, using the function power.t.test. Do the same against an alternative µ = 178.

```{r}
n = 50
s = 10
mu0 = 175
mu1 = 176
mu2 = 178
power.t.test(n = n, sd = s, sig.level = 0.05, delta = mu1-mu0, type = "one.sample")
power.t.test(n = n, sd = s, sig.level = 0.05, delta = mu2-mu0, type = "one.sample")
```

> b.	You could compute the power for some more alternatives and then make a curve. To make life a bit easier, R makes it possible to define the parameter delta (i.e. the difference between mu under the alternative and the null hypothesis) as a vector for several values of mu under the alternative hypothesis. For example, you could store the alternatives µ = 176 and µ = 178 in a variable (vector) alt and the deltas in a variable d:  

```{r}
alt <- c(176,178) 
d <- alt-175 
```


and then pass the command 

```{r}
power.t.test(n=50,delta=d,sd=10,sig.level=0.05,type="one.sample")
```

> This would give you both answers to part (a) at once. To distill only the power values from the output, use 

```{r}
power.t.test(n=50,delta=d,sd=10,sig.level=0.05,type="one.sample")$power
```

> Exploit the technique sketched above to make a power curve, that is, a curve with on the horizontal axis the alternatives and on the vertical axis the corresponding power. Let the values under the alternative vary from 170 to 180, with steps of 0.25, using `seq(170, 180, 0.25)`
> The resulting curve should be symmetric around 175, where it takes its minimum value. How big is the power at the value of 175?

```{r}
mus <- seq(170, 180, 0.25)
deltas <- mu0-mus
powers <- power.t.test(n = n, delta = deltas, sd = s, sig.level = .05, type = "one.sample")$power
plot(mus, powers)
min(powers)
powers[mus == 175]
```


> c.	Now draw an actual sample of size 50 from a normal distribution with mean 176 and standard deviation 10. 

```{r}
set.seed(2)
samp <- rnorm(50,176,10)
```

> Test this sample in a t-test against the test value µ = 175. Store the results of the t-test in, say, an object result.T:  

```{r}
result.T <- t.test(samp, mu=175) 
```

> To extract the p-value from the object result.T, pass the command 

```{r}
result.T$p.value
```

> What is the p-value returned by the t-test? Does your t-test lead to a correct decision? How big is the probability that you will correctly reject $H_0$? 

The decision here would be to maintain $H_0$, which is incorrect, as the sample was drawn from a population with mean 176.

```{r}
power.t.test(n = 50, sd = 10, delta = 1, sig.level = .05, type = "one.sample")
```

> d.	[Challenge exercise] In this exercise we will try to determine the power of a one sample t-test by using simulations.
Using R, we are going to draw 2000 samples, each of size n=50, from a normal distribution with mean 176 and standard deviation 10. For each of these samples we want to perform a t-test to test the null hypothesis that µ = 175. We will then determine in how many of the samples the null hypothesis is (correctly) rejected.

> We will first define a new function (T.p) that returns the p-value from a one sample t-test:  

```{r}
T.p <- function(X) {
  result.T <- t.test(X, mu=175)
  return(result.T$p.value)
} 
```


> Next we draw our samples and calculate the p-value for each, storing them in an object RES. 

```{r}
# First make an empty vector to fill with results (p-values)
RES <- rep(NA, 2000)
# Draw 2000 samples of 50 and put the p-value from each in RES:
set.seed(2)
for (i in 1:2000) {
  dat <- rnorm(50,176,10)
  RES[i] <- T.p(dat)}

# Get the number and proportion of samples for which the p-value is lower than 0.05
sum(RES<0.05); sum(RES<0.05)/2000

```

> Compare this to your answer found in c).

This is pretty close to the calculated power with `power.t.test`.

> NOTE: Obviously it is not necessary to use simulations to get the power if you know that the assumption of normally distributed data is true, but you could use this method for situations where the data do not come from a normal distribution and if the sample size is small. This way you could compare the power of the t-test to alternative (non-parametric) tests.

## Day 4: HYPOTHESIS TESTING + POWER 2
### (Power and) sample size estimation in R
> The following give two possibilities (there are more) for estimating the sample size using the statistical package R.

#### The function POWER.T.TEST( )
> The minimum sample size to detect a difference of δ in a normally distributed outcome variable can be estimated by using the function power.t.test(). The general call to this function is of the form
`power.t.test(n=…,delta=…,sd=…,sig.level=…,power=…,type=…,alternative=…)`
(Use the call ?power.t.test to get information about all the options of this function). This function can be used in case of a one sample design or two (independent or paired) samples design.

#### The library PWR
> The statistical package R may be extended by the library pwr. This library offers several utilities to carry out basic sample size computations. It contains, among others, the functions:
`pwr.t.test()` and `pwr.t2n.test()`.
> The first function very much resembles the function power.t.test():
`-	pwr.t.test(n=…,d=…,sig.level=…,power=…,type=…,alternative=…)
with d = effect size (µ1 - µ0) /σ`

> If the sample sizes will be unequal, then one can use the function pwr.t2n.test(). A general call to this function is of the form:
-	pwr.t2n.test()
`pwr.t2n.test(n1=..,n2=..,d=..,sig.level=..,power=..,type=..,alternative=..)`
> with n1 and n2 are the sample sizes in the two groups  and d is effect size (µ1 - µ0) /σ

### Exercises without SPSS or R

> 1.	Recall the exercise from yesterday: does alcohol affect your reaction time? Subjects were given a psychological test when they were sober (no alcohol) and after drinking two beers. The dataset contained reaction times (in ms) for 6 subjects while sober and after drinking alcohol. 

```{r}
sober = c(73, 57, 97, 60, 76, 87)
with_alcohol = c(81, 80, 121, 94, 85, 102)
```

> Yesterday, the researcher correctly used a paired samples t-test to answer this question. What would have happened if he had accidentally used an unpaired samples t-test? Here is the output that he would have gotten:
 
```{r}
t.test(with_alcohol, sober, paired = F, var.equal = T)
t.test(sober, with_alcohol, paired = T)
diff_paired <- with_alcohol - sober
se_diff_paired <- sd(diff_paired) / sqrt(length(diff_paired))
se_diff_paired

sd_pooled = sqrt(((length(sober)-1)*sd(sober)^2 + (length(with_alcohol)-1)*sd(with_alcohol)^2)/(length(sober)+length(with_alcohol) - 2))
se_pooled = sd_pooled * sqrt(1/length(sober)+1/length(with_alcohol))
se_pooled

(mean(with_alcohol) - mean(sober)) + c(-1,1)*qt(p = .975, df = length(sober)+length(with_alcohol)-2)*se_pooled

```

> Compare these results from with the results from day 3 (Exercise 1). What do you notice about the mean difference? About the standard error of the difference in means? And about the p-value?

The difference in means remains equal, the standard error is approximately doubled, the p-value is lower in the paired example.

> In the following questions, two studies are performed. Using pictures or words, argue the cases described below.

> 2.	In the first study, two treatments are compared in two groups of 30 patients, in the second study, the same two treatments are compared in two groups of, respectively, 30 and 20 patients. The expected effect size is in both studies the same. Which of the studies will have more power?

The study with two groups of 30 patients will have the most power. The T-statistic is determined by the difference in means between the two groups, the pooled standard deviation (assuming equal variance) of the samples and the sample sizes. The t-statistic scales with roughly $\sqrt{n}$, and will be larger when $n$ is larger, leading to a higher chance of rejecting $H_0$ in the case that $H_1$ is true.

```{r, include = F}
norm_function <- function(mu, sd) {
  f = function(x) (1/(sd*sqrt(2*pi)))*exp(-(x-mu)^2/(2*sd^2))
  return(f)
}
# create distributions for sample means under H0 and H1
# assuming large sample size, so T-distribution converges to normal distribution
mu0 = 0; sd0 = 1;
mu1 = 2; sd1 = 1.2;
h0_distribution = norm_function(mu = mu0, sd = sd0)
h1_distribution = norm_function(mu = mu1, sd = sd1)
alpha = 0.05
boundary_value = qnorm(p = .95, mean = mu0, sd = sd0)
xmin = -3
xmax = 6


require(ggplot2)
ggplot(data.frame(x = c(xmin, xmax)), aes(x)) + 
  stat_function(fun = h0_distribution) + 
  stat_function(fun = h0_distribution, 
                xlim = c(boundary_value,xmax),
                geom = "area", alpha = 0.5) + 
  stat_function(fun = h1_distribution) +
  stat_function(fun = h1_distribution,
                xlim = c(xmin, boundary_value),
                geom = "area", alpha = 0.25) + 
  theme_bw()
```

> 3.	In both studies, two treatments are compared in two groups of 30 patients, in the first study, the standard deviation was 6 and in the second study 5. The expected effect size is in both studies the same. Which of the research designs will have more power?

The second study with lower variance will have more power, since power increases when variance decreases.

> 4.	In both studies, two treatments are compared in two groups of patients, and in the first study the standard deviation is 6 and in the second study 5. The expected effect size and the required power is both studies the same. Which of the two studies will need a larger number of patients?

By the same reasoning as in 3. the study with lower variance will need fewer patients to achieve the same power

> 5.	In both studies, two treatments are compared in two groups of patients of the same size. The standard deviations are the same. The expected effect size is in the first study twice as large as in the second. Which of the studies will have more power?

The study with a higher expected effect size will have larger power

> 6.	In both studies, two treatments are compared in two groups of patients. The standard deviations are the same. The expected effect size is in the first study twice as large as in the second. The required  power is for both studies equal to 0.90. Which of the two studies will need a larger number of patients?

Assuming equal study sizes for the 2 studies, the study with larger effect size will need fewer patients.

> 7.	Researchers want to evaluate whether there is a significant difference in mean heart rate between two different drugs. A difference of 4 beats per minute is considered relevant. Based on other studies the standard deviation in both groups was assumed to be 8 beats per minute. The type I error was set at 5% (two-sided) and type II error at 10% (one-sided). No sample size calculation was carried out ahead of time; a total of 135 patients were randomized to the two drugs. Argue whether 135 patients were enough for this study.

For 2 independent samples and equal variances, the power can be calculated with iteratively with

$$n \geq 2*(\frac{s_p}{\mu_1-\mu_0}*(t_{\alpha,v}+t_{\beta(1),v}))^2$$

Where $v$ gets updated with each iteration.

```{r}
alpha = 0.05
beta = 0.1
diff = 4
s = 8

n0 = 2*((s/diff) * (qnorm(alpha/2, lower.tail = F) + qnorm(beta, lower.tail = F)))^2
n0 = ceiling(n0) # round upwards to an integer
n0
n1 = 2*((s/diff) * (qt(alpha/2, lower.tail = F, df = 2*n0-2) + qt(beta, lower.tail = F, df = 2*n0-2)))^2
n1 = ceiling(n1)
n1
n1 = 85.03
n1 = 85.06159
n2 = 2*((s/diff) * (qt(alpha/2, lower.tail = F, df = 2*n1-2) + qt(beta, lower.tail = F, df = 2*n1-2)))^2
n2 = ceiling(n2)
n2
```

So 87 people per group = 174 would be enough, which means that the study is underpowered. NB we take $\alpha/2$ because this difference was two-sided, while the type II error is always one-sided. NB2 if the population variance is known, we could have stopped at `n0` (`r n0`), taking quantiles from the normal distribution instead of a t-distribution.

### Excercises in R
> 11.	Start this exercise by getting the built-in dataset ToothGrowth.
a.	Get some information about the dataset by running the command:

```{r}
data("ToothGrowth")
# help(ToothGrowth)

```

> b.	Attach the headers of this dataset to your workspace and run the commands:

```{r}
attach(ToothGrowth)
```

> Because you have ‘attached’ the dataset, you can use the headers in the dataset as if they were variables:

```{r}
boxplot(len)
boxplot(len~supp)

```


> Interpret the plots.
c.	Run a suitable t-test to check whether the supplements resort in significantly different effects.

From the description, it looks like the data were not paired. So an unpaired t-test will be used, not assuming equal variance.

```{r}
t.test(len~supp, var.equal = F, paired = F)
```

> d.	Are the conditions for the t-test in c) met?

We did not assume equal variance. To check for normality in the residuals:

```{r, message = F, warning = F}
resid_OJ = len[supp == "OJ"] - mean(len[supp == "OJ"])
resid_VC = len[supp == "VC"] - mean(len[supp == "VC"])

resid_both <- c(resid_OJ, resid_VC)

qqnorm(resid_both)
qqline(resid_both, col = "red")

```

The residuals look pretty normally distributed, save for some data points on the extreme sides of the distribution, which is common for limited sample sizes.

> e.	When you are done with a dataset, remember to detach it before working with a new dataset within the same R session:

```{r}
detach(ToothGrowth)
```


> 12.	In this exercise you will need a dataset energy in the package ISwR. Load this package by passing the command

```{r}
library(ISwR)

```

> If this library is not installed on your computer (and cannot be installed), then load the dataset energy.RData from Moodle.
a.	To get some descriptive statistics, pass the following commands:

```{r}
plot(expend~stature, data=energy)
tapply(energy$expend, energy$stature,mean)
tapply(energy$expend, energy$stature,sd)
```

> b.	Check whether there is a significant difference in mean expenditure between lean and obese women.

```{r}
t.test(expend~stature, data = energy, var.equal = F, paired = F)
```

> c.	Which assumption(s) do you make when applying this test? Do you think the assumptions are reasonable?

Assumptions are: unequal variance (which is liberal), normal distribution of residuals. To inspect these, we will make the residual plot in a different way, using a linear regression model. This model assumes equal variance, but this will not influence the residuals as these are just $x_ij - \mu_i$ for individual $j$ belonging to group $i$. Colors are added to indicate the group of an individual.

```{r}
fit <- lm(expend~stature, data = energy)
plot(fit, which = 2, col = energy$stature)
```

In this case, there is quite some deviation from the normal distribution for higher expenditures, so we cannot be sure that the t-test is appropriate.

### Exercises using nQuery, PS, or R

> 13.	Calculate in each of the following situations the minimum required total sample size.
a.	Use one of the software packages to estimate the required sample size for exercise #7 above.

```{r}
alpha = 0.05
beta = 0.1
diff = 4
sigma = 8

power.t.test(delta = diff, sd = sigma, sig.level = alpha, power = 1-beta, type = "two.sample", alternative = "two.sided")

# using samplesize package
samplesize::n.ttest(power = 1-beta, alpha = alpha, mean.diff = diff, sd1 = sigma, sd2 = sigma, k = 1, design = "unpaired", fraction = "balanced", variance = "equal")

samplesize::n.ttest(power = 1-beta, alpha = alpha, mean.diff = diff, sd1 = sigma, sd2 = sigma, 
                    design = "unpaired", variance = "unequal")
```

> b.	The dissolving time t of a drug in gastric juice is known to be normally distributed with a mean of 45 seconds and an estimated standard deviation s of 3 seconds. Under an experimental condition, a difference in the average dissolving time of at least 2 sec is to be detected, if it is present. The goal is to detect this difference with a two-sided α of 0.05 and a power of 0.90.

```{r}
power.t.test(delta = 2, sd = 3, sig.level = 0.05, power = 0.9, type = "one.sample", alternative = "two.sided")
```

> c.	A study on the difference in concentration in tubes with liquid medicine will be planned. Half of the tubes are exposed to sunlight and the other half not. It is expected that the average concentration changes with 3.5 mg/l after the drug has been in sunlight. The expected standard deviation is 6 mg/l. The risk of type I error (two-sided) will be set to 0.05 and the risk of type II error to 0.20. How many tubes are at least required for this study?

```{r}
power.t.test(delta = 3.5, sd = 6, sig.level = 0.05, power = 0.8, type = "two.sample", alternative = "two.sided")
```



## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
