---
title: "Assignments for Generalized Linear Methods"
author: "Wouter van Amsterdam"
date: 2018-03-05
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->

# Setup

```{r}
library(dplyr)
library(data.table)
library(magrittr)
library(purrr)
library(here) # for tracking working directory
library(ggplot2)
library(epistats)
library(broom)
```

# Day 1

## 1 Throat

> Analyze the throat dataset (throat.txt or throat.sav) in R, SPSS, or both.

### a.

>Examine the relation between sore throat and duration of surgery in three ways: 1) make a scatterplot of sore throat by duration of surgery; 2) make histograms of duration split by sore throat; and 3) make a plot of proportion having sore throat by duration of surgery (you'll need to categorize duration).

> In a survey of 35 patients having surgery with a general anesthetic, patients were asked whether or not they experienced a sore throat (throat=0 for
no, throat=1 for yes).  The duration of the surgery in minutes was also recorded, and the type of device used to secure the airway (0 = laryngeal mask airway; 1=tracheal tube)

```{r}
throat <- read.table(here("data", "throat.txt"), sep = ";", header = T)
str(throat)
```

Rename variables for easier interpretation

```{r}
throat %<>%
  transmute(
    patient = Patient,
    duration = D,
    sore_throat = as.logical(`T`),
    tracheal_tube = as.logical(Y))
```


Scatterplot

```{r}
throat %>%
  ggplot(aes(x = duration, y = sore_throat)) + 
  geom_point()
```

Histograms

```{r}
throat %>%
  ggplot(aes(x = duration, fill = sore_throat)) + 
  geom_histogram()
```

Proportion sore throats by category of duration.

Let's divide duration in 5 categories

Calculate mean duration by quantile for proper plotting

```{r}
throat %<>%
  mutate(duration_group = quant(duration, n.tiles = 5))

throat_grouped <-throat %>%
  group_by(duration_group) %>%
  summarize(mean_duration = mean(duration), 
         prop_throat = mean(sore_throat))
```

Plot them

```{r}
throat_grouped %>%
  ggplot(aes(x = mean_duration, y = prop_throat)) + 
  geom_point() +
  lims(y = c(0,1))
```

Now improved with errorbars

In `epistats` ther is a function that returns a proportion with a confidence interval 
for logical variables (without using `n = length(x), x = sum(x)`)

Group the data by duration group using `nest` from `tidyr`
Perform the confidence interval estimation in each subset,
pull out the proportions and confidence intervals.


```{r}
require(tidyr)

throat %<>%
  mutate(duration_group = quant(duration, n.tiles = 5))

throat_nested <- throat %>%
  group_by(duration_group) %>%
  nest() %>% 
  mutate(
    mean_duration = map(data, function(data) mean(data$duration)),
    prop = map(data, function(data) binom.confint_logical(data$sore_throat))) %>%
  unnest(prop, mean_duration)

throat_nested %>%
  ggplot(aes(x = mean_duration, y = mean)) + 
  geom_errorbar(aes(ymin = lower, ymax = upper)) + 
  lims(y = c(0,1)) + 
  theme_minimal() + labs(y = "proportion sore throat")


```



### b.

> Fit a logistic regression model to explain the probability of sore throat as a function of duration of surgery. SPSS users: do this once using the Regression, Binary Logistic menu option, and a second time using the Generalized Linear Model menu option. Compare the results from both "methods" for estimating a logistic regression; are there differences in the parameter estimates, standard errors or maximum likelihood?

```{r}
fit <- glm(sore_throat ~ duration, data = throat, family = binomial(link = "logit"))
summary(fit)
```

### c.

> Add the fitted logistic curve from (d) to one of the graphs in (a) (SPSS users: save the predicted probabilities from the model; use either a multiple line graph or an overlay scatterplot).

```{r}
throat_nested %<>%
  mutate(pred = predict(fit, newdata = data.frame(duration = mean_duration), 
                        type = "response"))

throat_nested %>%
  ggplot(aes(x = mean_duration, y = mean)) + 
  geom_errorbar(aes(ymin = lower, ymax = upper)) + 
  geom_line(aes(y = pred), lty = 2) + 
  lims(y = c(0,1)) + 
  theme_minimal() + labs(y = "proportion sore throat")
  
```

## 2. Throat 2

> Continue with the analysis of the throat dataset in R, SPSS, or both (SPSS users: use the GLM menu for the modelling):

### a.

> Examine the relation between sore throat and device, and between device and duration.

```{r}
throat %>%
  select(sore_throat, tracheal_tube, duration) %>%
  mutate_if(is.logical, as.factor) %>%
  GGally::ggpairs()
```

Patients without a tracheal tube seem to have a sore throat more often.

Patients with a tracheal tube seem to have a longer duration

### b.

> Fit a logistic regression model to explain the probability of sore throat as a function of type of device. Get the Wald and profile likelihood 

```{r}
fit2 <- glm(sore_throat ~ tracheal_tube, data = throat, family = binomial(link = "logit")) 
summary(fit2)
confint(fit2)
```

Both Wald test and profile likelihood agree that tracheal tube is not significant.

### c.

> Fit the remaining models from the lecture and interpret the output.

```{r}
fit2 <- glm(sore_throat ~ tracheal_tube + duration, data = throat, family = binomial(link = "logit"))
fit3 <- glm(sore_throat ~ duration * tracheal_tube, data = throat, family = binomial(link = "logit"))

summary(fit3)
AIC(fit2, fit3)
```

There seems to be a significant interaction between tracheal tube and duration,
 according to both the p-value from the fit summary and the AIC.

Without the tracheal tube, the duration of the procedure does not seem to matter.
The tracheal tube itselve is protective for sore throat.
For patients with a tracheal tube, increased duration is associated with 
higher odds of sore throat


### 3.

> Optional in R: continue with the analysis of the throat dataset, and repeat the model diagnostics. For saving, "binning" and plotting the binned residuals, see the script provided.

```{r}
plot(fit3)
```

Use binning (adapted from provided script)

```{r}
throat %<>%
  mutate(
    residuals = residuals(fit3),
    linpred = predict(fit3, type = "link")
  )

throat %>%
  mutate(pred_cat = quant(linpred, n.tiles = 10)) %>%
  group_by(pred_cat) %>%
  summarize(residuals = mean(residuals),
            linpred = mean(linpred)) %>%
  ggplot(aes(x = linpred, y = residuals)) +
  geom_point()

```

This should be unstructured.


## 4

> The R script GLM computer lab1 analyses.R contains the beginnings of an analysis of the ICU dataset (ICU.RData, ICU.sav). Use and expand on this script in R (or use SPSS) to answer the following questions.
a.	(SPSS users note: this is not entirely possible, see answers to 1a&c for compromise.) Examine the relation between status and systolic blood pressure (SYS). Try to make a graph of this relation, similar to the graph of status vs. age in the lecture notes (bottom left graph on slide 60). Compare this plot to the systolic blood pressure plot on slide 61 of the lecture notes. What is different in how this new plot has been made?
b.	Fit a logistic regression model using only systolic blood pressure (SYS) to predict status. What is the odds ratio for dying (status = dead) for a 10 unit increase in systolic blood pressure?
c.	What assumption does the model in 3(b) make about dying and SYS? Do you think that assumption is met?
d.	Examine the relation between status and level of consciousness (LOC) in a contingency table. What do you notice? What problems might this give in the model fitting?
e.	Fit a logistic regression model using LOC to predict status. Comment on the estimates and standard errors for the regression coefficients.

> This dataset will be considered for further analysis on days 2 and 3.

```{r}
# fit_all <- ...
# stepAIC(fit_all)

# check assumptions (binned deviance, by variable)


```

This assignment was skipped due to time-limitations and it being discussed during the lecture.

## 5.

> Can we predict birth weight using gestational age? Is the prediction the same for boys and girls?
a.	Use the dataset bwt_gestage.csv to answer these questions. Note: sex = 1 are the boys, sex = 2 are the girls.
b.	Interpret your findings.
c.	Fit the final model from (a) using both the lm() and glm() functions in R. Compare the parameter estimates and standard errors from the two methods of fitting a linear model.
d.	Repeat (c) using both the Regression, Linear and the Generalized Linear Models procedures in SPSS. Compare the parameter estimates and standard errors from the two methods of fitting a linear model. What do you notice?


## 6. 

> We wish to find factors that influence the probability that a low birth weight infant (<1500 g) will experience a germinal matrix hemorrhage. A sample of 100 low birth weight newborns was retrospectively collected in a hospital in Boston, MA. Factors possibly indicative of a germinal matrix hemorrhage were extracted from a chart review and included sex, head circumference, systolic blood pressure and gestational age of the infant, and whether the mother suffered from toxemia during the pregnancy. Use the dataset lowbwt.txt to predict the probability of hemorrhage. (Note: the dichotomous variables are defined as follows: sex=1 is a male, tox=1 is toxemia, grmhem=1 hemorrhage.)
a.	Start by describing the data, get a sense of the relations between the potential explanatory variables and the outcome.
b.	Construct a model to predict occurrence of germinal matrix hemorrhage.
c.	Interpret your findings.

## 7. 

> The dataset epilepsy in the R library HSAUR (or the SPSS file epilepsy.sav) contains data from a clinical trial on 59 patients suffering from epilepsy. Patients were randomized to groups receiving either an anti-epileptic drug or a placebo, in addition to standard chemotherapy. N.B. If you're working in R and you've loaded the faraway library, unload it now! Otherwise you may end up with the wrong epilepsy data frame (both faraway and HSAUR contain data frames with different structures but the same name): detach("package:faraway"). Get some information about this data frame by loading the HSAUR library and using help(epilepsy). This is data from a longitudinal trial; we will use only the data from the last two-week period. We are interested in whether the probability of seizure is higher in the treatment or control group in this period.
a.	Start by making a selection of the data for period 4 and making a new variable for seizure yes/no.
b.	Get some descriptive statistics for the data, get a sense of the relations between the potential explanatory variables and the dichotomous outcome seizure.
c.	What type of variable is seizure.rate?
d.	Give two reasons why a logistic regression model is not the most appropriate way to analyze this data.



# Day 2

## 1.

> The R script ICU analyses day 2.R contains the beginnings of an analysis of the ICU dataset (ICU.RData, ICU.sav). Use and expand on this script in R (or use SPSS) to answer the following questions.

Setup 

```{r}
# Analyses of throat and ICU datasets for day 2 GLM course

library(gmodels)
library(splines)
library(HSAUR)

load(here("data", "ICU.RData"))
str(ICU)

```

### a.

> Examine the relation between status (STA) and type of admission (TYP). 

```{r}
CrossTable(ICU$TYP, ICU$STA, prop.c=FALSE, prop.t=FALSE, prop.chisq=FALSE) 
```

### b.

> Fit a logistic regression model using TYP to predict status. Express the results as OR and 95% CI.

```{r}
icu.m1 <- glm(formula = STA ~ TYP, family = binomial(link = "logit"), data=ICU)
summary(icu.m1)
exp(coefficients(icu.m1))
exp(confint(icu.m1))
```

### c.

> Fit two binomial models producing the Risk Ratio and Risk Difference, with their 95% CI. 

```{r}
# "relative risk" regression: link=log, family = binomial
icu.m2 <- glm(formula = STA ~ TYP, family = binomial(link = "log"), data=ICU)
summary(icu.m2)
exp(coefficients(icu.m2))
exp(confint(icu.m2))

# "risk difference" regression: link=identity, family = binomial
# Note: do not exponentiate coeff & CI
icu.m3 <- glm(formula = STA ~ TYP, family = binomial(link = "identity"), data=ICU)
summary(icu.m3)
# confint(icu.m3)
confint.default(icu.m3)
```

For the identity link, likihood profiling for confidence intervals does not work.
Possibly due to inadmissable values in the range of the profile.

### d.

> Fit two further binomial models using the probit link and the cloglog link. 

```{r}
# probit link
icu.m4 <- glm(formula = STA ~ TYP, family = binomial(link = "probit"), data=ICU)
summary(icu.m4)

# cloglog link
icu.m5 <- glm(formula = STA ~ TYP, family = binomial(link = "cloglog"), data=ICU)
summary(icu.m5)
```

### e.

> Decide which link gives the best fitting model, based on deviance or AIC

```{r}
AIC(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5)
```

All have equivalent AIC.

```{r}
list(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5) %>%
  map_dbl(deviance)
```

All have equivalent deviance

## 2.

> Repeat the analyses 1a-d for the continuous variable SYS, being systolic blood pressure.

The identity link required starting values to work

```{r}
try(fit_id <- glm(STA ~ SYS, data = ICU, family = binomial(link = "identity"),
                  start = c(mean(ICU$STA == "Dead"), 0)))
```

The rest we can do in one line

```{r}
links = list("logit", "log", "probit", "cloglog")

fits <- links %>%
  map(function(link) glm(STA ~ SYS, data = ICU, family = binomial(link = link)))

links <- c(links, "identity")
fits[[length(fits)+1]]  <- fit_id

data.frame(link = unlist(links), 
           aic = map_dbl(fits, AIC),
           deviance = map_dbl(fits, AIC))
```

### a.

> Decide which link now gives the best fitting model, based on deviance or AIC

The log link gives the lowest AIC, so this is the best fit.

### b.

> Discuss the difference with 1e

With this continous predictor, there is a difference in AICs between the models.

In the previous case with only a single binary predictor, there are only 
two possible values for the predicted probability of survival, regardless
of the link function: $\hat{p}_0$ for unexposed, $\hat{p}_1$ for exposed. 
Each set of values for $p_0$ and $p_1$ gives rise to a single value of 
the resulting likelihood.
Since all glm models are fitted according to the same criterion of maximum 
likelihood, they will all find the same values for $p_0$ and $p_1$.

We can check this by looking at the values of the predictions

```{r}
list(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5) %>%
  map("fitted.values") %>%
  map(unique)
```

In the case of the continous predictor, the predicted probability takes on 
more values, and now the different link functions start to matter 
for the model fit.

### c.

> The logistic model may be improved by introducing a non-linear effect of SYS. One possible way of achieving this is to add a quadratic term to the model. In R, you may also use a flexible natural spline model (use function ns from library splines in the model specification). Check whether model fit improves.

```{r}
require(splines)
fit_logit1 <- glm(STA ~ SYS + I(SYS^2), data = ICU, family = binomial(link = "logit"))
fit_logit2 <- glm(STA ~ ns(SYS, df = 2), data = ICU, family = binomial(link = "logit"))
fit_logit3 <- glm(STA ~ ns(SYS, df = 3), data = ICU, family = binomial(link = "logit"))

AIC(fit_logit1, fit_logit2, fit_logit3)
```

The spline seems to increase model fit, however including more complicated 
splines does not.


## 3.

> The dataset epilepsy.RData (or the SPSS file epilepsy.sav) contains data from a clinical trial on 59 patients suffering from epilepsy. Patients were randomized to groups receiving either an anti-epileptic drug or a placebo, in addition to standard chemotherapy. This is data from a longitudinal trial; we will use only the data from the last two-week period. We are interested in whether the seizure rate is higher in the treatment or control group in this period. This dataset has already been used in yesterday's computer lab and today's lecture.

```{r}
load(here("data", "epilepsy.RData"))
str(epilepsy)
```


### a.	

> Start by making a selection of the data for period 4.

```{r}
epi4 <- epilepsy %>% filter(period == "4")
str(epi4)
```

### b. 

> Repeat the analysis from today's lecture. Comment on the impact of adjustment for the baseline seizure rate. Pay attention to the fact that this is a randomized trial.

First some marginal distributions for treatment groups

```{r}
epi4 %>%
  as.data.table() %>%
  melt.data.table(id.vars = c("subject", "treatmnt"), 
                  measure.vars = c("base", "age", "seizr.rt")) %>%
  ggplot(aes(x = treatmnt, y = value)) + 
  geom_boxplot() +
  facet_wrap(~variable)
```

Looks like the covariates base and age are equally distributed among 
treatment groups, and seizure rate seems a bit lower in the treatment group.

Now for the covariate-outcome distributions:


```{r}
epi4 %>%
  ggplot(aes(x = base, y = seizr.rt)) + 
  geom_point()

epi4 %>%
  ggplot(aes(x = age, y = seizr.rt)) + 
  geom_point()
```

Clear correlation between base rate and follow-up seizure rate.
No clear marginal correlation between age and seizure rate at follow-up

Model with poisson

```{r}
fit1 <- glm(seizr.rt ~ treatmnt, family = poisson, data = epi4)
summary(fit1)
```

Adjusted for base rate

```{r}
fit2 <- glm(seizr.rt ~ treatmnt + log(base), family = poisson, data = epi4)
summary(fit2)
```

Effect seems somewhat stronger after adjustment for base-rate

### c.

> Examine the effects of further adjustment.

```{r}
fit3 <- glm(seizr.rt ~ treatmnt + log(base) + age, family = poisson, data = epi4)
summary(fit3)
```

After adjusting for age, treatment is no longer significant.

```{r}
AIC(fit1, fit2, fit3)
```

Adding age to the model results in a slightly worse fit according to the AIC.

However, model fit is not the primary goal for causal research. 

Let's look at model diagnostics of the fits

```{r}
plot(fit2, which = 5)
plot(fit3, which = 5)
```

Observation 49 seems to have a strong effect on the model


## Day 3 Model diagnostics

### 1. epilepsy

Covered in class

```{r}
library(HSAUR)
data(epilepsy, package = "HSAUR")
epi <- epilepsy[epilepsy$period==4,]
summary(epi)
```

Plot marginal distributions

```{r}
epi %>%
  select(-period) %>%
  gather(-treatment, -subject, -seizure.rate, key = "variable", value = "value") %>%
  ggplot(aes(x = value, y = seizure.rate)) +
  geom_point() + geom_smooth() +
  facet_wrap(~variable, scales = "free_x") + 
  theme_minimal()
```

Look at extreme cases

```{r}
epi %>%
  filter(seizure.rate == max(seizure.rate))
```


#### Linear model

```{r}
fit_lm <- lm(seizure.rate ~ age + base +treatment, data = epi)
plot(fit_lm)
```

- no homoscedasticity
- non-normal distrubtion of residuals

#### Transform variables

```{r}
epi %>%
  mutate(log_base = log(base + 0.5)) %>%
  select(-period) %>%
  gather(-treatment, -subject, -seizure.rate, key = "variable", value = "xvalue") %>%
  mutate(log_sr = log(seizure.rate + 0.5)) %>%
  gather(seizure.rate, log_sr, key = "outcome", value = "yvalue") %>%
  ggplot(aes(x = xvalue, y = yvalue)) +
  geom_point() + geom_smooth() +
  facet_grid(outcome~variable, scales = "free") + 
  theme_minimal()
```


```{r}
fit_lm_log <- lm(log(seizure.rate + 0.5) ~ age + log(base + 0.5) + treatment, data = epi)
plot(fit_lm_log)
```

#### Partial plot

Linear relationship between residuals of a model without the variable


Create a function for partial plots

```{r}
partial_residuals.lm <- function(fit, term, resid_type = "response") {
  formula0  = formula(fit)
  all_vars  = all.vars(formula0)
  response  = all_vars[1]
  all_terms = all_vars[-1]
  new_terms = setdiff(all_terms, term)
  
  fit_resp <- lm(reformulate(new_terms, response), data = fit$model)
  fit_term <- lm(reformulate(new_terms, term), data = fit$model)
  
  return(
    data.frame(resid_response = resid(fit_resp, type = resid_type),
               resid_term     = resid(fit_term, type = resid_type))
  )
}

partial_plots.lm <- function(fit, terms = NULL) {
  formula0  = formula(fit)
  all_vars  = all.vars(formula0)
  response  = all_vars[1]
  all_terms = all_vars[-1]

  terms = if (!is.null(terms)) {terms} else {all_terms}

  resid_data = pmap_df(list(terms), function(term) {
    data.frame(term = term, 
               partial_residuals.lm(fit, term))
    })
  
  p = ggplot(resid_data, aes(x = resid_term, y = resid_response)) + 
    geom_point() + geom_smooth() + 
    facet_wrap(~term, scales = "free_x") + 
    theme_minimal() + labs(y = paste0("Residual of ", response))
  print(p)
  
  return(resid_data)
  
}

partial_plots.lm(fit_lm)

```


# Day 4. Non-standard models

## 1. Matched case control 

> A case-control study was performed to determine whether induced (and spontaneous) abortions could increase the risk of secondary infertility. Obstetric and gynaecologic histories were obtained from 100 women with secondary infertility admitted to a department of obstetrics and gynecology its division of fertility and sterility. For every patient, an attempt was made to find two healthy control subjects from the same hospital with matching for age, parity, and level of education. Two control subjects each were found for 83 of the index patients. The data can be found in infertility.csv. The numbers of (spontaneous or induced) abortions are coded as 0=0, 1=1, 2=2 or more.

### a.

> What type of study is this? What type of analysis do you prefer for this study design?

Matched case control, can be analyzed with conditional logistic regression.

### b.

> Perform the analysis and interpret the results. Do previous (spontaneous or induced) abortions affect the risk of secondary infertility?

Read in data

```{r}
infert <- read.csv(here("data", "infertility.csv"), sep = ";")
str(infert)
summary(infert)
```

Check stratum variable, which tells us the matced pairs

```{r}
table(infert$stratum)
```

Perform analysis

```{r}
require(survival)
fit1 <- clogit(case ~  induced + spontaneous + strata(stratum),
       data = infert, method = "exact")
summary(fit1)
```

Both previous spontanious and previous induced abortions increase the risk 
of infertility. 

The odds ratio of induced abortions is 4.09, 
the odds ratio of spontaneous abortions is 7.29




### c.

> How do we control for the potential confounding effects of age, parity and education?

They are accounted for by the matching, 
so no need to add them as covariates to the model

## 2. Multinomial regression

> Madsen (1976) investigated satisfaction with housing conditions in Copenhagen. Residents in selected areas living in rented homes built between 1960 and 1968 were questioned about their satisfaction and their degree of contact with other residents. The data can be found in the file housinglong.csv. The variable satisfaction is coded 1=low, 2=medium, 3=high; contact is coded 1=low and 2=high. Save your script/SPSS code, we will use this data again in Exercise 4.

### a.

> Summarize the data using appropriate tables and percentages to show the associations between levels of satisfaction and contact with other residents, levels of satisfaction and type of housing, and contact and type of housing.

```{r}
housinglong <- read.csv(here("data", "housinglong.csv"), sep = ";")
str(housinglong)
```

There are three categorical variables, when can get all pairwise contingengy 
tables with 3 tables

```{r}
require(gmodels)
CrossTable(housinglong$type, housinglong$satisfaction, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)
```

Seems like people from tower block are most often in the highest satisfaction 
categorty

```{r}
CrossTable(housinglong$type, housinglong$contact, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)
```

People living in 'house's have most contact with neighbours

```{r}
CrossTable(housinglong$contact, housinglong$satisfaction, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)
```

People with more contact are more often in the highest category of satisfaction.

### b.

> Use nominal (multinomial) logistic regression to model associations between level of satisfaction and the other two variables. Use the likelihood ratio test (LRT) to delete non-significant variables in order to obtain a parsimonious model that summarizes the patterns of the data.

Drop1 trew an error ("Error in if (trace) { : argument is not interpretable as logical"),
so we will make the models ourselves and perform LRtests

```{r}
require(nnet)
fit0 <- multinom(satisfaction ~ 1, data = housinglong)
fit1 <- multinom(satisfaction ~ type, data = housinglong)
fit2 <- multinom(satisfaction ~ contact, data = housinglong)
fit3 <- multinom(satisfaction ~ type + contact, data = housinglong)
anova(fit3, fit2, test = "Chisq")
anova(fit3, fit1, test = "Chisq")
```

Dropping either contact or type will lead to a significant decrease of the
 likelihood, although the effect of dropping type is greater.

### c.

> Interpret the coefficients from the model in (b).

```{r}
summary(fit3)
exp(coef(fit3))
```

The odds of being in satisfactory class 2 is 1.07 times higher than 
the odds of being in class 1, for people in type house, compared to 
type appartment, given the same level of contact. 

The odds of being in satisfactory class 3 is 0.73 times 
the odds of being in class 1, for people in type house, compared to 
type appartment, given the same level of contact. 

Possible extensions:

- recode type to dummy variables, see if we can drop 1 of the 3 levels

### d.

> In SPSS is it not possible to get residuals for a multinomial or ordinal logistic regression. In R we can make our own "deviance residuals" as follows (assuming the dataset is called house, and the multinomial model from which we wish to estimate deviance residuals is called house.mlr.2):
likl <- numeric(1681)
for (i in 1:1681) likl[i] <-  fitted(house.mlr.2)[i,house$satisfaction[i]]
Plot these deviance residuals against case number:
plot(1:1681, -2*log(likl))

```{r}
likl <- numeric(1681)
for (i in 1:1681) likl[i] <-  fitted(fit3)[i,housinglong$satisfaction[i]]
plot(1:1681, -2*log(likl))
```


> We will start the afternoon session with a theoretical (non-computer) question. Discuss the following with a few of your neighbors. We will then discuss the question in the group before proceeding to the computer lab questions.

## 3. Polypharmacy

> A researcher wishes to gain insight into the independent management and use of polypharmacy (≥ 5 medications) by elderly home healthcare clients in relation to their cognitive and self-management skills.
Three measurement tests were assessed: the Clock-Drawing test (CDT), the Self-Management Ability Scale (SMAS-30) and the independent Medication Management Score (iMMS).
The iMMS instrument consists of 17 "yes/no" questions regarding independent medication management, where a "no" indicates lack of management ability in a particular area of medication management. The iMMS equals the number of questions that were answered with "no".
The Clock-Drawing test ("Can you draw a clock and put the hands on 10 past 11?") purports to measure the cognitive abilities of the individual, and is scored on a scale from 1 to 5 (5 being best).
The Self-Management Ability Scale (SMAS-30) consists of 30 questions on general self-management issues, and is scaled from 0 to 100.

> The researcher wishes to predict the iMMS from the CDT and SMAS-30, as well as age and sex of the individual with a generalized linear model, using one of three probability distributions: the Gaussian, binomial or Poisson distribution.

### a. 

> Give at least one advantage and one disadvantage for each of these three approaches.

iMMS is a bounded discrete variable, ranging from 0 to 17;

- Gaussian: since the range of 0-17 with steps of 1 is not very small, 
it may be approximated as a continous variable. Using the Guassian distribution 
with GLM gives the regular linear regression, which has the easiest interpretation. 
A downside is that the response is actually discrete and bounded

- binomial: this seems like a logical choice of distribution for this problem.
iMMS can be seen as the result of 17 bernoulli trials (yes/no), however,
 it may be that the trials are not independent of each other 
 (so scoring 'no' on a certain question will increase the probability of 
 scoring 'no' on another question), and that the probability of 'success' 
 on each question is not the same. This violates two of the assumptions of the
 binomial distribution. Also, the resulting coefficients are not always easy 
 interpretable depending on the chosen link function.

- Poisson: the Poisson distribution is suitable for discrete (count) variables, 
bounded by 0 as is the case here. A downside is that there exists an upper bound
here. 

### b.

> Which specific graphs from the initial data analysis step and/or the model checking step would you need to help you choose among the three approaches?

Plotting the marginal distribution of the outcome may be benificial. 
When the mean of the distribution is in the center of the range and the distribution
is approximately bell-shaped, the Gaussian approximation may be ok. However,
this ultimately depends on the error distribution of the models.

Plotting marginal distributions will not be very helpful, as each distribution 
has assumptions on the error distribution and not the marginal distribution, 
so probably model checking is best.

- For all models:

-- Calculate deviance, check which model has lowest deviance
-- Look for influential observations based on the Cook's distance


- Guassian

-- Create a fit with both explanatory variables, plot
-- QQ-plot of residuals
-- y vs pred(y) to assess homoscedasticity
-- make partial plots to assess linearity of the relationship

- Binomial


- Poisson

-- calculate dispersion parameter

## 4. Housing revisited

> We will revisit the Madsen dataset on satisfaction with housing conditions (housinglong.csv). Recall: the variable satisfaction is coded 1=low, 2=medium, 3=high; contact is coded 1=low and 2=high. 

### a.

> In question 2 we analyzed the data using a multinomial logistic regression. Why was this not the most appropriate model for examining associations between levels of satisfaction and the other variables? Fit a more suitable model and compare the results with those from (b). See if you can reduce this model, again using the LRT.

Multinomial regression assumes nominal outcome, so no order in the levels of the 
outcome. In this case, we have that class 1 < class 2 < class 3, so we have 
order. This information was disregarded by the multinomial model.

Better may be proportional odds model

```{r}
housinglong <- read.csv(here("data", "housinglong.csv"), sep = ";")
```

```{r}
require(MASS)
# fit_po1 <- polr(factor(satisfaction) ~ contact, data = housinglong)
# fit_po2 <- polr(factor(satisfaction) ~ type, data = housinglong)
fit_po3 <- polr(factor(satisfaction) ~ type + contact, data = housinglong)

drop1(fit_po3, test = "Chisq")
```

We cannot drop any of the explanatory variables.

Compare with the multinomial regression models

```{r}
fit_mn3 <- multinom(satisfaction ~ type + contact, data = housinglong)

fits <- list(multinomial = fit_mn3, proportional_odds = fit_po3)
```

```{r}
fits %>%
  map_df(function(fit) data.frame(deviance = fit$deviance,
                                  df = fit$edf,
                                  AIC = AIC(fit)), .id = "model")
```

### b.

> Comment on the AIC and residual deviance of the models from Exercises 2b and 4a.

The deviance of the multinomial model is lower. However, this model has 
more estimated parameters, as it estimates coefficients for the explanatory 
variables for 2 of the 3 levels of the response variable. 

The proportional odds model assumes the same coefficients for differences 
between class 1 and 2 and class 2 and 3, and therefore has more residual 
degrees of freedom.

This results in a lower AIC, and arguably a better fit. However, the difference 
is small.

### c.

> R users: as in Exercise 2, try to save and plot the deviance residuals from the model in (a).

```{r}
nobs = fit_po3$nobs
likl_po <- numeric(nobs)
for (i in 1:nobs) likl_po[i] <- fit_po3$fitted.values[i, housinglong$satisfaction[i]]
plot(1:nobs, -2*log(likl_po))
```

Try to compare models

```{r}
bind_rows(list(multinomial = data.frame(likl = likl), 
               proportional_odds = data.frame(likl = likl_po)), .id = "model") %>%
  mutate(loglik = -2*log(likl)) %>%
  group_by(model) %>% 
  mutate(index = 1:n(), 
         satisfaction = housinglong$satisfaction) %>%
  ggplot(aes(x = index, y = loglik, col = model)) +
  geom_point() + facet_wrap(~satisfaction, labeller = "label_both")
```


### d.

> In both SPSS and R, it is at least possible to get fitted probabilities. From the best model you obtained in (a), get the fitted probabilities per combination of type and contact. Use these to calculate the fitted frequencies (counts).
Hint: in R, use the predict() function (and the option type="probs") on a new data frame containing all combinations of type and contact; in SPSS, try aggregating the predicted values over the categories of type & contact). Use the predicted probabilities to get predicted counts and find where the largest discrepancies are between observed frequencies and expected frequencies estimated from the model.

Make a grid of the possible covariate combinations and predict probabilities.

```{r}
cov_grid <- expand.grid(
  contact = unique(housinglong$contact),
  type = sort(unique(housinglong$type))
)

grid_pred <- predict(fit_po3, newdata = cov_grid, type = "probs")
row.names(grid_pred) <- paste0(cov_grid$type, "_contact", cov_grid$contact)
grid_pred
```

Get the observed probabilities

```{r}
obs_probs <- prop.table(ftable(table(
  housinglong$type, 
  housinglong$contact, 
  housinglong$satisfaction), 
  col.vars = 3), margin = 1)
obs_probs
```

Subtract to view differences

```{r}
diff_grid <- obs_probs - grid_pred
diff_grid
```

Visualize (take absolute difference)

```{r}
image(t(abs(diff_grid)), xaxt = "n", yaxt = "n")
axis(1, at = seq(0, 1, length.out = 3), labels = 1:3, las = 1)
axis(2, at = seq(0, 1, length.out = 6), labels = rownames(grid_pred), las = 1)

```

### e. 

> For the more advanced R user: included in the R solutions for today is code to check the proportional odds assumption for the model in part (d). To do this, we need to calculate the ln(odds) of satisfaction=1 vs 2&3 and of of satisfaction=1&2 vs 3 for each level of housing type and contact and graph these. 


The advanced SPSS user can look at this link for code on checking the proportional odds assumption in SPSS http://www.ats.ucla.edu/stat/spss/dae/ologit.htm .


## 5. Esophageal cancer

> A retrospective case-control study of 200 male cases of esophageal cancer and 778 population controls was carried out in Ille-et-Vilaine (France). Interest is in the relation between tobacco consumption (tobhigh: 1 = 20+ g/day, 0 = less than 20 g/day) and esophageal cancer (case: 1 = case, 0 = control), while considering the possible confounding or effect- modifying effects of alcohol consumption (alchigh: 1 = 80+ g /day, 0 = < 80 g/day). The data can be found in bd1.sav or bd1.csv (separator = ",")

### a.

> What type of study is this? What type of analysis would you prefer for this study design?

Case-control

Logistic regression (the outcome is binary)

### b.

> Use this data to answer the research question, paying attention to the role (confounding?/effect modification?) of alcohol use.


### c.

>Do some model checking.

Deviance, 


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
