<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Wouter van Amsterdam" />

<meta name="date" content="2018-03-05" />

<title>Assignments for Generalized Linear Methods</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">epi_stats</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Assignments for Generalized Linear Methods</h1>
<h4 class="author"><em>Wouter van Amsterdam</em></h4>
<h4 class="date"><em>2018-03-05</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Update knitr chunk options -->
<!-- Insert the date the file was last updated -->
<p><strong>Last updated:</strong> 2018-03-08</p>
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
<p><strong>Code version:</strong> 1173d6b</p>
<!-- Add your analysis here -->
<div id="setup" class="section level1">
<h1>Setup</h1>
<pre class="r"><code>library(dplyr)
library(data.table)
library(magrittr)
library(purrr)
library(here) # for tracking working directory
library(ggplot2)
library(epistats)
library(broom)</code></pre>
</div>
<div id="day-1" class="section level1">
<h1>Day 1</h1>
<div id="throat" class="section level2">
<h2>1 Throat</h2>
<blockquote>
<p>Analyze the throat dataset (throat.txt or throat.sav) in R, SPSS, or both.</p>
</blockquote>
<div id="a." class="section level3">
<h3>a.</h3>
<blockquote>
<p>Examine the relation between sore throat and duration of surgery in three ways: 1) make a scatterplot of sore throat by duration of surgery; 2) make histograms of duration split by sore throat; and 3) make a plot of proportion having sore throat by duration of surgery (you’ll need to categorize duration).</p>
</blockquote>
<blockquote>
<p>In a survey of 35 patients having surgery with a general anesthetic, patients were asked whether or not they experienced a sore throat (throat=0 for no, throat=1 for yes). The duration of the surgery in minutes was also recorded, and the type of device used to secure the airway (0 = laryngeal mask airway; 1=tracheal tube)</p>
</blockquote>
<pre class="r"><code>throat &lt;- read.table(here(&quot;data&quot;, &quot;throat.txt&quot;), sep = &quot;;&quot;, header = T)
str(throat)</code></pre>
<pre><code>&#39;data.frame&#39;:   35 obs. of  4 variables:
 $ Patient: int  1 2 3 4 5 6 7 8 9 10 ...
 $ D      : int  45 15 40 83 90 25 35 65 95 35 ...
 $ T      : int  0 0 0 1 1 1 0 0 0 0 ...
 $ Y      : int  0 0 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Rename variables for easier interpretation</p>
<pre class="r"><code>throat %&lt;&gt;%
  transmute(
    patient = Patient,
    duration = D,
    sore_throat = as.logical(`T`),
    tracheal_tube = as.logical(Y))</code></pre>
<p>Scatterplot</p>
<pre class="r"><code>throat %&gt;%
  ggplot(aes(x = duration, y = sore_throat)) + 
  geom_point()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Histograms</p>
<pre class="r"><code>throat %&gt;%
  ggplot(aes(x = duration, fill = sore_throat)) + 
  geom_histogram()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Proportion sore throats by category of duration.</p>
<p>Let’s divide duration in 5 categories</p>
<p>Calculate mean duration by quantile for proper plotting</p>
<pre class="r"><code>throat %&lt;&gt;%
  mutate(duration_group = quant(duration, n.tiles = 5))

throat_grouped &lt;-throat %&gt;%
  group_by(duration_group) %&gt;%
  summarize(mean_duration = mean(duration), 
         prop_throat = mean(sore_throat))</code></pre>
<p>Plot them</p>
<pre class="r"><code>throat_grouped %&gt;%
  ggplot(aes(x = mean_duration, y = prop_throat)) + 
  geom_point() +
  lims(y = c(0,1))</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Now improved with errorbars</p>
<p>In <code>epistats</code> ther is a function that returns a proportion with a confidence interval for logical variables (without using <code>n = length(x), x = sum(x)</code>)</p>
<p>Group the data by duration group using <code>nest</code> from <code>tidyr</code> Perform the confidence interval estimation in each subset, pull out the proportions and confidence intervals.</p>
<pre class="r"><code>require(tidyr)

throat %&lt;&gt;%
  mutate(duration_group = quant(duration, n.tiles = 5))

throat_nested &lt;- throat %&gt;%
  group_by(duration_group) %&gt;%
  nest() %&gt;% 
  mutate(
    mean_duration = map(data, function(data) mean(data$duration)),
    prop = map(data, function(data) binom.confint_logical(data$sore_throat))) %&gt;%
  unnest(prop, mean_duration)

throat_nested %&gt;%
  ggplot(aes(x = mean_duration, y = mean)) + 
  geom_errorbar(aes(ymin = lower, ymax = upper)) + 
  lims(y = c(0,1)) + 
  theme_minimal() + labs(y = &quot;proportion sore throat&quot;)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="b." class="section level3">
<h3>b.</h3>
<blockquote>
<p>Fit a logistic regression model to explain the probability of sore throat as a function of duration of surgery. SPSS users: do this once using the Regression, Binary Logistic menu option, and a second time using the Generalized Linear Model menu option. Compare the results from both “methods” for estimating a logistic regression; are there differences in the parameter estimates, standard errors or maximum likelihood?</p>
</blockquote>
<pre class="r"><code>fit &lt;- glm(sore_throat ~ duration, data = throat, family = binomial(link = &quot;logit&quot;))
summary(fit)</code></pre>
<pre><code>
Call:
glm(formula = sore_throat ~ duration, family = binomial(link = &quot;logit&quot;), 
    data = throat)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.189  -1.149  -1.131   1.204   1.225  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept) -0.136898   0.658830  -0.208    0.835
duration     0.001734   0.012292   0.141    0.888

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 48.492  on 34  degrees of freedom
Residual deviance: 48.472  on 33  degrees of freedom
AIC: 52.472

Number of Fisher Scoring iterations: 3</code></pre>
</div>
<div id="c." class="section level3">
<h3>c.</h3>
<blockquote>
<p>Add the fitted logistic curve from (d) to one of the graphs in (a) (SPSS users: save the predicted probabilities from the model; use either a multiple line graph or an overlay scatterplot).</p>
</blockquote>
<pre class="r"><code>throat_nested %&lt;&gt;%
  mutate(pred = predict(fit, newdata = data.frame(duration = mean_duration), 
                        type = &quot;response&quot;))

throat_nested %&gt;%
  ggplot(aes(x = mean_duration, y = mean)) + 
  geom_errorbar(aes(ymin = lower, ymax = upper)) + 
  geom_line(aes(y = pred), lty = 2) + 
  lims(y = c(0,1)) + 
  theme_minimal() + labs(y = &quot;proportion sore throat&quot;)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="throat-2" class="section level2">
<h2>2. Throat 2</h2>
<blockquote>
<p>Continue with the analysis of the throat dataset in R, SPSS, or both (SPSS users: use the GLM menu for the modelling):</p>
</blockquote>
<div id="a.-1" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Examine the relation between sore throat and device, and between device and duration.</p>
</blockquote>
<pre class="r"><code>throat %&gt;%
  select(sore_throat, tracheal_tube, duration) %&gt;%
  mutate_if(is.logical, as.factor) %&gt;%
  GGally::ggpairs()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Patients without a tracheal tube seem to have a sore throat more often.</p>
<p>Patients with a tracheal tube seem to have a longer duration</p>
</div>
<div id="b.-1" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Fit a logistic regression model to explain the probability of sore throat as a function of type of device. Get the Wald and profile likelihood</p>
</blockquote>
<pre class="r"><code>fit2 &lt;- glm(sore_throat ~ tracheal_tube, data = throat, family = binomial(link = &quot;logit&quot;)) 
summary(fit2)</code></pre>
<pre><code>
Call:
glm(formula = sore_throat ~ tracheal_tube, family = binomial(link = &quot;logit&quot;), 
    data = throat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5353  -0.9508  -0.9508   0.8576   1.4224  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)         0.8109     0.6009   1.349   0.1772  
tracheal_tubeTRUE  -1.3705     0.7467  -1.836   0.0664 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 48.492  on 34  degrees of freedom
Residual deviance: 44.889  on 33  degrees of freedom
AIC: 48.889

Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>confint(fit2)</code></pre>
<pre><code>                      2.5 %     97.5 %
(Intercept)       -0.310979 2.11680249
tracheal_tubeTRUE -2.929278 0.04379487</code></pre>
<p>Both Wald test and profile likelihood agree that tracheal tube is not significant.</p>
</div>
<div id="c.-1" class="section level3">
<h3>c.</h3>
<blockquote>
<p>Fit the remaining models from the lecture and interpret the output.</p>
</blockquote>
<pre class="r"><code>fit2 &lt;- glm(sore_throat ~ tracheal_tube + duration, data = throat, family = binomial(link = &quot;logit&quot;))
fit3 &lt;- glm(sore_throat ~ duration * tracheal_tube, data = throat, family = binomial(link = &quot;logit&quot;))

summary(fit3)</code></pre>
<pre><code>
Call:
glm(formula = sore_throat ~ duration * tracheal_tube, family = binomial(link = &quot;logit&quot;), 
    data = throat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.9459  -0.7546  -0.5331   0.7840   2.0107  

Coefficients:
                           Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept)                 2.66116    1.49224   1.783  0.07453 . 
duration                   -0.06208    0.04295  -1.445  0.14833   
tracheal_tubeTRUE          -5.52029    2.01592  -2.738  0.00617 **
duration:tracheal_tubeTRUE  0.10127    0.04791   2.114  0.03454 * 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 48.492  on 34  degrees of freedom
Residual deviance: 37.908  on 31  degrees of freedom
AIC: 45.908

Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>AIC(fit2, fit3)</code></pre>
<pre><code>     df      AIC
fit2  3 49.10924
fit3  4 45.90770</code></pre>
<p>There seems to be a significant interaction between tracheal tube and duration, according to both the p-value from the fit summary and the AIC.</p>
<p>Without the tracheal tube, the duration of the procedure does not seem to matter. The tracheal tube itselve is protective for sore throat. For patients with a tracheal tube, increased duration is associated with higher odds of sore throat</p>
</div>
<div id="section" class="section level3">
<h3>3.</h3>
<blockquote>
<p>Optional in R: continue with the analysis of the throat dataset, and repeat the model diagnostics. For saving, “binning” and plotting the binned residuals, see the script provided.</p>
</blockquote>
<pre class="r"><code>plot(fit3)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-14-2.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-14-3.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-14-4.png" width="672" style="display: block; margin: auto;" /></p>
<p>Use binning (adapted from provided script)</p>
<pre class="r"><code>throat %&lt;&gt;%
  mutate(
    residuals = residuals(fit3),
    linpred = predict(fit3, type = &quot;link&quot;)
  )

throat %&gt;%
  mutate(pred_cat = quant(linpred, n.tiles = 10)) %&gt;%
  group_by(pred_cat) %&gt;%
  summarize(residuals = mean(residuals),
            linpred = mean(linpred)) %&gt;%
  ggplot(aes(x = linpred, y = residuals)) +
  geom_point()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This should be unstructured.</p>
</div>
</div>
<div id="section-1" class="section level2">
<h2>4</h2>
<blockquote>
<p>The R script GLM computer lab1 analyses.R contains the beginnings of an analysis of the ICU dataset (ICU.RData, ICU.sav). Use and expand on this script in R (or use SPSS) to answer the following questions. a. (SPSS users note: this is not entirely possible, see answers to 1a&amp;c for compromise.) Examine the relation between status and systolic blood pressure (SYS). Try to make a graph of this relation, similar to the graph of status vs. age in the lecture notes (bottom left graph on slide 60). Compare this plot to the systolic blood pressure plot on slide 61 of the lecture notes. What is different in how this new plot has been made? b. Fit a logistic regression model using only systolic blood pressure (SYS) to predict status. What is the odds ratio for dying (status = dead) for a 10 unit increase in systolic blood pressure? c. What assumption does the model in 3(b) make about dying and SYS? Do you think that assumption is met? d. Examine the relation between status and level of consciousness (LOC) in a contingency table. What do you notice? What problems might this give in the model fitting? e. Fit a logistic regression model using LOC to predict status. Comment on the estimates and standard errors for the regression coefficients.</p>
</blockquote>
<blockquote>
<p>This dataset will be considered for further analysis on days 2 and 3.</p>
</blockquote>
<pre class="r"><code># fit_all &lt;- ...
# stepAIC(fit_all)

# check assumptions (binned deviance, by variable)</code></pre>
<p>This assignment was skipped due to time-limitations and it being discussed during the lecture.</p>
</div>
<div id="section-2" class="section level2">
<h2>5.</h2>
<blockquote>
<p>Can we predict birth weight using gestational age? Is the prediction the same for boys and girls? a. Use the dataset bwt_gestage.csv to answer these questions. Note: sex = 1 are the boys, sex = 2 are the girls. b. Interpret your findings. c. Fit the final model from (a) using both the lm() and glm() functions in R. Compare the parameter estimates and standard errors from the two methods of fitting a linear model. d. Repeat (c) using both the Regression, Linear and the Generalized Linear Models procedures in SPSS. Compare the parameter estimates and standard errors from the two methods of fitting a linear model. What do you notice?</p>
</blockquote>
</div>
<div id="section-3" class="section level2">
<h2>6.</h2>
<blockquote>
<p>We wish to find factors that influence the probability that a low birth weight infant (&lt;1500 g) will experience a germinal matrix hemorrhage. A sample of 100 low birth weight newborns was retrospectively collected in a hospital in Boston, MA. Factors possibly indicative of a germinal matrix hemorrhage were extracted from a chart review and included sex, head circumference, systolic blood pressure and gestational age of the infant, and whether the mother suffered from toxemia during the pregnancy. Use the dataset lowbwt.txt to predict the probability of hemorrhage. (Note: the dichotomous variables are defined as follows: sex=1 is a male, tox=1 is toxemia, grmhem=1 hemorrhage.) a. Start by describing the data, get a sense of the relations between the potential explanatory variables and the outcome. b. Construct a model to predict occurrence of germinal matrix hemorrhage. c. Interpret your findings.</p>
</blockquote>
</div>
<div id="section-4" class="section level2">
<h2>7.</h2>
<blockquote>
<p>The dataset epilepsy in the R library HSAUR (or the SPSS file epilepsy.sav) contains data from a clinical trial on 59 patients suffering from epilepsy. Patients were randomized to groups receiving either an anti-epileptic drug or a placebo, in addition to standard chemotherapy. N.B. If you’re working in R and you’ve loaded the faraway library, unload it now! Otherwise you may end up with the wrong epilepsy data frame (both faraway and HSAUR contain data frames with different structures but the same name): detach(“package:faraway”). Get some information about this data frame by loading the HSAUR library and using help(epilepsy). This is data from a longitudinal trial; we will use only the data from the last two-week period. We are interested in whether the probability of seizure is higher in the treatment or control group in this period. a. Start by making a selection of the data for period 4 and making a new variable for seizure yes/no. b. Get some descriptive statistics for the data, get a sense of the relations between the potential explanatory variables and the dichotomous outcome seizure. c. What type of variable is seizure.rate? d. Give two reasons why a logistic regression model is not the most appropriate way to analyze this data.</p>
</blockquote>
</div>
</div>
<div id="day-2" class="section level1">
<h1>Day 2</h1>
<div id="section-5" class="section level2">
<h2>1.</h2>
<blockquote>
<p>The R script ICU analyses day 2.R contains the beginnings of an analysis of the ICU dataset (ICU.RData, ICU.sav). Use and expand on this script in R (or use SPSS) to answer the following questions.</p>
</blockquote>
<p>Setup</p>
<pre class="r"><code># Analyses of throat and ICU datasets for day 2 GLM course

library(gmodels)
library(splines)
library(HSAUR)

load(here(&quot;data&quot;, &quot;ICU.RData&quot;))
str(ICU)</code></pre>
<pre><code>&#39;data.frame&#39;:   200 obs. of  22 variables:
 $ ID    : num  8 12 14 28 32 38 40 41 42 50 ...
 $ STA   : Factor w/ 2 levels &quot;Alive&quot;,&quot;Dead&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ AGE   : num  27 59 77 54 87 69 63 30 35 70 ...
 $ AGECAT: num  30 60 80 50 90 70 60 30 40 70 ...
 $ SEX   : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 2 1 1 1 2 1 1 2 1 2 ...
 $ RACE  : Factor w/ 3 levels &quot;White&quot;,&quot;Black&quot;,..: 1 1 1 1 1 1 1 1 2 1 ...
 $ SER   : Factor w/ 2 levels &quot;Medical&quot;,&quot;Surgical&quot;: 1 1 2 1 2 1 2 1 1 2 ...
 $ CAN   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 2 ...
 $ CRN   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ INF   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 1 1 2 2 2 1 1 1 1 ...
 $ CPR   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ SYS   : num  142 112 100 142 110 110 104 144 108 138 ...
 $ HRA   : num  88 80 70 103 154 132 66 110 60 103 ...
 $ PRE   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 2 1 1 1 1 1 ...
 $ TYP   : Factor w/ 2 levels &quot;Elective&quot;,&quot;Emergency&quot;: 2 2 1 2 2 2 1 2 2 1 ...
 $ FRA   : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 2 1 1 1 1 1 1 ...
 $ PO2   : Factor w/ 2 levels &quot;&gt; 60&quot;,&quot;&lt;= 60&quot;: 1 1 1 1 1 2 1 1 1 1 ...
 $ PH    : Factor w/ 2 levels &quot;&gt;= 7.25&quot;,&quot;&lt; 7.25&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ PCO   : Factor w/ 2 levels &quot;&lt;= 45&quot;,&quot;&gt; 45&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ BIC   : Factor w/ 2 levels &quot;&gt;= 18&quot;,&quot;&lt; 18&quot;: 1 1 1 1 1 2 1 1 1 1 ...
 $ CRE   : Factor w/ 2 levels &quot;&lt;= 2.0&quot;,&quot;&gt; 2.0&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ LOC   : Factor w/ 3 levels &quot;No Coma or Stupor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, &quot;variable.labels&quot;)= Named chr  &quot;Identification Code&quot; &quot;Status&quot; &quot;Age in Years&quot; &quot;Age Class&quot; ...
  ..- attr(*, &quot;names&quot;)= chr  &quot;ID&quot; &quot;STA&quot; &quot;AGE&quot; &quot;AGECAT&quot; ...
 - attr(*, &quot;codepage&quot;)= int 1252</code></pre>
<div id="a.-2" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Examine the relation between status (STA) and type of admission (TYP).</p>
</blockquote>
<pre class="r"><code>CrossTable(ICU$TYP, ICU$STA, prop.c=FALSE, prop.t=FALSE, prop.chisq=FALSE) </code></pre>
<pre><code>
 
   Cell Contents
|-------------------------|
|                       N |
|           N / Row Total |
|-------------------------|

 
Total Observations in Table:  200 

 
             | ICU$STA 
     ICU$TYP |     Alive |      Dead | Row Total | 
-------------|-----------|-----------|-----------|
    Elective |        52 |         2 |        54 | 
             |     0.963 |     0.037 |     0.270 | 
-------------|-----------|-----------|-----------|
   Emergency |       108 |        38 |       146 | 
             |     0.740 |     0.260 |     0.730 | 
-------------|-----------|-----------|-----------|
Column Total |       160 |        40 |       200 | 
-------------|-----------|-----------|-----------|

 </code></pre>
</div>
<div id="b.-2" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Fit a logistic regression model using TYP to predict status. Express the results as OR and 95% CI.</p>
</blockquote>
<pre class="r"><code>icu.m1 &lt;- glm(formula = STA ~ TYP, family = binomial(link = &quot;logit&quot;), data=ICU)
summary(icu.m1)</code></pre>
<pre><code>
Call:
glm(formula = STA ~ TYP, family = binomial(link = &quot;logit&quot;), data = ICU)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7765  -0.7765  -0.7765  -0.2747   2.5674  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -3.2581     0.7203  -4.523 6.08e-06 ***
TYPEmergency   2.2136     0.7446   2.973  0.00295 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 200.16  on 199  degrees of freedom
Residual deviance: 184.52  on 198  degrees of freedom
AIC: 188.52

Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>exp(coefficients(icu.m1))</code></pre>
<pre><code> (Intercept) TYPEmergency 
  0.03846155   9.14814450 </code></pre>
<pre class="r"><code>exp(confint(icu.m1))</code></pre>
<pre><code>                   2.5 %     97.5 %
(Intercept)  0.006293049  0.1235554
TYPEmergency 2.658796276 57.5739571</code></pre>
</div>
<div id="c.-2" class="section level3">
<h3>c.</h3>
<blockquote>
<p>Fit two binomial models producing the Risk Ratio and Risk Difference, with their 95% CI.</p>
</blockquote>
<pre class="r"><code># &quot;relative risk&quot; regression: link=log, family = binomial
icu.m2 &lt;- glm(formula = STA ~ TYP, family = binomial(link = &quot;log&quot;), data=ICU)
summary(icu.m2)</code></pre>
<pre><code>
Call:
glm(formula = STA ~ TYP, family = binomial(link = &quot;log&quot;), data = ICU)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7765  -0.7765  -0.7765  -0.2747   2.5674  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -3.2958     0.6938  -4.750 2.03e-06 ***
TYPEmergency   1.9498     0.7077   2.755  0.00587 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 200.16  on 199  degrees of freedom
Residual deviance: 184.52  on 198  degrees of freedom
AIC: 188.52

Number of Fisher Scoring iterations: 6</code></pre>
<pre class="r"><code>exp(coefficients(icu.m2))</code></pre>
<pre><code> (Intercept) TYPEmergency 
  0.03703704   7.02739702 </code></pre>
<pre class="r"><code>exp(confint(icu.m2))</code></pre>
<pre><code>                   2.5 %     97.5 %
(Intercept)  0.006254798  0.1099454
TYPEmergency 2.265999444 42.2886756</code></pre>
<pre class="r"><code># &quot;risk difference&quot; regression: link=identity, family = binomial
# Note: do not exponentiate coeff &amp; CI
icu.m3 &lt;- glm(formula = STA ~ TYP, family = binomial(link = &quot;identity&quot;), data=ICU)
summary(icu.m3)</code></pre>
<pre><code>
Call:
glm(formula = STA ~ TYP, family = binomial(link = &quot;identity&quot;), 
    data = ICU)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7765  -0.7765  -0.7765  -0.2747   2.5674  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.03704    0.02570   1.441     0.15    
TYPEmergency  0.22324    0.04449   5.018 5.22e-07 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 200.16  on 199  degrees of freedom
Residual deviance: 184.52  on 198  degrees of freedom
AIC: 188.52

Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code># confint(icu.m3)
confint.default(icu.m3)</code></pre>
<pre><code>                   2.5 %     97.5 %
(Intercept)  -0.01333321 0.08740729
TYPEmergency  0.13604217 0.31043170</code></pre>
<p>For the identity link, likihood profiling for confidence intervals does not work. Possibly due to inadmissable values in the range of the profile.</p>
</div>
<div id="d." class="section level3">
<h3>d.</h3>
<blockquote>
<p>Fit two further binomial models using the probit link and the cloglog link.</p>
</blockquote>
<pre class="r"><code># probit link
icu.m4 &lt;- glm(formula = STA ~ TYP, family = binomial(link = &quot;probit&quot;), data=ICU)
summary(icu.m4)</code></pre>
<pre><code>
Call:
glm(formula = STA ~ TYP, family = binomial(link = &quot;probit&quot;), 
    data = ICU)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7765  -0.7765  -0.7765  -0.2747   2.5674  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -1.7862     0.3175  -5.625 1.85e-08 ***
TYPEmergency   1.1437     0.3367   3.397 0.000681 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 200.16  on 199  degrees of freedom
Residual deviance: 184.52  on 198  degrees of freedom
AIC: 188.52

Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code># cloglog link
icu.m5 &lt;- glm(formula = STA ~ TYP, family = binomial(link = &quot;cloglog&quot;), data=ICU)
summary(icu.m5)</code></pre>
<pre><code>
Call:
glm(formula = STA ~ TYP, family = binomial(link = &quot;cloglog&quot;), 
    data = ICU)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7765  -0.7765  -0.7765  -0.2747   2.5674  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -3.2770     0.7071  -4.634 3.58e-06 ***
TYPEmergency   2.0780     0.7257   2.864  0.00419 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 200.16  on 199  degrees of freedom
Residual deviance: 184.52  on 198  degrees of freedom
AIC: 188.52

Number of Fisher Scoring iterations: 6</code></pre>
</div>
<div id="e." class="section level3">
<h3>e.</h3>
<blockquote>
<p>Decide which link gives the best fitting model, based on deviance or AIC</p>
</blockquote>
<pre class="r"><code>AIC(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5)</code></pre>
<pre><code>       df      AIC
icu.m1  2 188.5246
icu.m2  2 188.5246
icu.m3  2 188.5246
icu.m4  2 188.5246
icu.m5  2 188.5246</code></pre>
<p>All have equivalent AIC.</p>
<pre class="r"><code>list(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5) %&gt;%
  map_dbl(deviance)</code></pre>
<pre><code>[1] 184.5246 184.5246 184.5246 184.5246 184.5246</code></pre>
<p>All have equivalent deviance</p>
</div>
</div>
<div id="section-6" class="section level2">
<h2>2.</h2>
<blockquote>
<p>Repeat the analyses 1a-d for the continuous variable SYS, being systolic blood pressure.</p>
</blockquote>
<p>The identity link required starting values to work</p>
<pre class="r"><code>try(fit_id &lt;- glm(STA ~ SYS, data = ICU, family = binomial(link = &quot;identity&quot;),
                  start = c(mean(ICU$STA == &quot;Dead&quot;), 0)))</code></pre>
<pre><code>Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence

Warning: step size truncated due to divergence</code></pre>
<pre><code>Warning: glm.fit: algorithm did not converge</code></pre>
<pre><code>Warning: glm.fit: algorithm stopped at boundary value</code></pre>
<p>The rest we can do in one line</p>
<pre class="r"><code>links = list(&quot;logit&quot;, &quot;log&quot;, &quot;probit&quot;, &quot;cloglog&quot;)

fits &lt;- links %&gt;%
  map(function(link) glm(STA ~ SYS, data = ICU, family = binomial(link = link)))

links &lt;- c(links, &quot;identity&quot;)
fits[[length(fits)+1]]  &lt;- fit_id

data.frame(link = unlist(links), 
           aic = map_dbl(fits, AIC),
           deviance = map_dbl(fits, AIC))</code></pre>
<pre><code>      link      aic deviance
1    logit 195.3351 195.3351
2      log 193.5661 193.5661
3   probit 196.2581 196.2581
4  cloglog 194.5699 194.5699
5 identity 199.5667 199.5667</code></pre>
<div id="a.-3" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Decide which link now gives the best fitting model, based on deviance or AIC</p>
</blockquote>
<p>The log link gives the lowest AIC, so this is the best fit.</p>
</div>
<div id="b.-3" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Discuss the difference with 1e</p>
</blockquote>
<p>With this continous predictor, there is a difference in AICs between the models.</p>
<p>In the previous case with only a single binary predictor, there are only two possible values for the predicted probability of survival, regardless of the link function: <span class="math inline">\(\hat{p}_0\)</span> for unexposed, <span class="math inline">\(\hat{p}_1\)</span> for exposed. Each set of values for <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p_1\)</span> gives rise to a single value of the resulting likelihood. Since all glm models are fitted according to the same criterion of maximum likelihood, they will all find the same values for <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p_1\)</span>.</p>
<p>We can check this by looking at the values of the predictions</p>
<pre class="r"><code>list(icu.m1, icu.m2, icu.m3, icu.m4, icu.m5) %&gt;%
  map(&quot;fitted.values&quot;) %&gt;%
  map(unique)</code></pre>
<pre><code>[[1]]
[1] 0.26027397 0.03703705

[[2]]
[1] 0.26027397 0.03703704

[[3]]
[1] 0.26027397 0.03703704

[[4]]
[1] 0.26027397 0.03703704

[[5]]
[1] 0.26027397 0.03703704</code></pre>
<p>In the case of the continous predictor, the predicted probability takes on more values, and now the different link functions start to matter for the model fit.</p>
</div>
<div id="c.-3" class="section level3">
<h3>c.</h3>
<blockquote>
<p>The logistic model may be improved by introducing a non-linear effect of SYS. One possible way of achieving this is to add a quadratic term to the model. In R, you may also use a flexible natural spline model (use function ns from library splines in the model specification). Check whether model fit improves.</p>
</blockquote>
<pre class="r"><code>require(splines)
fit_logit1 &lt;- glm(STA ~ SYS + I(SYS^2), data = ICU, family = binomial(link = &quot;logit&quot;))
fit_logit2 &lt;- glm(STA ~ ns(SYS, df = 2), data = ICU, family = binomial(link = &quot;logit&quot;))
fit_logit3 &lt;- glm(STA ~ ns(SYS, df = 3), data = ICU, family = binomial(link = &quot;logit&quot;))

AIC(fit_logit1, fit_logit2, fit_logit3)</code></pre>
<pre><code>           df      AIC
fit_logit1  3 189.6764
fit_logit2  3 190.4331
fit_logit3  4 191.9052</code></pre>
<p>The spline seems to increase model fit, however including more complicated splines does not.</p>
</div>
</div>
<div id="section-7" class="section level2">
<h2>3.</h2>
<blockquote>
<p>The dataset epilepsy.RData (or the SPSS file epilepsy.sav) contains data from a clinical trial on 59 patients suffering from epilepsy. Patients were randomized to groups receiving either an anti-epileptic drug or a placebo, in addition to standard chemotherapy. This is data from a longitudinal trial; we will use only the data from the last two-week period. We are interested in whether the seizure rate is higher in the treatment or control group in this period. This dataset has already been used in yesterday’s computer lab and today’s lecture.</p>
</blockquote>
<pre class="r"><code>load(here(&quot;data&quot;, &quot;epilepsy.RData&quot;))
str(epilepsy)</code></pre>
<pre><code>&#39;data.frame&#39;:   236 obs. of  6 variables:
 $ treatmnt: Factor w/ 2 levels &quot;placebo&quot;,&quot;Progabide&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ base    : num  11 11 11 11 11 11 11 11 6 6 ...
 $ age     : num  31 31 31 31 30 30 30 30 25 25 ...
 $ seizr.rt: num  5 3 3 3 3 5 3 3 2 4 ...
 $ period  : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 2 3 4 1 2 3 4 1 2 ...
 $ subject : Factor w/ 59 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 2 2 2 2 3 3 ...
 - attr(*, &quot;variable.labels&quot;)= Named chr  &quot;treatment&quot; &quot;base&quot; &quot;age&quot; &quot;seizure.rate&quot; ...
  ..- attr(*, &quot;names&quot;)= chr  &quot;treatmnt&quot; &quot;base&quot; &quot;age&quot; &quot;seizr.rt&quot; ...
 - attr(*, &quot;codepage&quot;)= int 1252</code></pre>
<div id="a.-4" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Start by making a selection of the data for period 4.</p>
</blockquote>
<pre class="r"><code>epi4 &lt;- epilepsy %&gt;% filter(period == &quot;4&quot;)
str(epi4)</code></pre>
<pre><code>&#39;data.frame&#39;:   59 obs. of  6 variables:
 $ treatmnt: Factor w/ 2 levels &quot;placebo&quot;,&quot;Progabide&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ base    : num  11 11 6 8 66 27 12 52 23 10 ...
 $ age     : num  31 30 25 36 22 29 31 42 37 28 ...
 $ seizr.rt: num  3 3 5 4 21 7 2 12 5 0 ...
 $ period  : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 4 4 4 4 4 4 4 4 4 4 ...
 $ subject : Factor w/ 59 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
 - attr(*, &quot;variable.labels&quot;)= Named chr  &quot;treatment&quot; &quot;base&quot; &quot;age&quot; &quot;seizure.rate&quot; ...
  ..- attr(*, &quot;names&quot;)= chr  &quot;treatmnt&quot; &quot;base&quot; &quot;age&quot; &quot;seizr.rt&quot; ...
 - attr(*, &quot;codepage&quot;)= int 1252</code></pre>
</div>
<div id="b.-4" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Repeat the analysis from today’s lecture. Comment on the impact of adjustment for the baseline seizure rate. Pay attention to the fact that this is a randomized trial.</p>
</blockquote>
<p>First some marginal distributions for treatment groups</p>
<pre class="r"><code>epi4 %&gt;%
  as.data.table() %&gt;%
  melt.data.table(id.vars = c(&quot;subject&quot;, &quot;treatmnt&quot;), 
                  measure.vars = c(&quot;base&quot;, &quot;age&quot;, &quot;seizr.rt&quot;)) %&gt;%
  ggplot(aes(x = treatmnt, y = value)) + 
  geom_boxplot() +
  facet_wrap(~variable)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Looks like the covariates base and age are equally distributed among treatment groups, and seizure rate seems a bit lower in the treatment group.</p>
<p>Now for the covariate-outcome distributions:</p>
<pre class="r"><code>epi4 %&gt;%
  ggplot(aes(x = base, y = seizr.rt)) + 
  geom_point()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-31-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>epi4 %&gt;%
  ggplot(aes(x = age, y = seizr.rt)) + 
  geom_point()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-31-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Clear correlation between base rate and follow-up seizure rate. No clear marginal correlation between age and seizure rate at follow-up</p>
<p>Model with poisson</p>
<pre class="r"><code>fit1 &lt;- glm(seizr.rt ~ treatmnt, family = poisson, data = epi4)
summary(fit1)</code></pre>
<pre><code>
Call:
glm(formula = seizr.rt ~ treatmnt, family = poisson, data = epi4)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.9911  -2.0175  -1.1319   0.4214  13.0233  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        2.07497    0.06696  30.986   &lt;2e-16 ***
treatmntProgabide -0.17142    0.09640  -1.778   0.0754 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 476.25  on 58  degrees of freedom
Residual deviance: 473.08  on 57  degrees of freedom
AIC: 664.85

Number of Fisher Scoring iterations: 6</code></pre>
<p>Adjusted for base rate</p>
<pre class="r"><code>fit2 &lt;- glm(seizr.rt ~ treatmnt + log(base), family = poisson, data = epi4)
summary(fit2)</code></pre>
<pre><code>
Call:
glm(formula = seizr.rt ~ treatmnt + log(base), family = poisson, 
    data = epi4)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.6907  -1.2423  -0.0527   0.8498   3.5874  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)       -1.91906    0.25818  -7.433 1.06e-13 ***
treatmntProgabide -0.19920    0.09640  -2.066   0.0388 *  
log(base)          1.15056    0.06554  17.556  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 476.25  on 58  degrees of freedom
Residual deviance: 147.75  on 56  degrees of freedom
AIC: 341.51

Number of Fisher Scoring iterations: 5</code></pre>
<p>Effect seems somewhat stronger after adjustment for base-rate</p>
</div>
<div id="c.-4" class="section level3">
<h3>c.</h3>
<blockquote>
<p>Examine the effects of further adjustment.</p>
</blockquote>
<pre class="r"><code>fit3 &lt;- glm(seizr.rt ~ treatmnt + log(base) + age, family = poisson, data = epi4)
summary(fit3)</code></pre>
<pre><code>
Call:
glm(formula = seizr.rt ~ treatmnt + log(base) + age, family = poisson, 
    data = epi4)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.5962  -1.1318   0.1552   0.8062   3.6635  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)       -2.33017    0.40583  -5.742 9.37e-09 ***
treatmntProgabide -0.15726    0.10144  -1.550    0.121    
log(base)          1.17365    0.06819  17.211  &lt; 2e-16 ***
age                0.01100    0.00823   1.337    0.181    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 476.25  on 58  degrees of freedom
Residual deviance: 145.98  on 55  degrees of freedom
AIC: 341.74

Number of Fisher Scoring iterations: 5</code></pre>
<p>After adjusting for age, treatment is no longer significant.</p>
<pre class="r"><code>AIC(fit1, fit2, fit3)</code></pre>
<pre><code>     df      AIC
fit1  2 664.8524
fit2  3 341.5144
fit3  4 341.7444</code></pre>
<p>Adding age to the model results in a slightly worse fit according to the AIC.</p>
<p>However, model fit is not the primary goal for causal research.</p>
<p>Let’s look at model diagnostics of the fits</p>
<pre class="r"><code>plot(fit2, which = 5)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(fit3, which = 5)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-36-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>Observation 49 seems to have a strong effect on the model</p>
</div>
</div>
<div id="day-3-model-diagnostics" class="section level2">
<h2>Day 3 Model diagnostics</h2>
<div id="epilepsy" class="section level3">
<h3>1. epilepsy</h3>
<p>Covered in class</p>
<pre class="r"><code>library(HSAUR)
data(epilepsy, package = &quot;HSAUR&quot;)
epi &lt;- epilepsy[epilepsy$period==4,]
summary(epi)</code></pre>
<pre><code>     treatment       base             age         seizure.rate    period
 placebo  :28   Min.   :  6.00   Min.   :18.00   Min.   : 0.000   1: 0  
 Progabide:31   1st Qu.: 12.00   1st Qu.:23.00   1st Qu.: 3.000   2: 0  
                Median : 22.00   Median :28.00   Median : 4.000   3: 0  
                Mean   : 31.22   Mean   :28.34   Mean   : 7.305   4:59  
                3rd Qu.: 41.00   3rd Qu.:32.00   3rd Qu.: 8.000         
                Max.   :151.00   Max.   :42.00   Max.   :63.000         
                                                                        
    subject  
 1      : 1  
 2      : 1  
 3      : 1  
 4      : 1  
 5      : 1  
 6      : 1  
 (Other):53  </code></pre>
<p>Plot marginal distributions</p>
<pre class="r"><code>epi %&gt;%
  select(-period) %&gt;%
  gather(-treatment, -subject, -seizure.rate, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;%
  ggplot(aes(x = value, y = seizure.rate)) +
  geom_point() + geom_smooth() +
  facet_wrap(~variable, scales = &quot;free_x&quot;) + 
  theme_minimal()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Look at extreme cases</p>
<pre class="r"><code>epi %&gt;%
  filter(seizure.rate == max(seizure.rate))</code></pre>
<pre><code>  treatment base age seizure.rate period subject
1 Progabide  151  22           63      4      49</code></pre>
<div id="linear-model" class="section level4">
<h4>Linear model</h4>
<pre class="r"><code>fit_lm &lt;- lm(seizure.rate ~ age + base +treatment, data = epi)
plot(fit_lm)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-40-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-40-2.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-40-3.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-40-4.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li>no homoscedasticity</li>
<li>non-normal distrubtion of residuals</li>
</ul>
</div>
<div id="transform-variables" class="section level4">
<h4>Transform variables</h4>
<pre class="r"><code>epi %&gt;%
  mutate(log_base = log(base + 0.5)) %&gt;%
  select(-period) %&gt;%
  gather(-treatment, -subject, -seizure.rate, key = &quot;variable&quot;, value = &quot;xvalue&quot;) %&gt;%
  mutate(log_sr = log(seizure.rate + 0.5)) %&gt;%
  gather(seizure.rate, log_sr, key = &quot;outcome&quot;, value = &quot;yvalue&quot;) %&gt;%
  ggplot(aes(x = xvalue, y = yvalue)) +
  geom_point() + geom_smooth() +
  facet_grid(outcome~variable, scales = &quot;free&quot;) + 
  theme_minimal()</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-41-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>fit_lm_log &lt;- lm(log(seizure.rate + 0.5) ~ age + log(base + 0.5) + treatment, data = epi)
plot(fit_lm_log)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-42-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-42-2.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-42-3.png" width="672" style="display: block; margin: auto;" /><img src="figure/glm_assignments.Rmd/unnamed-chunk-42-4.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="partial-plot" class="section level4">
<h4>Partial plot</h4>
<p>Linear relationship between residuals of a model without the variable</p>
<p>Create a function for partial plots</p>
<pre class="r"><code>partial_residuals.lm &lt;- function(fit, term, resid_type = &quot;response&quot;) {
  formula0  = formula(fit)
  all_vars  = all.vars(formula0)
  response  = all_vars[1]
  all_terms = all_vars[-1]
  new_terms = setdiff(all_terms, term)
  
  fit_resp &lt;- lm(reformulate(new_terms, response), data = fit$model)
  fit_term &lt;- lm(reformulate(new_terms, term), data = fit$model)
  
  return(
    data.frame(resid_response = resid(fit_resp, type = resid_type),
               resid_term     = resid(fit_term, type = resid_type))
  )
}

partial_plots.lm &lt;- function(fit, terms = NULL) {
  formula0  = formula(fit)
  all_vars  = all.vars(formula0)
  response  = all_vars[1]
  all_terms = all_vars[-1]

  terms = if (!is.null(terms)) {terms} else {all_terms}

  resid_data = pmap_df(list(terms), function(term) {
    data.frame(term = term, 
               partial_residuals.lm(fit, term))
    })
  
  p = ggplot(resid_data, aes(x = resid_term, y = resid_response)) + 
    geom_point() + geom_smooth() + 
    facet_wrap(~term, scales = &quot;free_x&quot;) + 
    theme_minimal() + labs(y = paste0(&quot;Residual of &quot;, response))
  print(p)
  
  return(resid_data)
  
}

partial_plots.lm(fit_lm)</code></pre>
<pre><code>Warning in model.response(mf, &quot;numeric&quot;): using type = &quot;numeric&quot; with a
factor response will be ignored</code></pre>
<pre><code>Warning in Ops.factor(y, z$residuals): &#39;-&#39; not meaningful for factors</code></pre>
<pre><code>Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character</code></pre>
<pre><code>Warning in bind_rows_(x, .id): binding character and factor vector,
coercing into character vector

Warning in bind_rows_(x, .id): binding character and factor vector,
coercing into character vector

Warning in bind_rows_(x, .id): binding character and factor vector,
coercing into character vector</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-43-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>         term resid_response  resid_term
1         age     1.02096887   1.1303630
2         age     1.02096887   0.1303630
3         age     4.53348808  -5.0894009
4         age     2.92848040   5.9985047
5         age     2.38325756  -5.4522345
6         age     0.18090740  -0.1663926
7         age    -0.28153497   1.1743158
8         age    -2.38168865  13.9324267
9         age    -0.60907723   7.6577963
10        age    -1.67652728  -1.9135898
11        age     7.61831135   7.9324267
12        age    -4.63411565  -4.9026760
13        age    -2.09655802  -6.5619676
14        age     2.64334977   7.4928989
15        age   -15.96932312  -0.5292263
16        age    -8.77668096  -2.1554789
17        age    -1.09655802  -1.5619676
18        age    -3.22941532   5.5256403
19        age     0.90344198   2.4380324
20        age     2.29843430  -8.4740620
21        age     1.71846503  -0.8256842
22        age     2.62597656  -8.9575425
23        age     1.20594582   2.3940796
24        age     0.87840356  -4.1224399
25        age     9.71079983   2.0642850
26        age    -0.37402344  10.0424575
27        age     0.32347272 -10.9135898
28        age    -0.86916944  -6.2873372
29        age   -12.13694473  -7.7909995
30        age    -4.64179873   4.5387951
31        age    -2.89422574  -8.2963076
32        age     2.82830884   1.3081175
33        age     1.10577426 -10.2963076
34        age    -1.40674494  -4.0765437
35        age     9.47572816   2.2311257
36        age     2.61829347   6.4839286
37        age     3.52580500  -1.6479297
38        age   -10.41441015  -6.1865745
39        age    -4.54931026  -5.3293466
40        age     0.73582037  -0.8237408
41        age    -3.80173726  -5.1644492
42        age     1.92079732  11.4399758
43        age     3.93817053   5.8904173
44        age    -0.03679105  -6.5491104
45        age    -1.64179873   7.5387951
46        age     3.73582037  -3.8237408
47        age    -0.03679105  -1.5491104
48        age    -0.47419500  -3.6479297
49        age    20.17526712  -0.4945416
50        age     0.19826274   3.8355508
51        age    -2.54931026  -2.3293466
52        age    -1.82677568   7.2750785
53        age    -1.08686789  -5.6700550
54        age    -4.40674494  12.9234563
55        age     1.01328579   3.5718341
56        age     4.19826274  -2.1644492
57        age    -3.70924879  -7.0325909
58        age    -1.07920268   7.4399758
59        age     1.22330116   8.3960230
60       base    -4.70610071 -18.1706714
61       base    -4.83519321 -18.9781929
62       base    -3.48065573 -28.0158000
63       base    -3.06063819 -17.1330642
64       base    12.13206676  29.5616357
65       base    -0.96428571  -3.7857143
66       base    -5.70610071 -17.1706714
67       base     5.71391684  31.7120644
68       base    -1.93154568  -1.3255428
69       base    -8.09337822 -21.5932357
70       base    14.93936181  26.8669358
71       base    -4.60974823  -1.8233215
72       base    -6.73884074 -17.6308429
73       base     6.93936181  16.8669358
74       base     0.64843677  53.7917214
75       base    -3.35156323  16.7917214
76       base    -5.09337822 -13.5932357
77       base    21.29389929  81.8293286
78       base    -2.57700820 -10.3631500
79       base    -1.99702575 -17.2458858
80       base    -3.96428571 -18.7857143
81       base    -4.99702575 -28.2458858
82       base    -2.57700820 -11.3631500
83       base    -0.48065573  -6.0158000
84       base    17.16480679  25.0218071
85       base    -5.54426817 -12.9029785
86       base    -7.25521075 -28.8609286
87       base     3.13206676  10.5616357
88       base     0.03271173  36.5202751
89       base    -2.15999321   9.8255751
90       base    -7.70910326 -18.8646821
91       base    -3.41817822 -19.7894677
92       base    -3.96728827 -20.4797249
93       base    -4.19273324 -10.6345963
94       base     9.58182178   1.2105323
95       base    -1.77271570 -11.7518606
96       base    -2.80545573 -21.2120320
97       base    -0.70910326  29.1353179
98       base    -2.45091825   4.7503608
99       base    -6.67636322 -24.4045106
100      base    -7.32182574 -13.4421178
101      base    -2.12725318  -8.7142534
102      base     8.96909930  18.6330966
103      base     0.41998925  -1.0571606
104      base     1.22728430  12.2481394
105      base    -4.06364074 -26.8270749
106      base     1.06545177   2.9804465
107      base    -7.06364074 -22.8270749
108      base    55.54908175 114.7503608
109      base    -2.15999321  -6.1744249
110      base    -0.06364074   7.1729251
111      base    -0.77271570   6.2481394
112      base     5.41998925  18.9428394
113      base    -4.99816067   3.0932681
114      base    -3.15999321 -12.1744249
115      base     1.06545177 -11.0195535
116      base    -6.58001075 -12.0571606
117      base    -5.64362319 -11.9443391
118      base    -3.51453069 -12.1368177
119 treatment     1.57260406  -0.5052697
120 treatment     1.70302339  -0.5133604
121 treatment     5.89434668  -0.5541542
122 treatment     2.84404338  -0.4650200
123 treatment     3.81488508  -0.5743448
124 treatment     0.90791750  -0.5203627
125 treatment     0.26475873  -0.5052016
126 treatment    -3.48366697  -0.4134824
127 treatment    -0.90405585  -0.4559089
128 treatment    -0.72829262  -0.5296099
129 treatment     7.29884902  -0.4620268
130 treatment    -3.28705780  -0.5604083
131 treatment    -0.53895858  -0.5695194
132 treatment     2.37730228  -0.4627071
133 treatment   -15.17154410  -0.5405533
134 treatment    -7.78126702  -0.5430703
135 treatment    -0.19105523  -0.5290657
136 treatment    -3.21192859  -0.4984669
137 treatment     1.28726744  -0.4967027
138 treatment     4.10618943  -0.5855648
139 treatment     2.52559739  -0.5213831
140 treatment     4.49248802  -0.5863131
141 treatment     1.59511277  -0.4967708
142 treatment     2.12174950  -0.5526576
143 treatment    10.15782903  -0.5103672
144 treatment    -0.98547927  -0.4325890
145 treatment     2.44548136  -0.6024266
146 treatment     0.66394629  -0.5756374
147 treatment   -11.74189085   0.3939725
148 treatment    -5.86963909   0.5046578
149 treatment    -2.45554591   0.4062764
150 treatment     2.01086872   0.4865716
151 treatment     1.80529275   0.3900949
152 treatment    -1.51644987   0.4389795
153 treatment     8.54611686   0.4880001
154 treatment     1.12739075   0.5272974
155 treatment     3.09428138   0.4623674
156 treatment   -10.23212158   0.4095417
157 treatment    -4.48898175   0.4239545
158 treatment     0.19524336   0.4701860
159 treatment    -3.77033988   0.4307527
160 treatment    -0.21686058   0.5676831
161 treatment     2.53717897   0.5132928
162 treatment     0.18066421   0.4155236
163 treatment    -3.26089708   0.5289300
164 treatment     3.58650135   0.4459138
165 treatment    -0.47143245   0.4559773
166 treatment    -0.64487995   0.4461859
167 treatment    19.64803234   0.4314375
168 treatment    -0.94411386   0.5035694
169 treatment    -2.88023975   0.4482267
170 treatment    -3.41382512   0.5285219
171 treatment    -0.97624232   0.4168841
172 treatment    -6.73357850   0.5765221
173 treatment    -0.09704190   0.5031612
174 treatment     3.83840212   0.4550249
175 treatment    -3.43303720   0.4147753
176 treatment    -2.69518325   0.5353201
177 treatment    -0.51775726   0.5433428</code></pre>
</div>
</div>
</div>
</div>
<div id="day-4.-non-standard-models" class="section level1">
<h1>Day 4. Non-standard models</h1>
<div id="matched-case-control" class="section level2">
<h2>1. Matched case control</h2>
<blockquote>
<p>A case-control study was performed to determine whether induced (and spontaneous) abortions could increase the risk of secondary infertility. Obstetric and gynaecologic histories were obtained from 100 women with secondary infertility admitted to a department of obstetrics and gynecology its division of fertility and sterility. For every patient, an attempt was made to find two healthy control subjects from the same hospital with matching for age, parity, and level of education. Two control subjects each were found for 83 of the index patients. The data can be found in infertility.csv. The numbers of (spontaneous or induced) abortions are coded as 0=0, 1=1, 2=2 or more.</p>
</blockquote>
<div id="a.-5" class="section level3">
<h3>a.</h3>
<blockquote>
<p>What type of study is this? What type of analysis do you prefer for this study design?</p>
</blockquote>
<p>Matched case control, can be analyzed with conditional logistic regression.</p>
</div>
<div id="b.-5" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Perform the analysis and interpret the results. Do previous (spontaneous or induced) abortions affect the risk of secondary infertility?</p>
</blockquote>
<p>Read in data</p>
<pre class="r"><code>infert &lt;- read.csv(here(&quot;data&quot;, &quot;infertility.csv&quot;), sep = &quot;;&quot;)
str(infert)</code></pre>
<pre><code>&#39;data.frame&#39;:   248 obs. of  8 variables:
 $ education     : Factor w/ 3 levels &quot;0-5yrs&quot;,&quot;12+ yrs&quot;,..: 1 1 1 1 3 3 3 3 3 3 ...
 $ age           : int  26 42 39 34 35 36 23 32 21 28 ...
 $ parity        : int  6 1 6 4 3 4 1 2 1 2 ...
 $ induced       : int  1 1 2 2 1 2 0 0 0 0 ...
 $ case          : int  1 1 1 1 1 1 1 1 1 1 ...
 $ spontaneous   : int  2 0 0 0 1 1 0 0 1 0 ...
 $ stratum       : int  1 2 3 4 5 6 7 8 9 10 ...
 $ pooled.stratum: int  3 1 4 2 32 36 6 22 5 19 ...</code></pre>
<pre class="r"><code>summary(infert)</code></pre>
<pre><code>   education        age            parity         induced      
 0-5yrs : 12   Min.   :21.00   Min.   :1.000   Min.   :0.0000  
 12+ yrs:116   1st Qu.:28.00   1st Qu.:1.000   1st Qu.:0.0000  
 6-11yrs:120   Median :31.00   Median :2.000   Median :0.0000  
               Mean   :31.50   Mean   :2.093   Mean   :0.5726  
               3rd Qu.:35.25   3rd Qu.:3.000   3rd Qu.:1.0000  
               Max.   :44.00   Max.   :6.000   Max.   :2.0000  
      case         spontaneous        stratum      pooled.stratum 
 Min.   :0.0000   Min.   :0.0000   Min.   : 1.00   Min.   : 1.00  
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:21.00   1st Qu.:19.00  
 Median :0.0000   Median :0.0000   Median :42.00   Median :36.00  
 Mean   :0.3347   Mean   :0.5766   Mean   :41.87   Mean   :33.58  
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:62.25   3rd Qu.:48.25  
 Max.   :1.0000   Max.   :2.0000   Max.   :83.00   Max.   :63.00  </code></pre>
<p>Check stratum variable, which tells us the matced pairs</p>
<pre class="r"><code>table(infert$stratum)</code></pre>
<pre><code>
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 
 3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 
26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 
 3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 
51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 
 3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  2  3 
76 77 78 79 80 81 82 83 
 3  3  3  3  3  3  3  3 </code></pre>
<p>Perform analysis</p>
<pre class="r"><code>require(survival)
fit1 &lt;- clogit(case ~  induced + spontaneous + strata(stratum),
       data = infert, method = &quot;exact&quot;)
summary(fit1)</code></pre>
<pre><code>Call:
coxph(formula = Surv(rep(1, 248L), case) ~ induced + spontaneous + 
    strata(stratum), data = infert, method = &quot;exact&quot;)

  n= 248, number of events= 83 

              coef exp(coef) se(coef)     z Pr(&gt;|z|)    
induced     1.4090    4.0919   0.3607 3.906 9.38e-05 ***
spontaneous 1.9859    7.2854   0.3524 5.635 1.75e-08 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

            exp(coef) exp(-coef) lower .95 upper .95
induced         4.092     0.2444     2.018     8.298
spontaneous     7.285     0.1373     3.651    14.536

Rsquare= 0.193   (max possible= 0.519 )
Likelihood ratio test= 53.15  on 2 df,   p=2.869e-12
Wald test            = 31.84  on 2 df,   p=1.221e-07
Score (logrank) test = 48.44  on 2 df,   p=3.032e-11</code></pre>
<p>Both previous spontanious and previous induced abortions increase the risk of infertility.</p>
<p>The odds ratio of induced abortions is 4.09, the odds ratio of spontaneous abortions is 7.29</p>
</div>
<div id="c.-5" class="section level3">
<h3>c.</h3>
<blockquote>
<p>How do we control for the potential confounding effects of age, parity and education?</p>
</blockquote>
<p>They are accounted for by the matching, so no need to add them as covariates to the model</p>
</div>
</div>
<div id="multinomial-regression" class="section level2">
<h2>2. Multinomial regression</h2>
<blockquote>
<p>Madsen (1976) investigated satisfaction with housing conditions in Copenhagen. Residents in selected areas living in rented homes built between 1960 and 1968 were questioned about their satisfaction and their degree of contact with other residents. The data can be found in the file housinglong.csv. The variable satisfaction is coded 1=low, 2=medium, 3=high; contact is coded 1=low and 2=high. Save your script/SPSS code, we will use this data again in Exercise 4.</p>
</blockquote>
<div id="a.-6" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Summarize the data using appropriate tables and percentages to show the associations between levels of satisfaction and contact with other residents, levels of satisfaction and type of housing, and contact and type of housing.</p>
</blockquote>
<pre class="r"><code>housinglong &lt;- read.csv(here(&quot;data&quot;, &quot;housinglong.csv&quot;), sep = &quot;;&quot;)
str(housinglong)</code></pre>
<pre><code>&#39;data.frame&#39;:   1681 obs. of  3 variables:
 $ type        : Factor w/ 3 levels &quot;apartment&quot;,&quot;house&quot;,..: 3 3 3 3 3 3 3 3 3 3 ...
 $ satisfaction: int  1 1 1 1 1 1 1 1 1 1 ...
 $ contact     : int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>There are three categorical variables, when can get all pairwise contingengy tables with 3 tables</p>
<pre class="r"><code>require(gmodels)
CrossTable(housinglong$type, housinglong$satisfaction, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)</code></pre>
<pre><code>
 
   Cell Contents
|-------------------------|
|                       N |
|           N / Row Total |
|-------------------------|

 
Total Observations in Table:  1681 

 
                 | housinglong$satisfaction 
housinglong$type |         1 |         2 |         3 | Row Total | 
-----------------|-----------|-----------|-----------|-----------|
       apartment |       271 |       192 |       302 |       765 | 
                 |     0.354 |     0.251 |     0.395 |     0.455 | 
-----------------|-----------|-----------|-----------|-----------|
           house |       197 |       153 |       166 |       516 | 
                 |     0.382 |     0.297 |     0.322 |     0.307 | 
-----------------|-----------|-----------|-----------|-----------|
     tower block |        99 |       101 |       200 |       400 | 
                 |     0.247 |     0.253 |     0.500 |     0.238 | 
-----------------|-----------|-----------|-----------|-----------|
    Column Total |       567 |       446 |       668 |      1681 | 
-----------------|-----------|-----------|-----------|-----------|

 </code></pre>
<p>Seems like people from tower block are most often in the highest satisfaction categorty</p>
<pre class="r"><code>CrossTable(housinglong$type, housinglong$contact, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)</code></pre>
<pre><code>
 
   Cell Contents
|-------------------------|
|                       N |
|           N / Row Total |
|-------------------------|

 
Total Observations in Table:  1681 

 
                 | housinglong$contact 
housinglong$type |         1 |         2 | Row Total | 
-----------------|-----------|-----------|-----------|
       apartment |       317 |       448 |       765 | 
                 |     0.414 |     0.586 |     0.455 | 
-----------------|-----------|-----------|-----------|
           house |       177 |       339 |       516 | 
                 |     0.343 |     0.657 |     0.307 | 
-----------------|-----------|-----------|-----------|
     tower block |       219 |       181 |       400 | 
                 |     0.547 |     0.453 |     0.238 | 
-----------------|-----------|-----------|-----------|
    Column Total |       713 |       968 |      1681 | 
-----------------|-----------|-----------|-----------|

 </code></pre>
<p>People living in ’house’s have most contact with neighbours</p>
<pre class="r"><code>CrossTable(housinglong$contact, housinglong$satisfaction, 
           prop.c=FALSE,prop.t=FALSE,prop.chisq=FALSE)</code></pre>
<pre><code>
 
   Cell Contents
|-------------------------|
|                       N |
|           N / Row Total |
|-------------------------|

 
Total Observations in Table:  1681 

 
                    | housinglong$satisfaction 
housinglong$contact |         1 |         2 |         3 | Row Total | 
--------------------|-----------|-----------|-----------|-----------|
                  1 |       262 |       178 |       273 |       713 | 
                    |     0.367 |     0.250 |     0.383 |     0.424 | 
--------------------|-----------|-----------|-----------|-----------|
                  2 |       305 |       268 |       395 |       968 | 
                    |     0.315 |     0.277 |     0.408 |     0.576 | 
--------------------|-----------|-----------|-----------|-----------|
       Column Total |       567 |       446 |       668 |      1681 | 
--------------------|-----------|-----------|-----------|-----------|

 </code></pre>
<p>People with more contact are more often in the highest category of satisfaction.</p>
</div>
<div id="b.-6" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Use nominal (multinomial) logistic regression to model associations between level of satisfaction and the other two variables. Use the likelihood ratio test (LRT) to delete non-significant variables in order to obtain a parsimonious model that summarizes the patterns of the data.</p>
</blockquote>
<p>Drop1 trew an error (“Error in if (trace) { : argument is not interpretable as logical”), so we will make the models ourselves and perform LRtests</p>
<pre class="r"><code>require(nnet)
fit0 &lt;- multinom(satisfaction ~ 1, data = housinglong)</code></pre>
<pre><code># weights:  6 (2 variable)
initial  value 1846.767257 
final  value 1824.438811 
converged</code></pre>
<pre class="r"><code>fit1 &lt;- multinom(satisfaction ~ type, data = housinglong)</code></pre>
<pre><code># weights:  12 (6 variable)
initial  value 1846.767257 
iter  10 value 1807.174032
iter  10 value 1807.174031
iter  10 value 1807.174031
final  value 1807.174031 
converged</code></pre>
<pre class="r"><code>fit2 &lt;- multinom(satisfaction ~ contact, data = housinglong)</code></pre>
<pre><code># weights:  9 (4 variable)
initial  value 1846.767257 
final  value 1821.875901 
converged</code></pre>
<pre class="r"><code>fit3 &lt;- multinom(satisfaction ~ type + contact, data = housinglong)</code></pre>
<pre><code># weights:  15 (8 variable)
initial  value 1846.767257 
iter  10 value 1802.924087
final  value 1802.740161 
converged</code></pre>
<pre class="r"><code>anova(fit3, fit2, test = &quot;Chisq&quot;)</code></pre>
<pre><code>Likelihood ratio tests of Multinomial Models

Response: satisfaction
           Model Resid. df Resid. Dev   Test    Df LR stat.      Pr(Chi)
1        contact      3358   3643.752                                   
2 type + contact      3354   3605.480 1 vs 2     4 38.27148 9.849653e-08</code></pre>
<pre class="r"><code>anova(fit3, fit1, test = &quot;Chisq&quot;)</code></pre>
<pre><code>Likelihood ratio tests of Multinomial Models

Response: satisfaction
           Model Resid. df Resid. Dev   Test    Df LR stat.    Pr(Chi)
1           type      3356   3614.348                                 
2 type + contact      3354   3605.480 1 vs 2     2 8.867742 0.01186846</code></pre>
<p>Dropping either contact or type will lead to a significant decrease of the likelihood, although the effect of dropping type is greater.</p>
</div>
<div id="c.-6" class="section level3">
<h3>c.</h3>
<blockquote>
<p>Interpret the coefficients from the model in (b).</p>
</blockquote>
<pre class="r"><code>summary(fit3)</code></pre>
<pre><code>Call:
multinom(formula = satisfaction ~ type + contact, data = housinglong)

Coefficients:
  (Intercept)   typehouse typetower block   contact
2  -0.8099988  0.06967834       0.4067607 0.2959811
3  -0.4090469 -0.30402045       0.6415939 0.3282252

Std. Errors:
  (Intercept) typehouse typetower block   contact
2   0.2260285 0.1437749       0.1713009 0.1301046
3   0.2041219 0.1351693       0.1500773 0.1181870

Residual Deviance: 3605.48 
AIC: 3621.48 </code></pre>
<pre class="r"><code>exp(coef(fit3))</code></pre>
<pre><code>  (Intercept) typehouse typetower block  contact
2   0.4448586 1.0721633        1.501945 1.344445
3   0.6642831 0.7378458        1.899506 1.388502</code></pre>
<p>The odds of being in satisfactory class 2 is 1.07 times higher than the odds of being in class 1, for people in type house, compared to type appartment, given the same level of contact.</p>
<p>The odds of being in satisfactory class 3 is 0.73 times the odds of being in class 1, for people in type house, compared to type appartment, given the same level of contact.</p>
<p>Possible extensions:</p>
<ul>
<li>recode type to dummy variables, see if we can drop 1 of the 3 levels</li>
</ul>
</div>
<div id="d.-1" class="section level3">
<h3>d.</h3>
<blockquote>
<p>In SPSS is it not possible to get residuals for a multinomial or ordinal logistic regression. In R we can make our own “deviance residuals” as follows (assuming the dataset is called house, and the multinomial model from which we wish to estimate deviance residuals is called house.mlr.2): likl &lt;- numeric(1681) for (i in 1:1681) likl[i] &lt;- fitted(house.mlr.2)[i,house$satisfaction[i]] Plot these deviance residuals against case number: plot(1:1681, -2*log(likl))</p>
</blockquote>
<pre class="r"><code>likl &lt;- numeric(1681)
for (i in 1:1681) likl[i] &lt;-  fitted(fit3)[i,housinglong$satisfaction[i]]
plot(1:1681, -2*log(likl))</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-53-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>We will start the afternoon session with a theoretical (non-computer) question. Discuss the following with a few of your neighbors. We will then discuss the question in the group before proceeding to the computer lab questions.</p>
</blockquote>
</div>
</div>
<div id="polypharmacy" class="section level2">
<h2>3. Polypharmacy</h2>
<blockquote>
<p>A researcher wishes to gain insight into the independent management and use of polypharmacy (≥ 5 medications) by elderly home healthcare clients in relation to their cognitive and self-management skills. Three measurement tests were assessed: the Clock-Drawing test (CDT), the Self-Management Ability Scale (SMAS-30) and the independent Medication Management Score (iMMS). The iMMS instrument consists of 17 “yes/no” questions regarding independent medication management, where a “no” indicates lack of management ability in a particular area of medication management. The iMMS equals the number of questions that were answered with “no”. The Clock-Drawing test (“Can you draw a clock and put the hands on 10 past 11?”) purports to measure the cognitive abilities of the individual, and is scored on a scale from 1 to 5 (5 being best). The Self-Management Ability Scale (SMAS-30) consists of 30 questions on general self-management issues, and is scaled from 0 to 100.</p>
</blockquote>
<blockquote>
<p>The researcher wishes to predict the iMMS from the CDT and SMAS-30, as well as age and sex of the individual with a generalized linear model, using one of three probability distributions: the Gaussian, binomial or Poisson distribution.</p>
</blockquote>
<div id="a.-7" class="section level3">
<h3>a.</h3>
<blockquote>
<p>Give at least one advantage and one disadvantage for each of these three approaches.</p>
</blockquote>
<p>iMMS is a bounded discrete variable, ranging from 0 to 17;</p>
<ul>
<li><p>Gaussian: since the range of 0-17 with steps of 1 is not very small, it may be approximated as a continous variable. Using the Guassian distribution with GLM gives the regular linear regression, which has the easiest interpretation. A downside is that the response is actually discrete and bounded</p></li>
<li><p>binomial: this seems like a logical choice of distribution for this problem. iMMS can be seen as the result of 17 bernoulli trials (yes/no), however, it may be that the trials are not independent of each other (so scoring ‘no’ on a certain question will increase the probability of scoring ‘no’ on another question), and that the probability of ‘success’ on each question is not the same. This violates two of the assumptions of the binomial distribution. Also, the resulting coefficients are not always easy interpretable depending on the chosen link function.</p></li>
<li><p>Poisson: the Poisson distribution is suitable for discrete (count) variables, bounded by 0 as is the case here. A downside is that there exists an upper bound here.</p></li>
</ul>
</div>
<div id="b.-7" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Which specific graphs from the initial data analysis step and/or the model checking step would you need to help you choose among the three approaches?</p>
</blockquote>
<p>Plotting the marginal distribution of the outcome may be benificial. When the mean of the distribution is in the center of the range and the distribution is approximately bell-shaped, the Gaussian approximation may be ok. However, this ultimately depends on the error distribution of the models.</p>
<p>Plotting marginal distributions will not be very helpful, as each distribution has assumptions on the error distribution and not the marginal distribution, so probably model checking is best.</p>
<ul>
<li>For all models:</li>
</ul>
<p>– Calculate deviance, check which model has lowest deviance – Look for influential observations based on the Cook’s distance</p>
<ul>
<li>Guassian</li>
</ul>
<p>– Create a fit with both explanatory variables, plot – QQ-plot of residuals – y vs pred(y) to assess homoscedasticity – make partial plots to assess linearity of the relationship</p>
<ul>
<li><p>Binomial</p></li>
<li><p>Poisson</p></li>
</ul>
<p>– calculate dispersion parameter</p>
</div>
</div>
<div id="housing-revisited" class="section level2">
<h2>4. Housing revisited</h2>
<blockquote>
<p>We will revisit the Madsen dataset on satisfaction with housing conditions (housinglong.csv). Recall: the variable satisfaction is coded 1=low, 2=medium, 3=high; contact is coded 1=low and 2=high.</p>
</blockquote>
<div id="a.-8" class="section level3">
<h3>a.</h3>
<blockquote>
<p>In question 2 we analyzed the data using a multinomial logistic regression. Why was this not the most appropriate model for examining associations between levels of satisfaction and the other variables? Fit a more suitable model and compare the results with those from (b). See if you can reduce this model, again using the LRT.</p>
</blockquote>
<p>Multinomial regression assumes nominal outcome, so no order in the levels of the outcome. In this case, we have that class 1 &lt; class 2 &lt; class 3, so we have order. This information was disregarded by the multinomial model.</p>
<p>Better may be proportional odds model</p>
<pre class="r"><code>housinglong &lt;- read.csv(here(&quot;data&quot;, &quot;housinglong.csv&quot;), sep = &quot;;&quot;)</code></pre>
<pre class="r"><code>require(MASS)
# fit_po1 &lt;- polr(factor(satisfaction) ~ contact, data = housinglong)
# fit_po2 &lt;- polr(factor(satisfaction) ~ type, data = housinglong)
fit_po3 &lt;- polr(factor(satisfaction) ~ type + contact, data = housinglong)

drop1(fit_po3, test = &quot;Chisq&quot;)</code></pre>
<pre><code>Single term deletions

Model:
factor(satisfaction) ~ type + contact
        Df    AIC    LRT  Pr(&gt;Chi)    
&lt;none&gt;     3620.3                     
type     2 3651.6 35.322 2.138e-08 ***
contact  1 3625.7  7.376  0.006611 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We cannot drop any of the explanatory variables.</p>
<p>Compare with the multinomial regression models</p>
<pre class="r"><code>fit_mn3 &lt;- multinom(satisfaction ~ type + contact, data = housinglong)</code></pre>
<pre><code># weights:  15 (8 variable)
initial  value 1846.767257 
iter  10 value 1802.924087
final  value 1802.740161 
converged</code></pre>
<pre class="r"><code>fits &lt;- list(multinomial = fit_mn3, proportional_odds = fit_po3)</code></pre>
<pre class="r"><code>fits %&gt;%
  map_df(function(fit) data.frame(deviance = fit$deviance,
                                  df = fit$edf,
                                  AIC = AIC(fit)), .id = &quot;model&quot;)</code></pre>
<pre><code>              model deviance df      AIC
1       multinomial 3605.480  8 3621.480
2 proportional_odds 3610.286  5 3620.286</code></pre>
</div>
<div id="b.-8" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Comment on the AIC and residual deviance of the models from Exercises 2b and 4a.</p>
</blockquote>
<p>The deviance of the multinomial model is lower. However, this model has more estimated parameters, as it estimates coefficients for the explanatory variables for 2 of the 3 levels of the response variable.</p>
<p>The proportional odds model assumes the same coefficients for differences between class 1 and 2 and class 2 and 3, and therefore has more residual degrees of freedom.</p>
<p>This results in a lower AIC, and arguably a better fit. However, the difference is small.</p>
</div>
<div id="c.-7" class="section level3">
<h3>c.</h3>
<blockquote>
<p>R users: as in Exercise 2, try to save and plot the deviance residuals from the model in (a).</p>
</blockquote>
<pre class="r"><code>nobs = fit_po3$nobs
likl_po &lt;- numeric(nobs)
for (i in 1:nobs) likl_po[i] &lt;- fit_po3$fitted.values[i, housinglong$satisfaction[i]]
plot(1:nobs, -2*log(likl_po))</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-58-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Try to compare models</p>
<pre class="r"><code>bind_rows(list(multinomial = data.frame(likl = likl), 
               proportional_odds = data.frame(likl = likl_po)), .id = &quot;model&quot;) %&gt;%
  mutate(loglik = -2*log(likl)) %&gt;%
  group_by(model) %&gt;% 
  mutate(index = 1:n(), 
         satisfaction = housinglong$satisfaction) %&gt;%
  ggplot(aes(x = index, y = loglik, col = model)) +
  geom_point() + facet_wrap(~satisfaction, labeller = &quot;label_both&quot;)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-59-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="d.-2" class="section level3">
<h3>d.</h3>
<blockquote>
<p>In both SPSS and R, it is at least possible to get fitted probabilities. From the best model you obtained in (a), get the fitted probabilities per combination of type and contact. Use these to calculate the fitted frequencies (counts). Hint: in R, use the predict() function (and the option type=“probs”) on a new data frame containing all combinations of type and contact; in SPSS, try aggregating the predicted values over the categories of type &amp; contact). Use the predicted probabilities to get predicted counts and find where the largest discrepancies are between observed frequencies and expected frequencies estimated from the model.</p>
</blockquote>
<p>Make a grid of the possible covariate combinations and predict probabilities.</p>
<pre class="r"><code>cov_grid &lt;- expand.grid(
  contact = unique(housinglong$contact),
  type = sort(unique(housinglong$type))
)

grid_pred &lt;- predict(fit_po3, newdata = cov_grid, type = &quot;probs&quot;)
row.names(grid_pred) &lt;- paste0(cov_grid$type, &quot;_contact&quot;, cov_grid$contact)
grid_pred</code></pre>
<pre><code>                             1         2         3
apartment_contact1   0.3783899 0.2709460 0.3506642
apartment_contact2   0.3210770 0.2688545 0.4100685
house_contact1       0.4350948 0.2657691 0.2991361
house_contact2       0.3743657 0.2710563 0.3545779
tower block_contact1 0.2694631 0.2592953 0.4712416
tower block_contact2 0.2227370 0.2429973 0.5342657</code></pre>
<p>Get the observed probabilities</p>
<pre class="r"><code>obs_probs &lt;- prop.table(ftable(table(
  housinglong$type, 
  housinglong$contact, 
  housinglong$satisfaction), 
  col.vars = 3), margin = 1)
obs_probs</code></pre>
<pre><code>                       1         2         3
                                            
apartment   1  0.4100946 0.2397476 0.3501577
            2  0.3147321 0.2589286 0.4263393
house       1  0.3785311 0.2711864 0.3502825
            2  0.3834808 0.3097345 0.3067847
tower block 1  0.2968037 0.2465753 0.4566210
            2  0.1878453 0.2596685 0.5524862</code></pre>
<p>Subtract to view differences</p>
<pre class="r"><code>diff_grid &lt;- obs_probs - grid_pred
diff_grid</code></pre>
<pre><code>                           1             2             3
                                                        
apartment   1   0.0317047855 -0.0311983320 -0.0005064535
            2  -0.0063448212 -0.0099259609  0.0162707821
house       1  -0.0565637406  0.0054173313  0.0511464094
            2   0.0091150916  0.0386781672 -0.0477932588
tower block 1   0.0273405734 -0.0127199828 -0.0146205906
            2  -0.0348916749  0.0166712129  0.0182204620</code></pre>
<p>Visualize (take absolute difference)</p>
<pre class="r"><code>image(t(abs(diff_grid)), xaxt = &quot;n&quot;, yaxt = &quot;n&quot;)
axis(1, at = seq(0, 1, length.out = 3), labels = 1:3, las = 1)
axis(2, at = seq(0, 1, length.out = 6), labels = rownames(grid_pred), las = 1)</code></pre>
<p><img src="figure/glm_assignments.Rmd/unnamed-chunk-63-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="e.-1" class="section level3">
<h3>e.</h3>
<blockquote>
<p>For the more advanced R user: included in the R solutions for today is code to check the proportional odds assumption for the model in part (d). To do this, we need to calculate the ln(odds) of satisfaction=1 vs 2&amp;3 and of of satisfaction=1&amp;2 vs 3 for each level of housing type and contact and graph these.</p>
</blockquote>
<p>The advanced SPSS user can look at this link for code on checking the proportional odds assumption in SPSS <a href="http://www.ats.ucla.edu/stat/spss/dae/ologit.htm" class="uri">http://www.ats.ucla.edu/stat/spss/dae/ologit.htm</a> .</p>
</div>
</div>
<div id="esophageal-cancer" class="section level2">
<h2>5. Esophageal cancer</h2>
<blockquote>
<p>A retrospective case-control study of 200 male cases of esophageal cancer and 778 population controls was carried out in Ille-et-Vilaine (France). Interest is in the relation between tobacco consumption (tobhigh: 1 = 20+ g/day, 0 = less than 20 g/day) and esophageal cancer (case: 1 = case, 0 = control), while considering the possible confounding or effect- modifying effects of alcohol consumption (alchigh: 1 = 80+ g /day, 0 = &lt; 80 g/day). The data can be found in bd1.sav or bd1.csv (separator = “,”)</p>
</blockquote>
<div id="a.-9" class="section level3">
<h3>a.</h3>
<blockquote>
<p>What type of study is this? What type of analysis would you prefer for this study design?</p>
</blockquote>
<p>Case-control</p>
<p>Logistic regression (the outcome is binary)</p>
</div>
<div id="b.-9" class="section level3">
<h3>b.</h3>
<blockquote>
<p>Use this data to answer the research question, paying attention to the role (confounding?/effect modification?) of alcohol use.</p>
</blockquote>
</div>
<div id="c.-8" class="section level3">
<h3>c.</h3>
<blockquote>
<p>Do some model checking.</p>
</blockquote>
<p>Deviance,</p>
</div>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.4.3 (2017-11-30)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] tools     splines   stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] MASS_7.3-48         nnet_7.3-12         survival_2.41-3    
 [4] HSAUR_1.3-9         gmodels_2.16.2      tidyr_0.8.0        
 [7] bindrcpp_0.2        broom_0.4.3         epistats_0.1.0     
[10] ggplot2_2.2.1       here_0.1            purrr_0.2.4        
[13] magrittr_1.5        data.table_1.10.4-3 dplyr_0.7.4        

loaded via a namespace (and not attached):
 [1] gtools_3.5.0       tidyselect_0.2.3   reshape2_1.4.3    
 [4] lattice_0.20-35    colorspace_1.3-2   htmltools_0.3.6   
 [7] yaml_2.1.16        rlang_0.1.6        pillar_1.1.0      
[10] foreign_0.8-69     glue_1.2.0         RColorBrewer_1.1-2
[13] binom_1.1-1        bindr_0.1          plyr_1.8.4        
[16] stringr_1.2.0      munsell_0.4.3      gtable_0.2.0      
[19] psych_1.7.8        evaluate_0.10.1    labeling_0.3      
[22] knitr_1.19         GGally_1.3.2       parallel_3.4.3    
[25] Rcpp_0.12.15       scales_0.5.0       backports_1.1.2   
[28] gdata_2.18.0       mnormt_1.5-5       digest_0.6.15     
[31] stringi_1.1.6      grid_3.4.3         rprojroot_1.3-2   
[34] lazyeval_0.2.1     tibble_1.4.2       pkgconfig_2.0.1   
[37] Matrix_1.2-12      assertthat_0.2.0   rmarkdown_1.8     
[40] reshape_0.8.7      R6_2.2.2           nlme_3.1-131      
[43] git2r_0.21.0       compiler_3.4.3    </code></pre>
</div>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
