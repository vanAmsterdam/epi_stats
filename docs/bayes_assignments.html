<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Wouter van Amsterdam" />

<meta name="date" content="2018-04-30" />

<title>Assignments for applied Bayesian statistics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">epi_stats</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Assignments for applied Bayesian statistics</h1>
<h4 class="author"><em>Wouter van Amsterdam</em></h4>
<h4 class="date"><em>2018-04-30</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Update knitr chunk options -->
<!-- Insert the date the file was last updated -->
<p><strong>Last updated:</strong> 2018-05-04</p>
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
<p><strong>Code version:</strong> fc4400b</p>
<!-- Add your analysis here -->
<div id="setup-r" class="section level1">
<h1>Setup R</h1>
<p>We will use R version 3.3.2 for compatibility</p>
<pre class="r"><code>library(dplyr)
library(data.table)
library(magrittr)
library(purrr)
library(here) # for tracking working directory
library(ggplot2)
library(epistats)
library(broom)
library(rjags)
library(Bain)</code></pre>
</div>
<div id="day-1" class="section level1">
<h1>Day 1</h1>
<div id="exercise-1-a-bayesian-test-for-proportions" class="section level2">
<h2>Exercise 1: A Bayesian test for proportions</h2>
<blockquote>
<p>Several studies suggest that cognitive behavioral therapy is an effective treatment for Posttrau- matic Stress Disorder (PTSD) in male veterans. Imagine that you performed a study to compare Prolonged Exposure (PE), a type of cognitive behavioral therapy, with Present-Centered therapy (PC), a supportive intervention. In this randomized controlled trial 284 veterans were assigned to receive either PE or PC. The (dichotomous) outcome measure of interest was “loss of diagnosis”(LD); that is, each veteran that was no longer diagnosed with PTSD after treatment got the score 1, and the ones that still had the diagnosis got the score 0.</p>
</blockquote>
<blockquote>
<p>In this exercise you will use rjags to examine whether PE and PC are effective treatments for PTSD in veterans. The data you need for this exercise are displayed in Table 1 below.</p>
</blockquote>
<blockquote>
<p>Table 1 PE PC Loss of diagnosis 58 40 Total men treated 141 143</p>
</blockquote>
<div id="a-specify-your-bayesian-model-for-jags" class="section level3">
<h3>1.a Specify your Bayesian model for JAGS</h3>
<blockquote>
<p>Open the file Model1.txt (you can open it in R, or in a text editor like notepad). We will specify the model in this file in a couple of steps. In the the Model1.txt file you can add your own comments by putting # in front of those comments. In that way, JAGS will know that it should not run that code, but consider it as a comment</p>
</blockquote>
<div id="step-1.-likelihood" class="section level4">
<h4>Step 1. Likelihood</h4>
<blockquote>
<p>We are interested in the proportion of veterans that had a LD in each treatment condition, that is, we are interested in the probability of observing a succes (a 1) in the pe condition (θ_pe) and the pc condition (θ_pc).</p>
</blockquote>
<blockquote>
<p>We can model the number of successes for each condition with binomial distributions:</p>
</blockquote>
<blockquote>
<p>y_pe ~ Binomial(θ_pe, n_pe)</p>
</blockquote>
<blockquote>
<p>y_pc ~ Binomial(θ_pc, n_pc)</p>
</blockquote>
<blockquote>
<p>That is, for each condition, we assume that the data y (the number of successes in the data) have a binomial distribution with as parameters θ, the probability of observing a success, and n, the total number of observations in the condition.</p>
</blockquote>
<blockquote>
<p>The total number of observations in the conditions we know, as well as of course the data y (see Table 1). The probabilities θ¸ are what we want to estimate from the information we have, and we will do this in a Bayesian way.</p>
</blockquote>
<blockquote>
<p>In the model code for JAGS in Model1.txt we have to specify these distributions within model{ } so that JAGS can find the likelihood based on this information. Therefore, within model{ } we add the following code in Model1.txt:</p>
</blockquote>
<blockquote>
<h1 id="likelihood-of-the-data">likelihood of the data</h1>
<p>ype ~ dbin(ppe,npe) ypc ~ dbin(ppc,npc) Step 2. Priors Next, we have to specify prior distributions for all the parameters we need to estimate. That is, we need priors for θ_pe (ppe in our code) and θ_pc (ppc in our code). A commonly used conjugate prior distribution for probabilities from a binomial distribution is the beta-distribution. That is,</p>
</blockquote>
<blockquote>
<p>θ_pe ~ Beta(a_pe, b_pe)</p>
</blockquote>
<blockquote>
<p>θ_pc ~ Beta(a_pc, b_pc)</p>
</blockquote>
<blockquote>
<p>with shape parameters a (a_pe, a_pc) and b (b_pe, b_pc).</p>
</blockquote>
<blockquote>
<p>For each condition, we will specify that a = b = 1 in our model code to obtain low-informative prior distributions. That is, we add the following code in Model1.txt within model{ }:</p>
</blockquote>
<blockquote>
<h1 id="prior-distributions">prior distributions</h1>
<p>ppe ~ dbeta(1,1) ppc ~ dbeta(1,1) Step 3. Interesting additional quantities Finally we will specify a contrast you may be interested in, namely the ratio of the probability of succes in condition PE and the probability of succes in condition PC (θ_pe /θ_pc). By adding the following code within model{ } we will tell JAGS to calculate this ratio in each iteration of the estimator:</p>
</blockquote>
<blockquote>
<h1 id="contrast">contrast</h1>
<p>ratio &lt;- ppe/ppc You could also add any other quantity based on the probabilities in your code, for example, the difference in the probabilities.</p>
</blockquote>
<blockquote>
<p>Our model code is done for now - save your code as Model1.txt in your working directory.</p>
</blockquote>
</div>
</div>
<div id="b-preparing-the-data-for-jags-in-r" class="section level3">
<h3>1.b Preparing the data for JAGS in R</h3>
<blockquote>
<p>Before we can use our model, we first have to get our data (from Table 1) into R. Make four variables in R that contain respectively the number of veterans that lost their diagnosis for condition PE, the number of veterans that lost their diagnosis for condition PC, the total number of veterans that were in condition PE, and the total number of veterans that were in condition PC.</p>
</blockquote>
<blockquote>
<h1 id="data-for-exercise-1">data for exercise 1</h1>
</blockquote>
<pre class="r"><code>y_pe &lt;- 58
y_pc &lt;- 40
n_pe &lt;- 141
n_pc &lt;- 143 </code></pre>
<blockquote>
<p>Now, if we want to use this data for our analysis in rjags we need to put these data in what is called a list. In the list we specify for all the names we used for the data in the jags model code (that is, ype, ypc, npe, npc) what the actual data is that we have stored in R (y_pe, y_pc, n_pe, n_pc).</p>
</blockquote>
<blockquote>
<p>About lists: You can store various types of R objects (such as vectors, matrices or other lists) in a list. The list type of object is used for specifying data and initial values in rjags amongst other things, but it is, for instance, also frequently used for storing and presenting output from analyses in R. If you want to know more about lists you can read more here: <a href="http://rforpublichealth.blogspot.nl/2015/03/basics-of-lists.html" class="uri">http://rforpublichealth.blogspot.nl/2015/03/basics-of-lists.html</a>.</p>
</blockquote>
<blockquote>
<p>Make a list out of the data, and call the list you made to see what is inside as follows:</p>
</blockquote>
<blockquote>
<h1 id="data-for-exercise-1-for-rjags">data for exercise 1 for rjags</h1>
</blockquote>
<p>(actually, naming arguments in lists works in R without parentheses)</p>
<pre class="r"><code>dat_ex1 &lt;- list(&#39;ype&#39;=y_pe, &#39;ypc&#39;=y_pc, &#39;npe&#39;=n_pe, &#39;npc&#39;=n_pc) 
dat_ex1</code></pre>
<pre><code>$ype
[1] 58

$ypc
[1] 40

$npe
[1] 141

$npc
[1] 143</code></pre>
<pre class="r"><code>dat_ex1 &lt;- list(ype=y_pe, ypc=y_pc, npe=n_pe, npc=n_pc) 
dat_ex1</code></pre>
<pre><code>$ype
[1] 58

$ypc
[1] 40

$npe
[1] 141

$npc
[1] 143</code></pre>
</div>
<div id="c-specifying-and-running-the-bayesian-analysis-with-rjags" class="section level3">
<h3>1.c Specifying and running the Bayesian analysis with rjags</h3>
<blockquote>
<p>In order to run the analyses we first have to tell rjags what the model file is, what the data is, and specify the number of chains for the analyses (we use 2 for this exercise - you will learn more about this on Tuesday). It is also possible to specify initial values, but we will skip this for now (JAGS will generate the initial values itself based on the priors you specified in Model1.txt). We specify the model by means of the function jags.model(). To learn a bit more about this function already, run ?jags.model in R.</p>
</blockquote>
<blockquote>
<p>We use the jags.model() function and we name it rjags_ex1 as follows :</p>
</blockquote>
<pre class="r"><code>nsamp = 10000
rjags_ex1 &lt;- jags.model(file=here(&quot;analysis&quot;, &quot;bayes_1_Model1.txt&quot;),
                   data = dat_ex1,
                   n.chains = 2) ###compile and initialize jags model</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 2
   Unobserved stochastic nodes: 2
   Total graph size: 9

Initializing model</code></pre>
<blockquote>
<p>After you have run this line of code, jags will compile the model and specify initial values for (initialize) the model. Now, we want to start the estimation procedure to fit our Bayesian model. We start by letting the estimation procedure run for a while, to start up and converge (these first few iterations in the estimation procedure are called burn-in - more on this on Tuesday). We do this with the function update(). Using update(), jags starts the estimation procedure, but it doesn’t save this as the results.</p>
</blockquote>
<blockquote>
<p>We tell update which model to update in the first argument, and how many times in the second argument as follows:</p>
</blockquote>
<pre class="r"><code>update(rjags_ex1, nsamp) ####burnin</code></pre>
<blockquote>
<p>When jags is done with the first updates, we can now tell it to run some more iterations in our estimation procedure, and to calculate and store some results for us. For this we use the function coda.samples(). We need to tell coda.samples() which model to update, for which parameters we want jags to save the results, and how many iterations to use (we use 1000). To learn more about this function, use ?coda.samples().</p>
</blockquote>
<blockquote>
<p>First we will make a vector with function c() with the names of all the parameters we want to see the results for. Next, we specify the function coda.samples, and we name it samples_rjags_ex1.</p>
</blockquote>
<pre class="r"><code>parstosave=c(&#39;ppe&#39;,&#39;ppc&#39;, &#39;ratio&#39;)
samples_rjags_ex1=coda.samples(model=rjags_ex1, variable.names=parstosave, n.iter=nsamp) </code></pre>
<blockquote>
<p>When it has reached 100% it is done. For this model, it will go really fast, but for more complicated models it might take a little while, depending on how many iterations you chose.</p>
</blockquote>
</div>
<div id="d-inspect-and-interpret-the-results" class="section level3">
<h3>1.d Inspect and interpret the results</h3>
<blockquote>
<p>After updating you normally have to check whether the algorithm has reached the target distribution. On Tuesday you will learn why and how this is done. For now, you may assume the sampler has reached convergence, and you can go on with analyzing the posterior results.</p>
</blockquote>
<blockquote>
<p>If you call samples_rjags_ex1 you will get all the iterations for all the parameters rjags has saved for you. It can be very convenient to have all of these samples, however, for now we just want to see some summary results. To get summary results use function summary() on samples_rjags_ex1.</p>
</blockquote>
<pre class="r"><code>summary(samples_rjags_ex1) </code></pre>
<pre><code>
Iterations = 11001:21000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

        Mean      SD  Naive SE Time-series SE
ppc   0.2829 0.03720 0.0002631      0.0003266
ppe   0.4123 0.04099 0.0002898      0.0003654
ratio 1.4835 0.24980 0.0017663      0.0022190

2. Quantiles for each variable:

        2.5%    25%    50%    75%  97.5%
ppc   0.2129 0.2571 0.2820 0.3081 0.3579
ppe   0.3338 0.3843 0.4115 0.4403 0.4928
ratio 1.0634 1.3078 1.4589 1.6356 2.0371</code></pre>
<blockquote>
<p>You will see the mean, standard deviation, and various quantiles of the posteriors for each estimated parameter (you will also see two kinds of standard errors, but you can disregard these for now). These summary statistics are calculated by rjags over all of the saved samples per parameter in samples_rjags_ex1.</p>
</blockquote>
<blockquote>
<p>You can also makes plots of the posterior distributions like this:</p>
</blockquote>
<pre class="r"><code>plot(samples_rjags_ex1,density=TRUE, trace=FALSE) ###densities</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Write down and interpret these posterior results (mean, median, 95% credibility interval). Do you think PE is an effective treatment for PTSD in male veterans? What about PC? Would you consider one treatment superior to the other? What do you base this on?</p>
</blockquote>
<p>Based on the ratio of the two, the 95% credible interval does not include the null-value of no effect (ratio = 1), so it seems that ppe is more effective</p>
</div>
<div id="e-obtaining-the-results-analytically" class="section level3">
<h3>1.e Obtaining the results analytically</h3>
<blockquote>
<p>Rjags has provided you with the posterior results for θ_pe, θ_pc, and their ratio. In this part of the exercise you will obtain the posterior means for these parameters analytically.</p>
</blockquote>
<blockquote>
<p>It can be shown that the posterior distribution for each θ i is given by: It can further be shown that the posterior mean ( θ̂ i ) of the distribution is given by:</p>
</blockquote>
<blockquote>
<p>Calculate the posterior mean for both proportions θ_pe and θ_pc using this equation. Then calculate the ratio of these means. Compare these results to those you have obtained using rjags. Are the results similar?</p>
</blockquote>
<pre class="r"><code>a = 1; b = 1
theta_pe &lt;- (a + y_pe) / (a + y_pe + b + n_pe - y_pe)
theta_pc &lt;- (a + y_pc) / (a + y_pc + b + n_pc - y_pc)
theta_pe</code></pre>
<pre><code>[1] 0.4125874</code></pre>
<pre class="r"><code>theta_pc</code></pre>
<pre><code>[1] 0.2827586</code></pre>
<pre class="r"><code>theta_pe / theta_pc</code></pre>
<pre><code>[1] 1.459151</code></pre>
</div>
</div>
<div id="exercise-2-informative-prior-distributions" class="section level2">
<h2>Exercise 2: Informative Prior Distributions</h2>
<blockquote>
<p>On an international conference on PTSD you meet two fellow researchers, Thomas B. and Ronald F., who also evaluated the use of PE versus PC. Thomas recently executed a randomized clinical trial with 520 female veterans to evaluate the use of PE versus PC. Ronald F. did a comparable trial with 235 WOII male veterans in 1946.</p>
</blockquote>
<div id="a-including-data-from-previous-studies" class="section level3">
<h3>2.a Including data from previous studies</h3>
<blockquote>
<p>As discussed during the today’s lecture on informative prior specification, it can we worthwhile to include data obtained in previous studies in the analysis of new data.</p>
</blockquote>
<blockquote>
<p>Would you be interested to include the results obtained in either of the trials in the prior distribution for the analysis of your own data? Which data do you think would be most relevant and why?</p>
</blockquote>
<p>thomas has data on only women, which is a small subset of all veterans, and women differ from men with regards to psychiologic disorders</p>
<p>ronald used data from 1946, which is a very long time ago</p>
<p>I would give more weight to the ronald’s data</p>
<p>so use these beta distributions: ppe ~ dbeta(41,66) ppc ~ dbeta(45,86)</p>
<p>So now:</p>
<pre class="r"><code>40 / 105</code></pre>
<pre><code>[1] 0.3809524</code></pre>
<pre class="r"><code>45 / 130</code></pre>
<pre><code>[1] 0.3461538</code></pre>
<pre class="r"><code>(40 / 105) / (45 / 130)</code></pre>
<pre><code>[1] 1.100529</code></pre>
</div>
<div id="b-including-data-from-previous-studies" class="section level3">
<h3>2.b Including data from previous studies</h3>
<blockquote>
<p>In Exercise 2.c you will rerun the analysis from Exercise 1 with informative prior distributions based on the data obtained by either Thomas or Ronald. In order to do so you will need to alter the uninformative Beta(1,1) distributions into informative distributions. This is what their data looks like:</p>
</blockquote>
<blockquote>
<p>Table 2. PTSD data from Thomas B. PE PC Loss of diagnosis 120 80 Total men treated 245 275 Table 3. PTSD data from Ronald F. PE PC Loss of diagnosis 40 45 Total men treated 105 130 Given the data that you consider to be the most relevant, what would your new informative prior distributions look like?</p>
</blockquote>
<blockquote>
<p>Hint: You can think of parameters a_i and b_i of the Beta-distribution as the prior number of successes and failures + 1 respectively.</p>
</blockquote>
</div>
<div id="c-rerun-the-analysis-with-your-informative-prior-of-choice" class="section level3">
<h3>2.c Rerun the analysis with your informative prior of choice</h3>
<blockquote>
<p>Run the analysis again with your informative prior distributions. Ask for the posterior results for both proportions θ_pe and θ_pc and their ratio. Compare the results (mean, median, 95% Central Credibility Interval) with the results obtained in Exercise 1. To what degree do the informative priors influence the posterior results? Do you think this is an desirable effect?</p>
</blockquote>
<pre class="r"><code>rjags_ex2 &lt;- jags.model(file=here(&quot;analysis&quot;, &quot;bayes_1_Model2.txt&quot;),
                   data = dat_ex1,
                   n.chains = 2) ###compile and initialize jags model</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 2
   Unobserved stochastic nodes: 2
   Total graph size: 12

Initializing model</code></pre>
<pre class="r"><code>update(rjags_ex2, nsamp)
samples_rjags_ex2 = coda.samples(model=rjags_ex2, variable.names=parstosave, n.iter=nsamp) 
summary(samples_rjags_ex2)</code></pre>
<pre><code>
Iterations = 11001:21000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

        Mean     SD  Naive SE Time-series SE
ppc   0.3128 0.0280 0.0001980      0.0002526
ppe   0.3992 0.0309 0.0002185      0.0002913
ratio 1.2867 0.1531 0.0010828      0.0013985

2. Quantiles for each variable:

        2.5%    25%    50%    75%  97.5%
ppc   0.2596 0.2938 0.3121 0.3312 0.3698
ppe   0.3401 0.3782 0.3989 0.4201 0.4601
ratio 1.0113 1.1798 1.2784 1.3828 1.6128</code></pre>
<p>The ratio is lower, but the 95% credible interval still does not include 1</p>
</div>
<div id="d-bonus-rerun-the-analysis-with-the-other-informative-prior" class="section level3">
<h3>2.d (bonus) Rerun the analysis with the other informative prior</h3>
<blockquote>
<p>Rerun the analysis with informative prior distributions based on the data obtained with the other randomized controlled trial. Compare the results from all three analyses. Which informative priors affect the results the most? Why?</p>
</blockquote>
<pre class="r"><code>120 / 245</code></pre>
<pre><code>[1] 0.4897959</code></pre>
<pre class="r"><code>80 / 275</code></pre>
<pre><code>[1] 0.2909091</code></pre>
<pre class="r"><code>(120 / 245) / (80 / 275)</code></pre>
<pre><code>[1] 1.683673</code></pre>
<pre class="r"><code>rjags_ex2.2 &lt;- jags.model(file=here(&quot;analysis&quot;, &quot;bayes_1_Model2.2.txt&quot;),
                   data = dat_ex1,
                   n.chains = 2) ###compile and initialize jags model</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 2
   Unobserved stochastic nodes: 2
   Total graph size: 12

Initializing model</code></pre>
<pre class="r"><code>update(rjags_ex2.2, nsamp)
samples_rjags_ex2.2 = coda.samples(model=rjags_ex2.2, variable.names=parstosave, n.iter=nsamp) 
summary(samples_rjags_ex2.2)</code></pre>
<pre><code>
Iterations = 11001:21000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

        Mean      SD  Naive SE Time-series SE
ppc   0.2863 0.02220 0.0001570      0.0001939
ppe   0.4613 0.02568 0.0001816      0.0002337
ratio 1.6212 0.15658 0.0011072      0.0013423

2. Quantiles for each variable:

        2.5%    25%    50%    75%  97.5%
ppc   0.2441 0.2709 0.2860 0.3011 0.3310
ppe   0.4109 0.4438 0.4613 0.4784 0.5118
ratio 1.3379 1.5132 1.6124 1.7217 1.9515</code></pre>
<p>Using these priors, the ratio comes out higher</p>
<pre class="r"><code>summaries &lt;- map(list(model_1 = samples_rjags_ex1,
                      model_2 = samples_rjags_ex2,
                      model_2.2 = samples_rjags_ex2.2),
                 summary)
map(summaries, &quot;quantiles&quot;)</code></pre>
<pre><code>$model_1
           2.5%       25%       50%       75%     97.5%
ppc   0.2128730 0.2570714 0.2819624 0.3080776 0.3578587
ppe   0.3338448 0.3843227 0.4114886 0.4403394 0.4927564
ratio 1.0633575 1.3078245 1.4588771 1.6355836 2.0370514

$model_2
           2.5%       25%       50%       75%     97.5%
ppc   0.2596059 0.2937855 0.3120627 0.3312302 0.3698253
ppe   0.3400957 0.3781606 0.3988612 0.4201098 0.4600784
ratio 1.0112539 1.1798337 1.2783770 1.3827924 1.6127518

$model_2.2
           2.5%       25%       50%       75%     97.5%
ppc   0.2441026 0.2709388 0.2859529 0.3010749 0.3309539
ppe   0.4109234 0.4437891 0.4613238 0.4784141 0.5117843
ratio 1.3378968 1.5132265 1.6124217 1.7216934 1.9514837</code></pre>
<p>The data from Thomas were based on more people, but whe estimated coefficient was closer to what we observed in our data, so the influence on the estimate was smaller</p>
<blockquote>
<p>What happens when you include conflicting data? What happens when your prior is based on more data than available in the current study?</p>
</blockquote>
<p>It overrides the data</p>
</div>
<div id="d-bonus-try-to-obtain-the-posterior-results-in-2.c-and-2.d-analytically." class="section level3">
<h3>2.d (bonus) Try to obtain the posterior results in 2.c and 2.d analytically.</h3>
<p>Remember we used ppe ~ dbeta(41,66) ppc ~ dbeta(45,86)</p>
<p>And</p>
<p>ppe ~ dbeta(121,126) ppc ~ dbeta(80,196)</p>
<pre class="r"><code>a_pe = 41; b_pe = 66
a_pc = 46; b_pc = 86
theta_pe &lt;- (a_pe + y_pe) / (a_pe + y_pe + b_pe + n_pe - y_pe)
theta_pc &lt;- (a_pc + y_pc) / (a_pc + y_pc + b_pc + n_pc - y_pc)
theta_pe / theta_pc</code></pre>
<pre><code>[1] 1.276491</code></pre>
<pre class="r"><code>theta_pe</code></pre>
<pre><code>[1] 0.3991935</code></pre>
<pre class="r"><code>theta_pc</code></pre>
<pre><code>[1] 0.3127273</code></pre>
<pre class="r"><code>a_pe = 121; b_pe = 126
a_pc = 80;  b_pc = 196
theta_pe &lt;- (a_pe + y_pe) / (a_pe + y_pe + b_pe + n_pe - y_pe)
theta_pc &lt;- (a_pc + y_pc) / (a_pc + y_pc + b_pc + n_pc - y_pc)
theta_pe / theta_pc</code></pre>
<pre><code>[1] 1.610846</code></pre>
<blockquote>
<p>How did you include the prior information in the calculation of the posterior mean? Did you get similar results?</p>
</blockquote>
<p>Yes the results are very similar.</p>
<p>In fact, they were closer to the 50% percentile than to the means</p>
<pre class="r"><code>map(summaries, &quot;statistics&quot;)</code></pre>
<pre><code>$model_1
           Mean         SD     Naive SE Time-series SE
ppc   0.2828738 0.03720338 0.0002630677   0.0003266170
ppe   0.4123127 0.04098871 0.0002898339   0.0003653588
ratio 1.4835232 0.24979780 0.0017663372   0.0022190393

$model_2
           Mean         SD     Naive SE Time-series SE
ppc   0.3127617 0.02799939 0.0001979856   0.0002525555
ppe   0.3992100 0.03089787 0.0002184810   0.0002912842
ratio 1.2866978 0.15313240 0.0010828096   0.0013984623

$model_2.2
           Mean         SD     Naive SE Time-series SE
ppc   0.2862550 0.02220056 0.0001569817   0.0001938545
ppe   0.4612668 0.02568016 0.0001815862   0.0002336660
ratio 1.6212210 0.15657696 0.0011071663   0.0013423318</code></pre>
</div>
</div>
<div id="exercise-3-evaluating-assumptions-with-a-posterior-predictive-check" class="section level2">
<h2>Exercise 3: Evaluating Assumptions with a Posterior Predictive Check</h2>
<blockquote>
<p>In this exercise you will focus on the data from the PE-group. In the previous exercise you assumed these data were binomially distributed. In this exercise you will assess whether the binomial model actually fits the data. If all the observed statuses of diagnosis are truly a sequence of independent Bernoulli trials (such that the number of successes is binomially distributed), the proportion of success in the first half of the data should be equal to the proportion of success in the second half. You will evaluate this using rjags, by performing a posterior predictive check.</p>
</blockquote>
<div id="a-specify-your-bayesian-model-for-jags-1" class="section level3">
<h3>3.a Specify your Bayesian model for JAGS</h3>
<blockquote>
<p>Specify the basic model for the bernouilli distributed data of the PE condition, with uninformative prior distributions.</p>
</blockquote>
<div id="step-1.-likelihood-1" class="section level4">
<h4>Step 1. Likelihood</h4>
<blockquote>
<p>Open the file Model2.txt. Within the model{} statement, we need to specify the distributions and equations that describe the data for the PE-condition, so that JAGS can determine the likelihood of the data. The data you will use for this exercise is a series of n=141 Bernoulli trials. Please refer to the data in your model with x (like how in the previous exercises the data was called y_pe or y_pc), and refer to the total sample size with n.</p>
</blockquote>
<blockquote>
<p>You can do this with the following code: for (i in 1:n){ x[i] ~ dbern(ppe) } You see this code makes use of a “for loop”. Inside the for loop, it says x[i] ~ dbern(ppe). The for loop works like this: In its first loop, it note that i is equal to 1. Then it goes to the equation x[i] ~ dbern(ppe), and reads this as x[1] ~ dbern(ppe), that is, the first observation in the data x comes from a bernoulli distribution with parameter ppe. Then, it finishes its first loop, and goes to the second loop. Now it notes that i=2, and that x[2] ~ dbern(ppe), that is, the second observation in the data x also comes from a bernoulli distribution with parameter ppe. Then it goes to the third loop, and so on, until i is equal to n (with n being equal to the sample size of x). That is, this code says that each observation in x comes from a bernoulli distribution with parameter ppe.</p>
</blockquote>
</div>
<div id="step-2.-priors" class="section level4">
<h4>Step 2. Priors</h4>
<blockquote>
<p>Now, in file Model2.txt, within the model{} statement, specify a Beta(1,1) prior distribution for θ_pe.</p>
</blockquote>
</div>
</div>
<div id="b" class="section level3">
<h3>3.b</h3>
<blockquote>
<p>Specify all additional quantities in your model file that you need to do the posterior predictive check.</p>
</blockquote>
<div id="step-1." class="section level4">
<h4>Step 1.</h4>
<blockquote>
<p>Obtain the observed proportion of successes in each half of your data, and the difference between these proportions Within the model{} statement specify you wish to calculate the proportion of success in the first and second half of the data. Then specify you wish to calculate the difference between the two proportions. The latter is your discrepancy measure of interest.</p>
</blockquote>
<blockquote>
<p>You can do this with the following code:</p>
</blockquote>
<blockquote>
<h1 id="discrepancy-measure-in-the-data">discrepancy measure in the data</h1>
<p>ppe1 &lt;- sum(x[1:70])/70 ppe2 &lt;- sum(x[71:141])/71 dif &lt;- ppe1-ppe2 More information on the sum-function and other logical functions can be found in the JAGS manual under “Functions”.</p>
</blockquote>
</div>
<div id="step-2." class="section level4">
<h4>Step 2.</h4>
<blockquote>
<p>Obtain simulated data sets that are in line with your model assumptions. By sampling from a binomial distribution with the same probability as in the real dataset, we can obtain simulated data sets of bernoulli trials (each sample from the binomial distribution is equal to one data set of bernoulli trials). Specify two binomial distributions - the first one with a sample size that is equal to the first half of that of the real data, the second one with the same size as the second half of the real data. If the real data is also truly a set of bernouilli trials, the proportions of succes in the simulated datasets should be similar to what we found for the real dataset.</p>
</blockquote>
<blockquote>
<p>You can thus add the following lines within the model{} statement to obtain samples from the posterior predictive distribution in each iteration of the sampler (replicates of the first and second halves of the data):</p>
</blockquote>
<blockquote>
<h1 id="posterior-predictive-distribution">posterior predictive distribution</h1>
<p>postpred.ype1 ~ dbin(ppe,70) postpred.ype2 ~ dbin(ppe,71) Step 3. Obtain the observed proportion of successes in each half of each simulated data set, and the difference between these proportions. Obtain the proportion of success in the first and second half of the replicated data (simular to step 1), and calculate the difference between the two proportions (you could call it postpred.dif). This piece of code is not given, so you have to program this yourself.</p>
</blockquote>
<blockquote>
<p>Step 4. Use the step function to obtain the posterior predictive p-value (ppp-value) You can use the step function in JAGS in the following way to get a posterior predictive p-value for the difference between the real and simulated difference between the proportions of successes in each half of the data:</p>
</blockquote>
<blockquote>
<h1 id="posterior-predictive-p-value">posterior predictive p-value</h1>
<p>p &lt;- step(postpred.dif - dif) What does the step function do? See the JAGS manual (in chapter ‘Functions’) or (Ntzoufras 2009, p.96) for details on the step() function.</p>
</blockquote>
<p>Step function is False when x &lt; 0, and True when x &gt;= 1</p>
<blockquote>
<p>Now you know what the step function does, what does the mean of the posterior of p mean based on this piece of code? What is H0 in our (posterior predictive) hypothesis? What would you expect the posterior distribution of p to look like if H0 were true?</p>
</blockquote>
<p>In what proportion of the simulated samples was the difference higher than the observed difference.</p>
<p>If H0 is true, the observed difference should fall within the bulk of the distribution of the simulated differences</p>
</div>
</div>
<div id="c-use-rjags-to-run-your-bayesian-analysis-with-the-posterior-predictive-check." class="section level3">
<h3>3.c Use rjags to run your Bayesian analysis with the posterior predictive check.</h3>
<blockquote>
<p>Run this line of code in R to obtain a list with the data for the rjags model:</p>
</blockquote>
<pre class="r"><code>dat_ex3= list(x=c(0,0,1,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,1,1,1,0,0,1,0,1,1,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,1,1,0,1,0,1,1,0,0,0,1,0,0,1,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,0,0,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,0,0,0,1,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,1,1,0,0,0,1,0,0,1,0,1,0,0,0,0,1,1,0,0)
, n=141)</code></pre>
<blockquote>
<p>Now run the rjags analysis on your data with the model you specified in Model2.txt, in the same general way as in Exercise 1 and 2.</p>
</blockquote>
<pre class="r"><code>nsamp = 1000
rjag_3 &lt;- jags.model(here(&quot;analysis&quot;, &quot;bayes_1_Model3.txt&quot;),
                    data = dat_ex3,
                    n.chains = 2)</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 141
   Unobserved stochastic nodes: 3
   Total graph size: 162

Initializing model</code></pre>
<pre class="r"><code>update(rjag_3, nsamp)
vars_to_save &lt;- c(&quot;postpred.ppe1&quot;, &quot;postpred.ppe2&quot;, &quot;postpred.dif&quot;, &quot;p&quot;)
rjag_3_samples &lt;- coda.samples(rjag_3, variable.names = vars_to_save, n.iter = nsamp)</code></pre>
</div>
<div id="d-report-and-interpret-the-ppp-value." class="section level3">
<h3>3.d Report and interpret the ppp-value.</h3>
<pre class="r"><code>summary(rjag_3_samples)</code></pre>
<pre><code>
Iterations = 1001:2000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 1000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

                   Mean      SD Naive SE Time-series SE
p              0.214500 0.41058 0.009181       0.009180
postpred.dif  -0.003471 0.08129 0.001818       0.001788
postpred.ppe1  0.410564 0.07181 0.001606       0.001606
postpred.ppe2  0.414035 0.07057 0.001578       0.001578

2. Quantiles for each variable:

                 2.5%      25%       50%     75%  97.5%
p              0.0000  0.00000  0.000000 0.00000 1.0000
postpred.dif  -0.1642 -0.06358 -0.007847 0.04889 0.1620
postpred.ppe1  0.2714  0.35714  0.414286 0.45714 0.5571
postpred.ppe2  0.2817  0.36620  0.408451 0.46479 0.5634</code></pre>
<blockquote>
<p>What are your conclusions? Finally, give some thought to how this relates to the classical alternative for the ppp-value. Describe the difference(s).</p>
</blockquote>
<p>The proportion of times the posterior predictive check difference was higher than the observed difference</p>
<p>This was in 22% of the cases, which means that the observed difference is not very extreme under the null-hypothesis</p>
<pre class="r"><code>x1 &lt;- sum(dat_ex3$x[1:70])
n1 &lt;- 70
x2 &lt;- sum(dat_ex3$x[71:141])
n2 &lt;- 71
prop.test(c(x1, x2), c(n1, n2))</code></pre>
<pre><code>
    2-sample test for equality of proportions with continuity
    correction

data:  c(x1, x2) out of c(n1, n2)
X-squared = 0.34087, df = 1, p-value = 0.5593
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1137550  0.2389059
sample estimates:
   prop 1    prop 2 
0.4428571 0.3802817 </code></pre>
<p>The p-values are not very close</p>
<blockquote>
<p>Considerations for your presentation on Friday: Perform a Bayesian analysis on some (your own?) data set with uninformative and informative prior distributions Perform a posterior predictive pheck to check model assumptions for a particular (your own?) data set Present about the difference between classical hypothesis testing and using posterior predictive p-values</p>
</blockquote>
</div>
</div>
</div>
<div id="day-2" class="section level1">
<h1>Day 2</h1>
<blockquote>
<p>Applied Bayesian Statistics: Lab Meeting 2. Convergence, model selection with the DIC, and prediction. Today’s objectives Today you will use rjags to sample from the posterior distribution of a logistic regression model, and see if the procedure seems to have converged. You will also practice using the information criterium DIC in the context of the selection of predictors for a logistic regression model. Furthermore, for a person with known predictors but unknown outcome, you will obtain a prediction and credibility interval for the unknown outcome.</p>
</blockquote>
<div id="exercise-1-evaluating-convergence-for-a-logistic-regression-model" class="section level2">
<h2>Exercise 1: Evaluating Convergence for a Logistic Regression Model</h2>
<blockquote>
<p>In this exercise you will develop a clinical prediction rule for detecting major depressive disorder in primary care. The dataset you will use for this exercise consists of various measures of 1046 participants, aged 18-65 years. These participants were recruited from general practice waiting rooms. Major depressive disorder (depr: 0=no depression, 1=depression) was assessed with the Composite International Diagnostic Interview according to DSM-IV-TR criteria. For this exercise we will predict depression diagnosis with gender (0=male, 1=female).</p>
</blockquote>
<div id="a-specify-your-bayesian-logistic-regression-model-for-jags" class="section level3">
<h3>1.a Specify your Bayesian logistic regression model for JAGS</h3>
<div id="step-1.-likelihood-2" class="section level4">
<h4>Step 1. Likelihood</h4>
<blockquote>
<p>Open file ModelDay2.txt, and specify a univariate logistic regression model with gender as a predictor variable, such that JAGS can determine the likelihood of the data.</p>
</blockquote>
<blockquote>
<p>A logistic regression model could be specified for OpenBUGS as follows:</p>
</blockquote>
<blockquote>
<h1 id="likelihood-of-the-data-1">likelihood of the data</h1>
<p>for (i in 1:n){ logit(p[i]) &lt;- alpha + b.gender*gender[i] depr[i] ~ dbern(p[i])}</p>
</blockquote>
<pre class="r"><code>con1 &lt;- file(here(&quot;analysis&quot;, &quot;bayes_2_Modelday2.txt&quot;), open = &quot;r&quot;)
lines1 &lt;- readLines(con1)</code></pre>
</div>
<div id="step-2.-priors-1" class="section level4">
<h4>Step 2. Priors</h4>
<blockquote>
<p>Next, specify prior distributions for all parameters in the model that need to be estimated. What type of prior distributions would you specify for the regression coefficient and for the intercept? How would you specify these distributions to be uninformative?</p>
</blockquote>
<p>Take</p>
<ul>
<li>alpha: normal with mean 0, variance 10000 (precision 1/10000)</li>
<li>beta: normal with mean 0, variance 10000 (precision 1/10000)</li>
</ul>
<blockquote>
<p>You can refer to the jags manual for an overview of all available probability distributions (<a href="https://sourceforge.net/projects/mcmc-jags/files/Manuals/4.x/jags_user_manual.pdf/download" class="uri">https://sourceforge.net/projects/mcmc-jags/files/Manuals/4.x/jags_user_manual.pdf/download</a>). Pay special attention to what the parameters of each distribution represent - for example, the normal distribution is not specified with a mean and standard deviation as you might expect, but with a mean and a precision (the precision is equal to 1/variance).</p>
</blockquote>
</div>
<div id="step-3.-interesting-additional-quantities" class="section level4">
<h4>Step 3. Interesting additional quantities</h4>
<blockquote>
<p>You might want to specify the exponent of your regression coefficient in order to interpret directly the posterior distribution of the odds and odds ratios. To do so, include the following commands in the model:</p>
</blockquote>
<blockquote>
<h1 id="odds-ratios">odds ratios</h1>
<p>odds0 &lt;- exp(alpha) or.gender &lt;- exp(b.gender)</p>
</blockquote>
</div>
</div>
<div id="b-fit-the-logistic-regression-model-with-rjags." class="section level3">
<h3>1.b Fit the Logistic Regression Model with rjags.</h3>
<div id="step-1.-data" class="section level4">
<h4>Step 1. data</h4>
<blockquote>
<p>With these lines of code you can load and specify the data for rjags:</p>
</blockquote>
<pre class="r"><code>load(here(&quot;data&quot;, &quot;data_practical2.Rdata&quot;))
data_prac2_ex1 &lt;- dat_prac2[,1:2]
n=length(data_prac2_ex1[,1])
data_ex1 &lt;- list(&quot;n&quot;=n, &quot;depr&quot;= data_prac2_ex1[,1],&quot;gender&quot;= data_prac2_ex1[,2])</code></pre>
</div>
<div id="step-2.-initial-values" class="section level4">
<h4>Step 2. initial values</h4>
<blockquote>
<p>This time you will have also specify the initial values yourself (instead of generating initial values randomly). You should specify initial values for all the parameters in your model, and put them in a list. Make three of these lists, each with different initial values - one for each chain. Here is an example for the first of your chains:</p>
</blockquote>
<blockquote>
<p>Finally, put all three of your lists into a list like so:</p>
</blockquote>
<pre class="r"><code>ins1 &lt;- list(alpha=0, b.gender=1)
ins2 &lt;- list(alpha = -5, b.gender = 0)
ins3 &lt;- list(alpha = 5, b.gender = -5)
ivals &lt;- list(ins1, ins2, ins3)</code></pre>
</div>
<div id="step-3-rjags-model" class="section level4">
<h4>Step 3 rjags model</h4>
<blockquote>
<p>Now specify your jags.model() function similar to the exercises from yesterday. Use three chains, and add inits= ivals as an argument to specify initial values for these chains.</p>
</blockquote>
<pre class="r"><code>jm_logit &lt;- jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Modelday2.txt&quot;),
                       data = data_ex1,
                       n.chains = length(ivals),
                       inits = ivals)</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 2
   Total graph size: 2105

Initializing model</code></pre>
</div>
<div id="step-4-burnin-and-samples" class="section level4">
<h4>Step 4 Burnin and samples</h4>
<blockquote>
<p>Specify that you want to take 2000 samples burnin. Then specify which parameters you want to save, and use coda.samples() to take 2000 samples (per chain) to base your results on. Store the latter samples in object samps_ex1.</p>
</blockquote>
<pre class="r"><code>nburnin = 2000
update(jm_logit, nburnin)

nsamps = 2000
to_save &lt;- c(&quot;alpha&quot;, &quot;b.gender&quot;, &quot;odds0&quot;, &quot;or.gender&quot;)
samps_ex1 &lt;- coda.samples(jm_logit, variable.names = to_save, n.iter = nsamps)</code></pre>
</div>
</div>
<div id="c-inspect-the-convergence-of-the-model" class="section level3">
<h3>1.c Inspect the convergence of the model</h3>
<blockquote>
<p>Inspect the trace plots You can obtain trace plots for each parameter with the following line of code:</p>
</blockquote>
<pre class="r"><code>plot(samps_ex1, density = F)</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Do the three chains seem to mix properly?</p>
</blockquote>
<p>Yes pretty good mix</p>
<blockquote>
<p>Inspect the density plots You can obtain trace plots for each parameter with the following line of code:</p>
</blockquote>
<pre class="r"><code>plot(samps_ex1, trace = F)</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-27-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Do the densities look nice and smooth? If not, you might want to take more samples.</p>
</blockquote>
<p>Yes they are pretty smooth</p>
<blockquote>
<p>Inspect the Gelman Rubin convergence diagnostics You can get both plots for the gelman rubin statistics for all the samples, and obtain summary statistics for them in the following way:</p>
</blockquote>
<pre class="r"><code>gelman.plot(samps_ex1) ##plot gelman rubin statistics</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-28-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>gelman.diag(samps_ex1) ## table gelman rubin statistics</code></pre>
<pre><code>Potential scale reduction factors:

          Point est. Upper C.I.
alpha              1       1.01
b.gender           1       1.01
odds0              1       1.01
or.gender          1       1.01

Multivariate psrf

1</code></pre>
<blockquote>
<p>Does the black line in the plot converge to 1? Are the point estimates and majority of plausible values very close to 1 on equal to 1 for each parameter?</p>
</blockquote>
<p>Yes all very close</p>
<blockquote>
<p>Inspect the monte carlo standard errors (naive se) for each parameter Use the function summary() on samples_ex1 and inspect the standard errors for each parameter. The monte carlo standard errors (both the naive, and the time series error which is corrected for the autocorrelation of the chain) represent an estimate of the uncertainty contributed by only having a finite number of samples from the posterior. These errors should be small compared to the standard deviation of your estimates - a rule of thumb is that they should be smaller than about 5% of the posterior standard deviation. Is this the case for each parameter?</p>
</blockquote>
<pre class="r"><code>summary(samps_ex1)</code></pre>
<pre><code>
Iterations = 3001:5000
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 2000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean      SD  Naive SE Time-series SE
alpha     -2.0687 0.16316 0.0021063      0.0065371
b.gender   0.4867 0.19201 0.0024788      0.0078679
odds0      0.1280 0.02072 0.0002675      0.0008035
or.gender  1.6573 0.32446 0.0041888      0.0135047

2. Quantiles for each variable:

              2.5%     25%     50%     75%   97.5%
alpha     -2.40952 -2.1729 -2.0633 -1.9568 -1.7576
b.gender   0.11785  0.3576  0.4815  0.6124  0.8791
odds0      0.08986  0.1138  0.1270  0.1413  0.1725
or.gender  1.12507  1.4299  1.6184  1.8448  2.4086</code></pre>
<p>Yes they are lower than 5% from the SD of the parameter</p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<blockquote>
<p>Do you think the sampler has converged? If not, consider centering the predictor to avoid a strong correlation between the intercept and slope (as discussed in today’s lecture), and/or taking more samples.</p>
</blockquote>
<p>To me it seems pretty converged</p>
<blockquote>
<p>Tip: You can make a scatter plot to visually inspect the correlation between the intercept and slope for the first chain like this:</p>
</blockquote>
<p>Make them into a data.frame, bind together by chain</p>
<pre class="r"><code>samps_df &lt;- samps_ex1 %&gt;%
  map(as.data.frame) %&gt;%
  rbindlist(idcol = &quot;chain&quot;)</code></pre>
<p>Plot by chain</p>
<pre class="r"><code>samps_df %&gt;%
  ggplot(aes(x = alpha, y = b.gender)) + 
  geom_point(alpha = .5) + 
  facet_wrap(~chain)</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-31-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Does not seem too narrow in either of the 3 chains</p>
</div>
<div id="d-inspect-and-interpret-the-results-1" class="section level3">
<h3>1.d Inspect and interpret the results</h3>
<blockquote>
<p>Once you have ensured yourself that the sampler has converged (for all parameters) you can continue to report and interpret the posterior results. What is the posterior estimate of the OR for gender? Looking at the 95% Credible Interval would you want to keep this predictor in the model?</p>
</blockquote>
<blockquote>
<p>Use the function summary() and your density plots to draw your conclusions.</p>
</blockquote>
<pre class="r"><code>summary(samps_ex1)</code></pre>
<pre><code>
Iterations = 3001:5000
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 2000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean      SD  Naive SE Time-series SE
alpha     -2.0687 0.16316 0.0021063      0.0065371
b.gender   0.4867 0.19201 0.0024788      0.0078679
odds0      0.1280 0.02072 0.0002675      0.0008035
or.gender  1.6573 0.32446 0.0041888      0.0135047

2. Quantiles for each variable:

              2.5%     25%     50%     75%   97.5%
alpha     -2.40952 -2.1729 -2.0633 -1.9568 -1.7576
b.gender   0.11785  0.3576  0.4815  0.6124  0.8791
odds0      0.08986  0.1138  0.1270  0.1413  0.1725
or.gender  1.12507  1.4299  1.6184  1.8448  2.4086</code></pre>
<p>From the 95% credible interval, I would keep the regression coefficient in.</p>
</div>
<div id="e-credible-and-confidence-intervals" class="section level3">
<h3>1.e Credible and Confidence Intervals</h3>
<blockquote>
<p>Describe the difference between the classical Confidence Interval and the Bayesian Credibility Interval.</p>
</blockquote>
<p>Check with glm</p>
<pre class="r"><code>fit_glm &lt;- glm(depr ~ gender, family = binomial, data = data_prac2_ex1)
summary(fit_glm)</code></pre>
<pre><code>
Call:
glm(formula = depr ~ gender, family = binomial, data = data_prac2_ex1)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.6122  -0.6122  -0.6122  -0.4888   2.0899  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -2.0644     0.1638 -12.604   &lt;2e-16 ***
gender        0.4850     0.1932   2.511    0.012 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 884.65  on 1045  degrees of freedom
Residual deviance: 878.02  on 1044  degrees of freedom
AIC: 882.02

Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>confint(fit_glm)</code></pre>
<pre><code>                 2.5 %     97.5 %
(Intercept) -2.3996663 -1.7559256
gender       0.1138989  0.8728945</code></pre>
<p>The confidence intervals are not the same.</p>
</div>
</div>
<div id="exercise-2-model-selection-with-the-dic-for-a-logistic-regression-model" class="section level2">
<h2>Exercise 2: Model Selection with the DIC for a Logistic Regression Model</h2>
<div id="a-choose-five-candidate-models" class="section level3">
<h3>2.a Choose five candidate models</h3>
<blockquote>
<p>Based on what you know about depressive disorders, select three candidate predictor variables (in addition to gender) from the variables listed below. Choose and write down five interesting candi- date models that you could build with these predictors.</p>
</blockquote>
<blockquote>
<p>Candidate predictors for the model are: gender: 0=male, 1=female age: age in years educ: educational level, 0=more than primary, 1=only primary consult: number of consults in the last 12 months household: 0=with others, 1=alone partner: 0=with partner, 1=single diagnosis: wether GP made diagnosis, 0=diagnosis , 1=only complaint (no diagnosis) problems: presentation of mental or social problems at inclusion, 0=no, 1=yes somatic: presentation of somatic complaints at inclusion, 0=no, 1=yes antidep: antidepressant prescribed in the last 12 months, 0=no, 1=yes depGP: depression code at GP, 0=no, 1=yes cidi1: any depressed feelings in lifetime, 0=no, 1=yes cidi2: any loss of interest in lifetime, 0=no, 1=yes</p>
</blockquote>
<p>All could be important, I choose:</p>
<ul>
<li>problems</li>
<li>age</li>
<li>household</li>
</ul>
<p>models:</p>
<ul>
<li>fit0: depr ~ 1</li>
<li>fit1: depr ~ gender</li>
<li>fit2: depr ~ gender + age</li>
<li>fit3: depr ~ gender + age + problems</li>
<li>fit4: depr ~ gender + age + problems + household</li>
</ul>
</div>
<div id="b-specify-and-fit-each-of-the-five-models-and-monitor-the-dic-for-each-model." class="section level3">
<h3>2.b Specify and fit each of the five models, and monitor the DIC for each model.</h3>
<p>First inspect the data</p>
<pre class="r"><code>str(dat_prac2)</code></pre>
<pre><code>&#39;data.frame&#39;:   1046 obs. of  14 variables:
 $ depr     : num  0 0 1 0 0 0 0 0 0 0 ...
 $ gender   : num  0 1 0 1 1 0 1 1 1 1 ...
 $ age      : num  66 56 51 24 60 49 54 57 63 52 ...
 $ consult  : num  2 15 24 7 6 12 17 10 8 1 ...
 $ educ     : num  0 0 1 0 0 0 0 0 0 0 ...
 $ household: num  0 0 0 0 0 0 0 0 0 1 ...
 $ partner  : num  0 0 0 1 0 0 0 0 0 1 ...
 $ diagnosis: num  0 0 0 1 1 0 1 0 1 1 ...
 $ problems : num  0 0 0 0 1 0 0 0 0 0 ...
 $ somatic  : num  1 1 1 1 0 1 1 1 1 1 ...
 $ depGP    : num  0 0 0 0 0 0 0 0 0 0 ...
 $ antidep  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ cidi1    : num  0 0 0 0 0 1 1 1 0 0 ...
 $ cidi2    : num  0 0 1 0 0 1 0 0 0 0 ...</code></pre>
<p>Setup a container for the models</p>
<pre class="r"><code>library(formula.tools)
models &lt;- data.frame(
  model = 0:4,
  outcome = &quot;depr&quot;,
  rhs_char = c(&quot;1&quot;, 
               &quot;gender&quot;, 
               &quot;gender + age&quot;, 
               &quot;gender + age + problems&quot;, 
               &quot;gender + age + problems + household&quot;)
)
models %&lt;&gt;%
  mutate(
    model_file = paste0(&quot;bayes_2_Model2.&quot;, model, &quot;.txt&quot;),
    model_file_full = here(&quot;analysis&quot;, model_file),
    formula_char = paste0(outcome, &quot;~&quot;, rhs_char),
    covariates = map(formula_char, ~rhs.vars(formula(.x))),
    parameters = map(covariates, ~{
      params = c(&quot;alpha&quot;)
      if (length(.x) &gt; 0) params = c(params, paste0(&quot;b.&quot;, .x))
      return(params)})
    )
models$parameters</code></pre>
<pre><code>[[1]]
[1] &quot;alpha&quot;

[[2]]
[1] &quot;alpha&quot;    &quot;b.gender&quot;

[[3]]
[1] &quot;alpha&quot;    &quot;b.gender&quot; &quot;b.age&quot;   

[[4]]
[1] &quot;alpha&quot;      &quot;b.gender&quot;   &quot;b.age&quot;      &quot;b.problems&quot;

[[5]]
[1] &quot;alpha&quot;       &quot;b.gender&quot;    &quot;b.age&quot;       &quot;b.problems&quot;  &quot;b.household&quot;</code></pre>
<p>Declare starting values for each model</p>
<p>These should be lists with values named per variable</p>
<p>We will set starting values between -5 and 5 for each of them, as they are all regression coefficients. To make sure not all variables start with the same coefficient, we will cycle the starting values</p>
<pre class="r"><code>nmodels &lt;- nrow(models)
start_values &lt;- c(-5, 0, 5)
nchains = length(start_values)
# models$formula_char %&gt;%
#   map(formula) %&gt;% 
#   map(rhs.vars) %&gt;%
#   map(print)

start_values_list &lt;- vector(length = nmodels, mode = &quot;list&quot;)
for (i in 1:nmodels) {
  params = models$parameters[i][[1]]
  nparams = length(params)

  start_values_model &lt;- vector(length = nchains, mode = &quot;list&quot;)
  
  for (j in 1:nchains) {
    start_values_model[[j]] &lt;- vector(length = nparams, mode = &quot;list&quot;)
    names(start_values_model[[j]]) &lt;- params

    ## assign value of alpha
    start_values_model[[j]][[&quot;alpha&quot;]] &lt;- start_values[j]

    ## assign values of other variables
    if (nparams &gt; 1) {
      for (k in 2:(nparams)) {
        shifter = 1 + ((1 + j + k) %% 3)
        start_values_model[[j]][[k]] &lt;- start_values[shifter]
      }
    }
  }
  start_values_list[[i]] &lt;- start_values_model
}
print(start_values_list[[2]])</code></pre>
<pre><code>[[1]]
[[1]]$alpha
[1] -5

[[1]]$b.gender
[1] 0


[[2]]
[[2]]$alpha
[1] 0

[[2]]$b.gender
[1] 5


[[3]]
[[3]]$alpha
[1] 5

[[3]]$b.gender
[1] -5</code></pre>
<p>Compile the models, store them in a list</p>
<pre class="r"><code>start_values_list[[2]][[1]]</code></pre>
<pre><code>$alpha
[1] -5

$b.gender
[1] 0</code></pre>
<pre class="r"><code>dat_prac2_cage &lt;- mutate(dat_prac2, age = (age - min(age)) / diff(range(age)))
j_models &lt;- map2(models$model_file_full, start_values_list,
                 ~jags.model(.x, 
                             data = dat_prac2_cage,
                             inits = .y,
                            n.chains = 3)) </code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;gender&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;age&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;household&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;problems&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 1
   Total graph size: 1051

Initializing model</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;age&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;household&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;problems&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 2
   Total graph size: 2104

Initializing model</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;household&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;problems&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 3
   Total graph size: 3388

Initializing model</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;household&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 4
   Total graph size: 4566

Initializing model</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(.x, data = dat_prac2_cage, inits = .y, n.chains = 3):
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 5
   Total graph size: 5772

Initializing model</code></pre>
<pre class="r"><code>models %&lt;&gt;%
  mutate(jags_model = j_models,
         init_values = start_values_list,
         out_vars = c(&quot;alpha&quot;, setdiff(rhs_char, &quot;1&quot;)))</code></pre>
<blockquote>
<p>Do not forget to specify prior distributions and initial values for all parameters in each logistic regression model you run. For each model, inspect the convergence, examine and write down the posterior results: posterior means and 95% CIs of the parameters in each model, and the DIC.</p>
</blockquote>
<p>Now burnin each model and extract the relevant parameters</p>
<pre class="r"><code>nburnin = 2000
niter = 2000

burnin_and_run &lt;- function(model, params, nburnin, niter) {
  update(model, nburnin)
  # out_vars &lt;- c(&quot;alpha&quot;)
  # if (length(vars) &gt; 0) {
  #   out_vars &lt;- c(out_vars, paste0(&quot;b.&quot;, vars), paste0(&quot;or.&quot;, vars))
  # }
  samples = coda.samples(model, n.iter = niter, variable.names = params)
  return(samples)
}

models %&lt;&gt;%
  mutate(samples = map2(jags_model, parameters,
                        ~burnin_and_run(.x, .y, nburnin = nburnin, niter = niter)))</code></pre>
<p>Check convergence for the models</p>
<p>(implement in ggplot later)</p>
<pre class="r"><code># models %&gt;%
  # mutate(sample_df = samples %&gt;%
  #          map(~as.data.frame(.x[[1]])) %&gt;%
  #          rbindlist(idcol = &quot;chain&quot;, fill = T))</code></pre>
<pre class="r"><code>plot(models$samples[1][[1]])</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(models$samples[2][[1]])</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(models$samples[3][[1]])</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(models$samples[4][[1]])</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-4.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(models$samples[5][[1]])</code></pre>
<p><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-5.png" width="672" style="display: block; margin: auto;" /><img src="figure/bayes_assignments.Rmd/unnamed-chunk-42-6.png" width="672" style="display: block; margin: auto;" /></p>
<p>Extract the DIC</p>
<pre class="r"><code>models %&lt;&gt;% 
  mutate(dic = map(jags_model, ~dic.samples(.x, n.iter = niter, type = &quot;pD&quot;)))</code></pre>
<p>Look at DICs</p>
<pre class="r"><code>get_dic &lt;- function(x) {
  deviance &lt;- sum(x$deviance)
  psum &lt;- sum(x[[2]])
  penalized_deviance = deviance + psum
  return(penalized_deviance)
}

models %&lt;&gt;%
  mutate(dic_value = map_dbl(dic, get_dic))</code></pre>
<pre class="r"><code>models %&gt;%
  select(outcome, rhs_char, dic_value)</code></pre>
<pre><code>  outcome                            rhs_char dic_value
1    depr                                   1  886.6655
2    depr                              gender  881.7402
3    depr                        gender + age  881.6680
4    depr             gender + age + problems  873.2346
5    depr gender + age + problems + household  870.8503</code></pre>
<blockquote>
<p>Obtaining the right variables for your analysis and putting these data in a list For each model you need to specify the right data. For this you need to see in which columns of the dataframe dat_prac2 your variables of interest are stored. You need to select these columns, store them in an object, and then store those in a list for rjags. For example, if you want to select the variables depr, gender and partner, you can go about it in the following way:</p>
</blockquote>
<blockquote>
<p>head(dat_prac2) ###Use this code to see an abbreviated version of the dataframe, and count in which columns your variables are ### we see that depr is in column 1, gender in 2, and partner in 7. ##Store each column you need in an object with an appropriate name: depr &lt;- dat_prac2[,1] gend &lt;- dat_prac2[,2] part &lt;- dat_prac2[,7]</p>
</blockquote>
<blockquote>
<p>n=length(data_prac2_ex1[,1]) ### don’t forget to specify n too - the number of observations which is needed for your for loop.</p>
</blockquote>
<blockquote>
<h3 id="now-state-which-object-belongs-with-which-variable-in-your-jags-model-code-and-put-this-in-a-list-you-can-supply-to-rjags">Now state which object belongs with which variable in your jags model code, and put this in a list you can supply to rjags:</h3>
</blockquote>
<blockquote>
<p>data_m1 &lt;- list(“n”=n, “depr”=depr, “gender” = gend, “partner” = part) Monitoring the DIC To keep track of the dic, add the following (adjusted) line of code after using coda.samples()</p>
</blockquote>
<blockquote>
<h2 id="in-the-first-argument-you-specify-which-rjags-model-to-sample-the-dic-for-the-second-how-many-samples-to-take-and-the-third-the-type-of-penalty-function-pd-for-the-dic.">in the first argument you specify which rjags model to sample the dic for, the second how many samples to take, and the third the type of penalty function (pD for the DIC).</h2>
<p>dic.mod1 &lt;- dic.samples(model = rjags_ex1, n.iter=2000, type = “pD”) To obtain the dic, call dic.mod1 and write down the penalized deviance.</p>
</blockquote>
</div>
<div id="c-which-variables-are-included-in-your-final-model" class="section level3">
<h3>2.c Which variables are included in your final model?</h3>
<p>All</p>
<blockquote>
<p>Report and interpret the posterior results of your final model.</p>
</blockquote>
<p>Exercise 3: Prediction with a Bayesian Logistic Regression Model In this exercise you will predict the probability of depression for a new patient using Bayesian prediction.</p>
</div>
</div>
<div id="a-add-the-data-for-the-new-patient-to-the-data-set" class="section level2">
<h2>3.a Add the data for the new patient to the data set</h2>
<blockquote>
<p>Add the data for the predictor variables for the new patient at the bottom (last row) of the data frame dat_prac2. Specify the depression score as NA, indicating that this is a missing observation.</p>
</blockquote>
<blockquote>
<p>You can do this with the following code:</p>
</blockquote>
<blockquote>
<p>load(“data_practical2.Rdata”)</p>
</blockquote>
<pre class="r"><code>data_new_patient=c(NA,2,3.50000E+01,2.00000E+00,0.00000E+00,0.00000E+00, 0.00000E+00,1.00000E+00,1.00000E+00,1.00000E+00,
                   0.00000E+00,0.00000E+00,1.00000E+00,1.00000E+00)
dat_prac2[1047,] &lt;- data_new_patient
dat_prac2_cage_pred &lt;- mutate(dat_prac2, age = (age - min(age)) / diff(range(age)))</code></pre>
<blockquote>
<p>Is the new patient male or female? Has he/she been prescribed antidepressants?</p>
</blockquote>
<div id="b-run-the-model-and-report-and-interpret-the-results" class="section level3">
<h3>3.b Run the model and report and interpret the results</h3>
<blockquote>
<p>Report and interpret the 95% CI of the predicted probability of depression for this patient. Don’t forget to request depr[1047] and p[1047] as parameters to save samples for. What are your conclusions?</p>
</blockquote>
<pre class="r"><code>final_init &lt;- start_values_list[[5]]
final_params &lt;- models$parameters[5][[1]]

jm_predict &lt;- jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;),
                         data = dat_prac2_cage_pred, 
                         inits = final_init, n.chains = length(final_init))</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;consult&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;educ&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;partner&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;diagnosis&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;somatic&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;depGP&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;antidep&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;cidi1&quot; in data</code></pre>
<pre><code>Warning in jags.model(here(&quot;analysis&quot;, &quot;bayes_2_Model2.4_predict.txt&quot;), :
Unused variable &quot;cidi2&quot; in data</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1046
   Unobserved stochastic nodes: 6
   Total graph size: 5780

Initializing model</code></pre>
<pre class="r"><code>update(jm_predict, nburnin)
samp_predict &lt;- coda.samples(jm_predict, variable.names = c(final_params, &quot;pred_depr&quot;, &quot;pred_p&quot;),
                             n.iter = niter)</code></pre>
<pre class="r"><code>summary(samp_predict)</code></pre>
<pre><code>
Iterations = 3001:5000
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 2000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

               Mean     SD Naive SE Time-series SE
alpha       -2.0474 0.2601 0.003358       0.016133
b.age       -0.3861 0.3219 0.004155       0.016242
b.gender     0.4826 0.1974 0.002548       0.007641
b.household  0.4694 0.2202 0.002842       0.004432
b.problems   0.7252 0.2465 0.003182       0.004746
pred_depr    0.3823 0.4860 0.006274       0.006440
pred_p       0.3837 0.0828 0.001069       0.002342

2. Quantiles for each variable:

                2.5%     25%     50%     75%   97.5%
alpha       -2.55852 -2.2240 -2.0386 -1.8701 -1.5495
b.age       -1.01142 -0.6049 -0.3912 -0.1674  0.2481
b.gender     0.08824  0.3525  0.4801  0.6137  0.8647
b.household  0.03785  0.3239  0.4712  0.6120  0.9038
b.problems   0.22526  0.5631  0.7259  0.8932  1.1976
pred_depr    0.00000  0.0000  0.0000  1.0000  1.0000
pred_p       0.23241  0.3252  0.3813  0.4387  0.5536</code></pre>
</div>
<div id="c-dealing-with-missing-data" class="section level3">
<h3>3.c Dealing with missing data</h3>
<blockquote>
<p>Compare this Bayesian approach of handling missing data with classical missing data methods you are familiar with. What are differences and similarities?</p>
</blockquote>
<p>Does not work with missing values</p>
<blockquote>
<p>Today’s considerations for your presentation on Friday: Fit a Bayesian logistic regression model on your own data</p>
</blockquote>
<blockquote>
<p>Discuss differences and similarities between the DIC and other information criteria.</p>
</blockquote>
<blockquote>
<p>Use a Bayesian model for prediction with your own data set</p>
</blockquote>
<blockquote>
<p>Discuss missing data analysis from a Bayesian perspective</p>
</blockquote>
</div>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.6

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] bindrcpp_0.2        formula.tools_1.7.1 Bain_0.1.0         
 [4] rjags_4-6           coda_0.19-1         broom_0.4.2        
 [7] epistats_0.1.0      ggplot2_2.2.1       here_0.1           
[10] purrr_0.2.4         magrittr_1.5        data.table_1.10.4  
[13] dplyr_0.7.4        

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.14         git2r_0.20.0         plyr_1.8.4          
 [4] bindr_0.1            class_7.3-14         tools_3.3.2         
 [7] digest_0.6.13        evaluate_0.10.1      tibble_1.3.4        
[10] gtable_0.2.0         nlme_3.1-131         lattice_0.20-35     
[13] pkgconfig_2.0.1      rlang_0.1.6          psych_1.7.5         
[16] yaml_2.1.16          parallel_3.3.2       mvtnorm_1.0-6       
[19] e1071_1.6-8          stringr_1.2.0        knitr_1.18          
[22] rprojroot_1.2        grid_3.3.2           glue_1.2.0          
[25] R6_2.2.2             foreign_0.8-69       rmarkdown_1.8       
[28] tidyr_0.7.2          reshape2_1.4.2       operator.tools_1.6.3
[31] MASS_7.3-47          backports_1.1.0      scales_0.4.1        
[34] htmltools_0.3.6      assertthat_0.2.0     mnormt_1.5-5        
[37] fungible_1.5         colorspace_1.3-2     nleqslv_3.3.1       
[40] labeling_0.3         stringi_1.1.6        lazyeval_0.2.0      
[43] munsell_0.4.3       </code></pre>
</div>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
